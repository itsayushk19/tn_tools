URL,Title,Text,Tags
https://wccftech.com/apple-specific-amd-radeon-pro-w6800x-duo-tested-5000-gpu-loses-to-nvidias-1600-us-rtx-4090/,"Apple-Specific AMD Radeon Pro W6800X Duo Tested, $5000 GPU Loses To NVIDIA’s $1600 US RTX 4090","Hardware enthusiast, Der8auer, recently modified an AMD Radeon Pro W6800X Duo graphics card only found with the Mac Pro system and tested it against several leading graphics cards on the market. While the modified GPU is outclassed by the NVIDIA GeForce RTX 4090 Founder's Edition, the graphics card beats others in head-to-head 3D Time Spy Extreme tests but comes at more than double the price of its competition.

AMD Radeon Pro W6800X Duo graphics card in the Apple Mac Pro costs over $5K but can't beat an RTX 4090

The AMD Radeon Pro W6800X Duo graphics card utilizes the Mac Pro eXpansion design and form factor for the Mac Pro system. One major component missing from its design is an external power connection. The unique way that Apple has produced enough power for this graphics card is by taking a custom connector and a PCIe x16 connector and meshing them together to supply 400W of power.

The AMD Radeon Pro W6800X Duo graphics card also offers two Navi 21 GPU dies that transmit information between the two using the AMD Infinity Fabric interconnect. However, in the process, Apple did remove 20 Compute Units on each Navi 21 GPU die, dropping the CUs down to 60 units (3,840 Stream Processors). Navi 212 GPU dies come with 32 GB GDDR6 memory, transmitting at 16 Gbps through the 256-bit interface. The AMD Infinity Cache available on the AMD Radeon Pro W6800X Duo is 128 MB.

Hartung modified the AMD Radeon Pro W6800X to work with a consumer Z790 motherboard by connecting the GPU to the PCIe expansion slot utilizing a PCIe x16 riser cable and soldered two ground wires along with two 12V wires from a 12VHPWR cable. The motherboard CPU was the Intel Core i9-13900K processor and also incorporated 32 GB of DDR5 C30 memory with 6000 Mbps memory frequency.

Hartung used 3D Time Spy Extreme G1 benchmarking software to test the GPUs for the test and initially ran into difficulty with the AMD Adrenalin Software driver. This was believed to be due to Apple intentionally blocking the ability for the AMD Radeon Pro W6800X to work outside of the Mac Pro system. Instead, Hartung used the Apple Boot Camp driver.

The graphics cards tested against the AMD Radeon Pro W6800X Duo graphics card were:

GeForce RTX 4090 FE

Asus Strix GeForce RTX 4080

Radeon RX 7900 XTX (MBA)

Gigabyte Eagle GeForce RTX 4070 Ti

The testing results showed that the NVIDIA GeForce RTX 4090 Founders Edition (FE) performed the best, scoring 123.49. However, the Apple-based AMD Radeon Pro W6800X graphics card beat the other three. The Asus Strix GeForce RTX 4080 GPU scored 93.28 against the score of 97.21 from the Apple AMD GPU, while the AMD Radeon RX 7900 XTX (MBA) scored 89.78, and the Gigabyte Eagle GeForce RTX 4070 Ti GPU came in last place with a score of 69.78.

The AMD Radeon Pro W6800X Duo MPX Module sells from Apple for upwards of $5,000, but Hartung paid less for his testing version. Interestingly, three of the four cards that were tested against the Apple AMD GPU are from NVIDIA, which says quite a bit about the performance of the high-dollar Mac Pro graphics card against consumer-grade graphics cards.

News Sources: der8auer (YouTube), Tom's Hardware","Report, Hardware"
https://wccftech.com/in-display-face-id-will-see-daylight-with-the-launch-of-iphone-16-pro/,In-Display Face ID Will See Daylight With The Launch Of iPhone 16 Pro,"With the launch of the iPhone X in 2017, Apple replaced Touch ID with Face ID on its flagship devices. It started with a notch that shrank down in size with the iPhone 13 series. Apple ditched the notch in favor of the Dynamic Island on the iPhone 14 Pro models, and it seems the company will move away with it in the coming years. Make no mistake, the entire iPhone 15 series is expected to feature the Dynamic Island cutout on the front. We are now hearing that next year's iPhone 16 Pro models will come with an in-display Face ID mechanism.

iPhone 16 Pro will feature an in-display Face ID mechanism, but the in-display camera will arrive with the iPhone 18 Pro

The Elec reports that Apple has the technology to implement in-display Face ID on the iPhone that allows the light to pass through the glass screen and enter the TrueDepth camera setup. If the news has any heft to it, we might see the iPhone 16 Pro models come with just the front-facing camera cutout. The display above the TrueDepth camera system would work normally and offer more screen real estate to users.

Apple's implementation will not be the first of its kind. Samsung has been playing around with under-display technology for a while and has implemented it in its latest Galaxy Z Fold series. Apple's in-display Face ID will work similarly to Samsung's implementation, where the TrueDepth sensors will be hidden under the display, and pixels will cover up the portion.

The report also suggests that Apple will bring down in-display Face ID to the standard iPhone models in 2025. Apple has created a gap between the standard and 'Pro' iPhone models and will also carry the difference in upcoming models. Henceforth, Apple will offer an in-display camera system with the iPhone 18 Pro models. This means that the 2026 'Pro' iPhone models will be the first iPhone to come with an all-screen display without any distractions.

Apple has secured a premium spot for the 'Pro' iPhone models with exclusive features and hardware upgrades. For instance, the iPhone 14 Pro models feature the new Dynamic Island cutout, while the standard models carry forward the design introduced with the iPhone 13. Another important aspect surrounding the iPhone display upgrade is the two-year cycle. Each iPhone will offer improved display technology for two years until the device goes all-screen.

This is not the first time that we are hearing details on the in-display Face ID and camera setup. Ross Young provided the same details back in 2022, highlighting that Face ID will go under the display with the iPhone 16 Pro while the iPhone 18 Pro will offer an in-display camera in 2026. When do you think Apple will launch an iPhone with an all-screen design? Let us know your thoughts in the comments.",Mobile
https://wccftech.com/microsoft-brings-imessage-to-windows/,"Microsoft Brings iMessage Support To Windows And Naturally, Certain Features Are Missing","In various versions of Windows, including Windows 11, Microsoft has introduced the Phone Link app, which allows users to make and receive calls or messages. As a bonus, you can even view the notifications on an Android handset, but today, the company is bringing iPhone support to the app and, more specifically, iMessage support. Here is everything you need to know if you have a Windows 11 computer and iPhone combo in your possession.

Sending and receiving messages using the Phone Link app is possible through iMessage support on Windows, but that is about all that you are getting

On Microsoft’s website, the company has stated that users that currently belong to the Windows Insider Program can test out the iMessage feature. However, keep in mind that only a small percentage of Insiders will gain access this week, so if you are not given the opportunity, then you will need to be patient, as availability will be added to more users with time.

As for those who have an iPhone and want to link it to Windows 11, here is what you need to do. Go to the Phone Link app, and you will be able to see the option to select an iPhone (previously, there was only the option to link an Android smartphone). After selecting, an installation process will start, guiding you on how to link the app with the iPhone after you scan a QR code displayed on your computer.

You will be able to see the ‘iPhone’ option

While the process of setting up an iPhone using the Windows 11’s Phone Link app could be considered seamless to some, there are limited features when setting up iMessage, as pointed out by MacRumors. For instance, users can send and receive text messages through iMessage, but as expected, there is no option to send images or videos, which is a massive letdown because WhatsApp’s dedicated Windows 11 app provides these additions.

The pairing process

Secondly, there is a lack of full message history for conversations, so when you want to run through something with a friend you discussed in the past, you will have to reach for your iPhone to get the job done, and that breaks productivity. In all fairness, it was expected that Microsoft would bring limited iMessage support to Windows 11, but the question remains if the company will expand upon this in the future. Stay tuned and find out.

News Source: Windows","Mobile, Announcement"
https://wccftech.com/dell-launches-new-xps-desktop-laptops-for-2023-intel-13th-gen-cpus-with-radeon-rx-7000-rtx-40-gpu-options/,DELL Launches New XPS Desktop & Laptops For 2023: Intel 13th Gen CPUs With Radeon RX 7000 & RTX 40 GPU Options,"Dell launches the new XPS Desktop, delivering up to the latest 13th Gen Intel Core CPUs and NVIDIA GeForce RTX 4090 GPU. The company is also releasing the new XPS 15 and XPS 17, which share the same series processor but offer NVIDIA GPUs from the RTX 40 series. Dell is marketing the new XPS Desktop for content creation and gaming, while the XPS 15 laptop is focused on creation. The XPS 17 offers the same content creation capability but also adds superior performance.

Dell ramps up the company's XPS Desktop and laptop offerings with new Intel, NVIDIA, and AMD options for all

The new desktop is configurable for processor options from Intel's Raptor Lake series chipset, ranging between the i5-13400 (offering ten cores, 20 MB of L3 cache, and frequencies between 2.5 GHz to 4.6 GHz). The system utilizes a Z690 motherboard with standard, advanced, and performance cooling options ranging between air and liquid. All XPS Desktops feature Windows 11 Home/Pro for consumers.

Memory options start at 8GB of DDR5-4800 with support for up to 64 GB (the company notes that additional memory is sold separately). Graphics options range from Intel's integrated UHD graphics to NVIDIA GeForce GTX 1650 SUPER, RTX 30 series GPUs, and RTX 40 series GPUs. AMD Radeon RX 6000 and 7000 series graphics cards are also offered to consumers.

The chassis on the XPS desktop is a mix of graphite and platinum aluminum bezels with steel sides. For connectivity options, Dell offers (in the front of the case) an SD Card reader, three USB 3.2 Type-A ports, a single USB 3.2 Type-C Gen 2, and a 3.5mm audio jack. In the back, the Dell XPS Desktop offers various graphical ports (depending on the GPU model) and USB 2.0 and 3.2 Type A and C ports. Gigabit Ethernet and 7.1 channel audio 6-connector stack of restackable audio ports. The new desktop from Dell delivers WiFi 6 and 6E options and Bluetooth 5.2. Accessories added to the system are the Dell Multimedia Keyboard, Optical Mouse, and an external slim DVD rewritable drive.

2 of 9

The XPS 15 laptop has a 15.6-inch InfinityEdge OLED display with a 92.9% screen-to-body ratio. Users will experience the system's 13th Gen Intel Core processors with the latest NVIDIA GeForce RTX 40 series GPUs. The screen on the XPS 15 laptop supports the DisplayHDR 500, 400 nits of brightness, 100% sRGB/DCI-P3 color gamut, 100,000:1 contrast ratio (1,650:1 in other configurations), and a 176° to 178° wide viewing angle. Connectivity is lush with two Thunderbolt 4 (USB Type-C) with DisplayPort and Power Delivery, one USB 3.2 Gen 2 Type-C (DisplayPort and Power Delivery), a single full-size SD card reader v6.0, and one 3.5mm audio jack.

2 of 9

The XPS 17 varies slightly with a better battery, larger screen, and increased somewhat durability and security, but it shares the same connectivity, memory, and storage options.

For those interested in the newest offerings from Dell's XPS lines, check out their official website for more details, pricing, configurations, and availability.

News Source: Dell","Press Release, Hardware"
https://wccftech.com/intel-others-will-have-to-limit-share-buybacks-chinese-chip-plans-to-receive-u-s-funding/,"Intel, Others Will Have To Limit Share Buybacks, Chinese Chip Plants To Receive U.S. Funding","This is not investment advice. The author has no position in any of the stocks mentioned. Wccftech.com has a disclosure and ethics policy.

After the U.S. CHIPS Act was made official last year, the Commerce Department has released its first funding round details for the investments that the government will make in the semiconductor industry to develop ""large scale clusters"" of leading edge chip fabrication and research facilities in the U.S. Today's announcement covers the first funding round of the program, which deals with requiring companies to submit their applications for up to 15% of support related to setting up new facilities in the U.S. to make leading edge chips or memory products.

They also issue rules that the firms applying for the grants will be required to follow, including a limitation for setting up new manufacturing facilities in high risk countries and submitting plans for future stock buyback to the Commerce Department as part of the application process.

U.S. CHIPS Act Will Evaluate Applicants On Several Criteria, Including Investments In Countries of Concern and Stock Buybacks

The U.S. CHIPS Act was passed in Congress last year, and today the Commerce Department opened up its first round of applications for the funding. This round asks interested parties to submit letters of interest to the government, through which their applications can be evaluated for the support. The applications will compete for up to $38 billion in direct funding and a whopping $75 billion for government loan guarantees and other backing.

As part of the application process, companies such as Intel, which have been quite vocal about the incentives, will also be required to make their own contributions and show how much private funding they have secured for the planned projects for which they are applying for the CHIPS funding. They will also be required to submit financial projections, including total capital expenditure, cash oufllws until the project breaks even and workforce spending.

Part of the details required by the funding application under the CHIPS Act. Image: CHIPS Incentives Program – Commercial Fabrication Facilities Notice of Funding Opportunity/ Department of Commerce

Additonally, Commerce will also require firms to submit details of any potential share ubybacks and dividend payment that they are planning for the future, and stop them from making any dividend payments or buybacks from the funds granted through the CHIPS Act. As part of a fact sheet titled Protecting U.S. Taxpayers, the Deparment outlines that:

Buyback Commitment: In light of the Department’s commitment to prioritizing applicants that invest in the United States, the applicant should detail their intentions with respect to stock buybacks over five years, including whether they intend to refrain from or limit them, as well as details around the existence of any current or future intentions for share buybacks, dividend payments, dividend payment increases, or special dividends.

The applications will be evaluated ""based on the extent of the applicant’s commitments to refrain from stock buybacks,"" and according to the details shared today, companies will also be required to share excess cash flows from any investment made through the CHIPS Act with the government.

As Commerce highlights:

The CHIPS Program Office will require recipients of more than $150 million in direct funding to share with the U.S. government a portion of any cash flows or returns that exceed the applicant’s projections above an established threshold. This requirement will be waived only in exceptional circumstances. The terms of upside sharing will be set on a case-by-case basis and will incentivize companies to ensure that their financial projections are as accurate as possible. Any upside sharing proceeds will go to support the purposes of the CHIPS Act and strengthen the U.S. semiconductor ecosystem.

Finally, should a firm receive funding from the government under the CHIPS Act, it will be forbidden from investing for the next decade in any country of concern, such as China. This is part of the government's efforts to limit access to semiconductor technology to nations that are deemed as hostile against U.S. national security, with the notice of funding opportunity explicitly pointing out:

Under the CHIPS Act, a successful applicant must enter into an agreement specifying that during the 10-year period beginning on the date of the award, it may not engage in any significant transaction involving the material expansion of semiconductor manufacturing capacity any foreign country of concern, except under certain limited conditions.63 Additional information on the implementation of this provision will be provided to applicants prior to award.",Finance
https://wccftech.com/the-nothing-phone-2-will-have-a-snapdragon-8-series-processor/,The Nothing Phone 2 will Have A Snapdragon 8 Series Processor,"The Nothing Phone 1 is one of the most, if not the most, exciting phones in the market. Despite being an Android device, it managed to do something different in a way that you get a unique design with some really cool looks and an overall excellent, near-stock Android experience. However, there was one minor issue with the phone - it was not a flagship device as it came with Snapdragon 7 series processor.

Nothing finally confirms that Nothing Phone 2 will be a premium device with Snapdragon 8 series processor

Don't get me wrong, the Snapdragon 7 series processor is very capable, however, when you are competing against the big boys in the market, it lags behind. Well, this is about to change as Nothing has finally confirmed at MWC 2023 that the upcoming Nothing Phone 2 is going to feature a Snapdragon 8 series processor. We do know that the phone will be coming later this year, but there are no more details that were shared with us.

As far as the choice of processor is concerned, even that is a mystery at best. While we would like to see a Snapdragon 8 Gen 2 chipset in the Nothing Phone 2, we also have to deal with the fact that such a chipset would put it right next to phones like OnePlus 11, Galaxy S23, and other similar flagships slated for this year. On the other hand, we could expect an older chipset like the Snapdragon 8 Gen 1 or the plus variant, and if that is the case, we would still be more than happy.

With the Nothing Phone 2 getting a flagship/premium SoC, the phone has just become a lot more attractive for everyone who is looking forward to buying a new phone and wants something different than what the traditional market has to offer. Sadly, at the time of writing, we know little to nothing about the upcoming phone from Nothing, aside from the fact that you are getting a Snapdragon 8 series chipset and you will also have Snapdragon Satellite support.

For those wondering about the release date, it is worth noting that the Nothing Phone 1 was released in July. So, we are hoping that the Nothing Phone 2 also comes out during the same time. We can expect the company to start sharing more and more details about the upcoming phone once MWC 2023 ends and we are headed into a new month.

What are you looking forward to the most in the Nothing Phone 2? Let us know your thoughts about a new competitor in the market in the comments below.",Mobile
https://wccftech.com/io-interactive-confirms-long-rumored-online-fantasy-rpg/,IO Interactive Confirms Long Rumored Online Fantasy RPG,"Today, Danish game developer IO Interactive confirmed the nearly two-year-old rumor that it's working on an online fantasy roleplaying game.

While the blog post does not go into any concrete details about the game other than it being a new IP, the article stresses that it's an entirely new journey for all the IO Interactive offices across the world and one that many developers had been waiting a long time to undertake. Indeed, a couple of years ago, IOI CEO Hakan B. Abrak candidly said the unannounced universe (other than Project 007, which is likely to come out sooner) was a 'love child' and something that the core staff at the company had been dreaming about for quite some time.

This excitement certainly shows in the brief but poignant interviews with some of the key people at IO Interactive who are working on the online fantasy RPG.

Tova Nystrom, Junior Gameplay Animator:

I think when it comes to fantasy, there is not as many rules you have to follow. You can kind of let your imagination run wild and exaggerate expression in general with animation. I get a lot of inspiration from everyone I'm working with because everyone has such a burning passion for fantasy, and this has been something a lot of us have been wanting to work on for very long. Now, when we finally get the chance to try something new, we kind of reconnect with the child who always loved the fantasy movies and games, and now we're creating our own version of that.

Esben Rasmussen, Art Director:

All of our colleagues are fantasy friends and have it as hobbies and interests, so when you are working on a fantasy game you can bring those past experiences and interests into whatever you're sitting and working with. There's lots of creative freedom, lots of responsibility and trust that is being instilled in you.

I think some of the specific challenges and the responsibility that I have for this project has pushed me to create the best work that I've created in my entire career. I can't wait to show the world more of it. Some of the innovations that we're doing and how we are pushing the limit on this project are elements that I'm not really able to share with you at the moment. But there are familiar elements combined with new ones that I don't think we have quite seen in a game.

Stephanie Pecaoco, Producer:

My interest in fantasy started from the day I was born, I think, and it grew from the day I started reading books and watching fantasy films with my father. He was the one who really brought me into this genre.

When I was being interviewed at IO Interactive, the producer that was interviewing me asked me to try out the game, and when I did, I was blown away. I want this game out there, out in the world. That's why I signed up.

Joshua Smith, Lead Sound Designer:

We're trying to create something that I think doesn't exist in this space currently. It's a world where we're going to allow you to be things you could never be.

Clement Linel, Senior AI Programmer:

I think what's appealing about this project is having this mix of both starting anew as it's a brand new world and at the same time relying on existing tech that has been developed over many games. This is not the studio's first game at all and their technology is very mature.

The last comment in particular pretty much confirms that IO Interactive will be using the Glacier engine seen in the HITMAN installment, although certainly optimized and tweaked for the needs of this specific project.

It may be a while before the so-called Project Fantasy is released (presumably on PC and Xbox, according to the original rumor), but we'll be sure to keep a watchful eye on any rumors or news in the meantime.",Gaming
https://wccftech.com/video-games-coming-out-march-2023/,"Resident Evil 4, Wo Long: Fallen Dynasty and More Exciting Games Coming Out in March","Keeping track of all the latest video games coming out is an increasingly complex task, what with multiple PC storefronts, Xbox One, PS4, Switch, mobile, and more to keep track of, but don’t worry, I’m here to help. Every month I'll be running down the games you need to be keeping an eye on, from the big triple-A headliners, to the intriguing indies you might overlook.

Following on the heels an unusually packed February, March isn’t quite as busy, but there are still some big games to look forward to, including the much-anticipated Resident Evil 4 remake, and Team Ninja’s latest Soulslike, Wo Long: Fallen Dynasty. On the indie front, players can look forward to the visually-impressive open-world Soulslike Bleak Faith: Forsaken, charming narrative puzzler Storyteller, and more.

Note: While I may have played demos or got early access to some of the games recommended in this article, in most cases I’m simply choosing games that look promising, and can’t vouch for the end product. Do wait for reviews before buying!

That said, here are the games you should be looking out for in March…

The Headliners

Wo Long: Fallen Dynasty (PC, Xbox One, Xbox Series X/S, PS4 & PS5, March 3)

Were you a fan of Team Ninja’s Nioh games? Looking for more punishment? Well, it doesn’t seem like a new Nioh is coming any time soon, but Team Ninja’s Wo Long: Fallen Dynasty is the next best thing. Another hardcore Soulslike packed with packed demonic enemies, Wo Long relocates the action from Japan to feudal China and introduces some new elements, like character creation and a greater focus on environmental traversal. This one doesn’t exactly reinvent the wheel, but I’m sure there are plenty of Nioh fans that will be perfectly alright with that. Here's everything you need to know about the game. You can pre-order Wo Long: Fallen Dynasty here.

Bayonetta Origins: Cereza and the Lost Demon (Switch, March 17)

PlatinumGames always zigs when you expect them to zag. Following on the heels of the excellent Bayonetta 3, the new isometric action-adventure Bayonetta Origins: Cereza and the Lost Demon weaves a downright wholesome storybook tale while focusing more on unique mechanics, exploration, and puzzle solving than the franchise’s usual high-intensity action. I’m not exactly sure what audience Bayonetta Origins is being made for, but I’ve had the opportunity to tackle the game’s early hours, and it shows promise. You can pre-order Bayonetta Origins: Cereza and the Lost Demon here.

WWE 2K23 (PC, Xbox One, Xbox Series X/S, PS4 & PS5, March 17)

Time to get your jorts out of the closet, because WWE 2K23 is almost here, and this time it’s all about the Hustle, Loyalty, and Respect. Yes, John Cena is the cover star, and WWE 2K23’s new showcase turns the tables as you’ll be tasked with defeating Super Cena in a variety of his most memorable matches. Other new features, like the WarGames match and a women’s career mode have also been added. I had an opportunity to go hands-on with an early version of WWE 2K23 and came away optimistic about its refined action and new features. You can pre-order WWE 2K23 here.

Resident Evil 4 (PC, Xbox Series X/S, PS4 & PS5, March 24)

Since Capcom embarked on their latest slate REmakes, a new version of Resident Evil 4 has been the dream of many fans, and now it’s almost here. Capcom is remaining surprisingly true to the original, bringing back the spin-kicks and action-movie tone, some of the goofier characters, and even less popular sections like the Island. That said, they are modernizing things as well – in addition to an obvious huge graphical update, you can expect a more character-driven story, levels designs that offer more player freedom, and a new parry system that replace dated quick-time events. Here’s everything you need to know about the remake. You can pre-order Resident Evil 4 here.

MLB The Show 23 (Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 28)

Major League Baseball Opening Day is just a bit over a month away, so, of course, that means MLB The Show 23 is also on the way to help kick things off. Expect the usual solid hardball experience, with some further tweaks to gameplay, a new Storylines mode, and more. You can pre-order MLB The Show 23 here.

Promising Indies

King of the Castle (PC, March 2)

King of the Castle is a new social party game, where royal politics are the only thing that are “sus.” One player takes on the role of the King of the land, while up to 24 others will play as members of your court via their PC, phone, or other devices. Basically, this looks like a simplified version of Crusader Kings, except with AI replaced by real people who are even more eager to stab you in the back. Here’s the Steam page for King of the Castle.

Figment 2: Creed Valley (PC, Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 9)

What if the Psychonauts games were isometric action-adventures instead of platformers? That’s basically the premise for the Figment series, which task players with puzzling and fighting their way through colorful worlds set inside the human mind with a particular focus on music. Figment 2: Creed Valley looks to deliver more mind-bending fun, with new features like co-op, musical boss fights, and more. Here’s the Steam page for Figment 2: Creed Valley.

Bleak Faith: Forsaken (PC, Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 10)

There are certainly no shortage of indie Soulslikes out there, but Bleak Faith: Forsaken looks more promising than most. Featuring impressive visuals, an in-depth class and perk system, and a full-on open-world to explore, Bleak Faith may be something to keep you busy while you wait for that Elden Ring expansion. Here’s the Steam page for Bleak Faith: Forsaken.

Storyteller (PC & Switch, March 23)

Storyteller is a unique (and adorable) narrative-driven puzzle game. Players are tasked with assembling specific stories using simple object and character icons, which will react in different ways depending on how you place them. The stories you’ll be recreating are classics of literature and myth, from Dracula, to Oedipus, to Romeo & Juliet, and you’re free to have some fun and rewrite the tales as you see fit. Here’s the Steam page for Storyteller.

Terra Nil (PC, March 28)

City builders are a dime-a-dozen, but Terra Nil takes the tools of Sim City and its imitators and does something very different with them. Rather than paving over nature, your goal is to take a desolate piece of land and bring it back to life by purifying the soil and creating the right conditions for plains, wetlands, beaches, rainforests, fields of wildflowers, and more. Build and feel good about it too. Here’s the Steam page for Terra Nil.

Full List of Games Worth Watching in March:

King of the Castle (PC, March 2)

Meg's Monster (PC, Xbox Series X/S & Switch, March 2)

Wo Long: Fallen Dynasty (PC, Xbox One, Xbox Series X/S, PS4 & PS5, March 3)

Melon Journey: Bittersweet Memories (PC, March 7)

Romancelvania (PC, Xbox Series X/S & PS5, March 7)

Paranormasight: The Seven Mysteries of Honjo (PC, March 8; Switch, March 9)

Caverns of Mars: Recharged (PC, Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 9)

Clash: Artifacts of Chaos (PC, Xbox One, Xbox Series X/S, PS4 & PS5, March 9)

Figment 2: Creed Valley (PC, Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 9)

Monster Energy Supercross - The Official Videogame 6 (PC, Xbox One, Xbox Series X/S, PS4 & PS5, March 9)

Oni: Road to Be The Mightiest Oni (PC, PS4, PS5 & Switch, March 9)

Bleak Faith: Forsaken (PC, Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 10)

Mato Anomalies (PC, Xbox One, Xbox Series X/S, PS4 & PS5, March 10)

The Legend of Heroes: Trails to Azure (PC, PS4 & Switch, March 14)

The Dark Pictures: Switchback VR (PS VR2, March 16)

Bayonetta Origins: Cereza and the Lost Demon (Switch, March 17)

WWE 2K23 (PC, Xbox One, Xbox Series X/S, PS4 & PS5, March 17)

Deceive Inc. (PC, Xbox Series X/S & PS5, March 21)

Tchia (PC, PS4 & PS5, March 21)

Storyteller (PC & Switch, March 23)

The Crown of Wu (PC, PS4 & PS5, March 24)

EA Sports PGA Tour (PC, Xbox Series X/S & PS5, March 24)

Resident Evil 4 (PC, Xbox Series X/S, PS4 & PS5, March 24)

9 Years of Shadows (PC, March 27)

Crime Boss: Rockay City (PC, March 28)

MLB The Show 23 (Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 28)

Terra Nil (PC, March 28)

Dredge (PC, Xbox One, Xbox Series X/S, PS4, PS5 & Switch, March 30)

Ravenbound (PC, March 30)

The Great War: Western Front (PC, March 30)

Total Tank Generals (PC, March 30)

And those are the games you should be keeping an eye on this coming month. What games are you planning to pick up in March? Did I miss anything you’re looking forward to?",Gaming
https://wccftech.com/download-ios-16-4-ipados-16-4-watchos-9-4-and-tvos-16-4-beta-2-released-to-developers/,"Download: iOS 16.4, macOS 13.3, watchOS 9.4, And tvOS 16.4 Beta 2 Released To Developers","Apple has decided to seed the second beta of its forthcoming iOS 16.4, iPadOS 16.4, macOS 13.3, watchOS 9.4, and tvOS 16.4 to developers. The latest beta builds are available for all compatible Apple devices and can be downloaded for free through the Apple Developer Center. If you are a registered developer, be sure to check out the latest beta. Check out what you should expect with the new builds.

Registered developers can now download iOS 16.4, iPadOS 16.4, macOS 13.3, watchOS 9.4, and tvOS 16.4 beta 2 on their compatible Apple devices

As mentioned earlier, you can download the latest iOS 16.4 and iPadOS 16.4 beta 2 from the Apple Developer Center. Make sure that you install the proper configuration profile. Once you do that, the beta update will be available through the stock Settings app on your iPhone or iPad. iOS 16.4 and iPadOS 16.4 will bring new emojis to the mix along with Safari Web Push notifications and much more.

macOS Ventura 13.3 can be installed on compatible Macs using a profile that can be downloaded from the Developer Center. The update will be available in the Software Update mechanism in System Settings. Much like iOS 16.4, macOS 13.3 will bring new emojis to the table along with support for new HomeKit architecture.

watchOS 9.4 can be downloaded on compatible Apple Watch models through a profile that can be installed through the Developer Center. Once the developer profile is installed, simply head over to the dedicated Apple Watch app on your iPhone and navigate to General > Settings to install the latest update. Apple advises users to keep the wearable plugged in, and it should have more than 50 percent of battery. Additionally, your Apple Watch should be close to the iPhone for the installation process to take place.

If you are enrolled in Apple's developer program, you can also test the latest tvOS 16.4 update. tvOS updates do not usually bring a lot to the table apart from performance improvements and bug fixes, but you are welcome to explore the hidden code. You can download the latest beta by installing the profile using Xcode.

This is all there is to it, folks. Are you experiencing issues with iOS 16.3.1? Let us know in the comments below.","Software, Mobile"
https://wccftech.com/guild-wars-2-brings-new-content-and-rewards-in-new-expansion-available-now/,Guild Wars 2 Brings New Content and Rewards in New Expansion; Available Now,"A new eevent for Guild Wars 2 has been made publicly available for all adventurers in the region of Cantha. In it, players get to experience an adventure in which players have to discover the secrets lurking beneath the Jade Sea. This new expansion will be available for all players who own the End of Dragons expansion for the game and it will include new rewards, a new story, and a new map for players to parttake in.

If you want to see a trailer that shows all the new expansion for Guild Wars 2 has to offer, you can check it out below:

The Guild Wars 2 story event ""What Lies Beneath"" is a new event for the End of Dragons expansion owenrs that will begin today. In it, players rejoin the Commander and their allies as Cantha recovers from the events that took place in the End of Dragons expansion. The new content will be free for all players who own the expansion and feature new rewards, new story, and a new map called the Gyala Delve. This location will also feature the map-wide meta event The Jade Crisis.

This new event has players exploring the depths of the Jade sea after the Commander, and their allies are given reports of strange behavior at a dig site of the Jade Brotherhood miners. Once there, the party discovers the effects of a mysterious illness that could threaten the hard-won stability of Cantha. Players will have to coordinate their efforts in a brand new map-spanning meta event to combat this new threat and ultimately discover the source of the sickness.

Fortunately, unnerving insights are not the only thing that players will hope to gain from Gyala Delve. As players coordinate their efforts in a brand new map-spanning meta event to combat a new threat, they will also receive new , rewards including a new Luxon weapon set, a holographic cape, and the Grinning Tahkayun Mask. All of them will offer players new and thematic ways to outfit their characters in Canthan style.

Additionally, these skins and other achievements will be available for players through gameplay. Of course, there's always going to be some degree of risk involved. But at this point, Guild Wars 2 players should know what they're in for. The update will certainly reward the bold souls that dare to try and face off against this new challenge and find the source of the illness. The What Lies Beneath event for Guild Wars 2 is now available for free for all players who own the End of Dragons Expansion.",Gaming
https://wccftech.com/destiny-2-lightfall-out-now-root-of-nightmares-raid-details-release-date/,"Destiny 2: Lightfall Expansion Out Now, “Root of Nightmares” Raid Detailed and Dated","The teasing and anticipation have finally come to an end, as the big Destiny 2: Lightfall expansion launches today. For those who haven’t been keeping up, Lightfall offers up some major story beats, as the long-teased big bad The Witness arrives, setting up the conclusion of the Light and Darkness saga that’s run through the entire series. Players can also look forward to visiting the neon-drenched Cyberpunk-flavored Neptunian city of Neomuna, mastering the new Stand subclass, taking on the new Terminal Overload activity, and more. You can get more details on what Lightfall includes, right here.

Destiny 2: Lightfall launches alongside the free Season of Defiance (the 20th season overall), will take players back to Earth to repel an invasion by Calus’ forces and engage in various activities and challenges. You can check out a new trailer for Season of Defiance, below.

Here’s a bit more information on what’s included in Season of Defiance…

Defiant Battlegrounds – In this new three-player activity, Guardians will bypass the Shadow Legion’s security by entering their outposts via the Ascendant Plane. Navigate the abyss and find missing captives by completing rituals that open the gateway to safety.

– In this new three-player activity, Guardians will bypass the Shadow Legion’s security by entering their outposts via the Ascendant Plane. Navigate the abyss and find missing captives by completing rituals that open the gateway to safety. Vanguard Ops Playlist Update – Now featuring Heist Battlegrounds and PsiOps Battlegrounds, the updated Vanguard Ops playlist will include refreshed versions of two strikes: The Arms Dealer and Lake of Shadows.

– Now featuring Heist Battlegrounds and PsiOps Battlegrounds, the updated Vanguard Ops playlist will include refreshed versions of two strikes: The Arms Dealer and Lake of Shadows. Guardian Games 2023 – The annual clash of Guardian classes arrives in May and is free for all Destiny 2 players. Hunters, Warlocks, and Titans will compete to complete events, bank medallions to receive great rewards, earn a commemorative statue in the Tower, and have bragging rights for a full year.

Bungie has also revealed first details of Destiny 2’s next raid, Root of Nightmares. You can check out a teaser image for the raid along with a quick description…

“Shortly after the launch of Lightfall, Bungie will unlock its latest raid, Root of Nightmares. […] The Root of Nightmares will launch for all Lightfall players on March 10 at 9am PT. With the launch of the raid, Bungie will also kick off its worldwide competition to crown the first fireteam in the world to complete the raid. The confirmed winning fireteam will win one-of-a-kind World First title belts for each fireteam member along with the glory of being awarded the World First title. Look for the official announcement of the winning World First team in the days following the launch of the raid.”

Destiny 2: Lightfall and the accompanying Season of Defiance are available now on PC, Xbox One, Xbox Series X/S, PS4, and PS5. As mentioned, the Root of Nightmares raid launches on March 10. What do you think? Has Bungie’s latest expansion piqued your interest?","Gaming (AAA), Gaming"
https://wccftech.com/usb-c-on-iphone-15-will-limit-data-speeds-on-cables-without-mfi-certification-compatible-accessories-underway/,"USB-C On iPhone 15 Will Limit Data Speeds On Cables Without MFi Certification, Compatible Accessories Underway","Apple will launch the new iPhone 15 and iPhone 15 Pro models later this year with a wide range of new features and forward-facing changes. The devices are finally adopting USB-C after years of feedback from users. While it is great news, there is a catch that you should know of. The USB-C port on iPhone 15 will limit data transfer speeds with cables that are not MFi certified. What this means is that the accessories need to be compatible with Apple's standards in order to take full advantage of the port.

Non-MFi accessories will not be able to take full advantage of the iPhone 15's USB-C port, Foxconn has already started production of compatible accessories

You might have come across a message on your iPhone that says, ""This accessory is not supported."" Well, the Made for iPhone or MFi accessories come with a dedicated chip that confirms if the accessory meets the company standards. You will be presented with a prompt telling you that the accessory is not supported if it is made by third-party sellers. Apple has adopted the approach for more than a decade now, and it will be brought forward with a USB-C port on the iPhone 15.

Despite Apple's goodwill to bring USB-C to its iPhone lineup later this year, not all cables will be compatible to transfer wired data at maximum speed. You will have to buy an MFi cable or any other accessory with the standard to make use of the USB-C port's full potential. It was coined by ShrimpApplePro that this year's iPhone 15 models will come with USB-C with MFi. Furthermore, Apple's main supplier Foxconn has already begun the production of MFi-compatible accessories.

Much like how Apple stops signing older iOS builds so users can enjoy the latest features and security updates, the chip that authenticates accessories encourages users to purchase original add-ons. Furthermore, it is also easier to distinguish between genuine and fake accessories. While there are pros, non-MFi accessories will not only limit the data transfer speed but also cap the iPhone's charging speed.

Another important aspect to note is that the entire iPhone 15 lineup will adopt a USB-C port, but only the iPhone 15 Pro models will feature USB 3.2 or Thunderbolt 3 support, according to analyst Ming-Chi Kuo. The standard models will stick to USB 2.0, which is another differentiating factor from Apple between the two models. Apple wants the 'Pro' models to keep a distance from the standard models, so it could position them as high-end phones with exclusive features.

Take note that it is too early to draw final conclusions since the final word rests with Apple. We will keep you guys updated on the latest as soon as further details are available.",Mobile
https://wccftech.com/diablo-iv-beta-pc-requirements-ray-tracing-post-launch/,"Diablo IV Beta PC Requirements Revealed, Ray Tracing Not Coming Until After Launch","Get ready to go back to hell, because the Diablo IV open beta kicks off next month on both PC and consoles, and today Blizzard provided some new details about what to expect. The beta will come in two phases, early access and the full open beta, with the former offering access to Barbarian, Rogue, and Sorcerer, and the latter letting you play as the full roster of five classes. Players will be able to tackle the World Boss Ashava, and team up via 4-player online co-op or 2-player couch co-op on consoles. You’ll be able to create up to 10 players during the beta, and yes, progress will carry over to the full version of the game.

Blizzard’s Diablo IV team also touched on some other topics, including the game’s armor system, strongholds, and more during a lengthy developer livestream, which you can check out here (provided you have around an hour to spare). You can also check out the latest trailer showcasing Diablo IV's new open-world Sanctuary here.

Looking to jump into the Diablo IV beta on PC? Blizzard has shared the following very reasonable Minimum and Recommended PC requirements:

Minimum Requirements

Operating System: 64-bit Windows 10

Processor: Intel Core i5-2500K or AMD FX-8100

Memory: 8 GB RAM

Graphics: NVIDIA GeForce GTX 660 or AMD Radeon R9 280

DirectX: Version 12

Storage: SSD with 45 GB available space

Internet: Broadband Connection

Performance: 720p native resolution, low graphics settings, 30fps

Recommended Specifications

Operating System: 64-bit Windows 10

Processor: Intel Core i5-4670K or AMD R3-1300X

Memory: 16 GB RAM

Graphics: NVIDIA GeForce GTX 970 or AMD Radeon RX 370

DirectX: Version 12

Storage: SSD with 45 GB available space

Internet: Broadband Connection

Performance: 1080p native resolution

It was also noted during the livestream, that ray tracing will not be available during the beta, and instead will be added to Diablo IV post-launch.

Here are the times for the Diablo IV early access and open betas. Those who pre-order Diablo IV get into the early access beta:

Early Access to the Open Beta begins March 17 at 9am PT and end March 20 at 12pm PT

Open Beta begins March 24 at 9am PT and ends March 27 at 12pm PT

Diablo IV launches on PC, Xbox One, Xbox Series X/S, PS4, and PS5 on June 6. So, what do you think? Will you be jumping into the open beta next month?","Gaming (AAA), Gaming"
https://wccftech.com/starfield-xbox-exclusive-call-of-duty-not-reason-spencer-pull-something-away/,Starfield Xbox Exclusive while CoD isn’t as Spencer Wants to Avoid “Pulling Something Away”,"Ever since Microsoft began their recent gaming studio shopping spree, the company’s policy on exclusives have been a bone of contention. As Microsoft tries to get their proposed $69 billion dollar acquisition of Activision Blizzard past regulators, they’ve been swearing up and down that Call of Duty will remain multiplatform, but at the same time, they’re insisting Bethesda’s Starfield will be an Xbox exclusive. Realistically, there are practical reasons why Starfield is exclusive while CoD isn’t, but still, it feels like Microsoft’s approach is somewhat scattershot at this point.

Well, in a new Xbox On interview, Phil Spencer seemed to be circling a more definitive answer about where Microsoft stands on the exclusivity question when asked about Starfield. Per Spencer, it all comes down to whether Microsoft is “pulling something away” from players on other platforms…

""I never said Starfield wouldn't be exclusive to Xbox. I think what I said is we're going to take it on a case-by-case basis. We're not going to pull games that are on other platforms. [...] Exclusive titles in the console space is part of the business. All platform-holders do it. They are marketing beats for the platform. Our competitors have a lot of exclusive games.

So, when we're launching new games, there are certain games that we're going to make... 'exclusive' for us is always a little bit hard, because we ship everything on PC as well, but let's just say, ship on Xbox, PC, and playable on cloud, and some of those won't be available on other competitive platforms.

There's no example in Bethesda of us pulling something away from the PlayStation community, that they had. Or of games people are playing, us not continuing to update those. Same thing with Minecraft, Minecraft Dungeons, and we'll do the same thing with [Minecraft] Legends when it comes out.""

So, making Call of Duty exclusive would be pulling it away from PlayStation fans, so they won’t do that, but Starfield is a new IP, so it’s fair game to make it an exclusive. That makes sense, but one wonders how far Spencer is willing to extend that thinking. The Elder Scrolls has traditionally been multiplatform. So has Doom. So, will The Elder Scrolls VI or the next Doom be on PlayStation in the name of not pulling something away from players? Of course, once the Activision Blizzard acquisition passes (or falls through) and Spencer can speak a little more clearly about his plans, perhaps we’ll get a more definitive answer on this.

What do you think Microsoft’s approach to exclusives will be going forward? Are they going to be generous or are Call of Duty and Minecraft going to be the exceptions to the rule?",Gaming
https://wccftech.com/fallout-76-update-adds-season-12-mutated-public-events-and-daily-ops-improvements/,"Fallout 76 Update Adds Season 12, Mutated Public Events, and Daily Ops Improvements","Yesterday, Bethesda Game Studios announced the release of a new Fallout 76 update, weighing around 24/25 GB on PlayStation, Xbox, and Microsoft Store PC, while PC Steam players must download around 14 GB and a half.

The highlight of the latest Fallout 76 update is the so-called 'Mutation Invasion', where mutators that players know from the Daily Ops missions are now also infecting Public Events in the open world. At the top of every hour, a Mutated Public Event will appear on the map, marked with a unique icon to better distinguish it from the regular Public Events. As you would expect, Mutated Events pose greater challenges but also provide greater rewards when successfully completed.

Such rewards include bonus currency, XP, Legendary Items, Treasury Notes, and a Mutated Package. The latter item features ammunition, stimpaks, resources, a three-star Legendary Item and, if you're lucky, also a rare plan usually dropped from different quests or events.

Even greater rewards are available in Mutated Public Events when at least three participants have an active Fallout 1st subscription. In that case, everyone participating in the event gets a Mutated Party Pack, which is an enhanced version of the Package with more rewards and a higher chance to drop the rare plans.

This new Fallout 76 patch also delivers some improvements to the Daily Ops missions, such as the new Reflective Skin mutator (where enemies get a temporary buff that reflects some of the damage done to them), a new encounter group (Aliens!), three new locations, and the following new plans for rewards: Floater Tubes (Gnasher, Freezer, and Flamer Variant), Hot Rod Handmade Skin, Flatwoods Monster Tube, Deep-Space Alien Power Armor skin and Jetpack.

Last but not least, Season 12 is now active in Fallout 76, themed around Rip Daring and his Cryptid Hunt. Players will find appropriately themed rewards and C.A.M.P. items, and there's also a new ally to recruit, Brother Steven from the Mothman cult. Moreover, the developers added a feature to re-roll one Daily or Weekly challenge per day; additional re-rolls can be unlocked by going through the Season 12 scoreboard.

After a shaky start, Fallout 76 found its footing and eventually reached 13.5 million players as of the end of last year. That number has certainly grown further since the game was included as part of the PS Plus subscription last month. As a reminder, about a year ago, Double Eleven announced that it is contributing to the development of Fallout 76, likely because Bethesda Game Studios devoted a greater number of developers to the upcoming launch of Starfield.",Gaming
https://wccftech.com/oneplus-11-fails-the-durability-test-as-it-cracks-while-being-bent/,OnePlus 11 Fails The Durability Test As It Cracks While Being Bent,"OnePlus phones, for the most part, are excellent value for money. Sure, they are no longer the flagship killers they were once known for, but that does not mean that the phones are not worth it. For instance, the OnePlus 11 manages to undercut most of the flagships in the market by being one of the more affordable flagship phones with top-tier specs.

The OnePlus 11 becomes the third phone in the series to bend, but this one does not completely break

However, the one thing that has been consistent with OnePlus phones is durability. If you remember, the OnePlus 10 Pro and 10T did not survive the durability test and got shattered pretty horribly. One would assume that the company has gone back to the drawing board with OnePlus 11 and improved the build quality, but it seems that is not the case.

JerryRigEverything, our favorite phone executioner, decided to try his durability test on OnePlus 11. While deeper grooves were indeed found at a level 7, the phone failed to survive the bend test and well, cracked. You can have a look at the video below:

Although the OnePlus 11 does not break the same way as its predecessor but bending the phone does crack the glass near the camera ring, and further pressure cracks the rest of the glass panel, as well. Showing that the phone is clearly not bend-proof. Before you decide you no longer want to get your hands on this phone, it is worth noting that this entire durability test is not as realistic, but does give a good idea of just how far a phone can go.

The silver lining here is that the OnePlus 11 still manages to survive the bend test, even though you are going to need a new glass panel, and I doubt that the frame still has the same structural integrity as it did before it was bent. Call it a cheap repair, but this is certainly not acceptable for a phone that costs $699. There was a time when OnePlus phones had solid build quality and wouldn't bend. Remember the OnePlus 8 Pro?

Although the OnePlus 11 seems like a phone durable enough for day-to-day use, if you are the type of user who believes in using their phone roughly or in harsh conditions, then I'd advise you to use a case to prevent any damage to the phone.

How is your experience with your OnePlus 11 going? Let us know in the comments below.",Mobile
https://wccftech.com/genshin-impact-3-5-update-is-now-live-introduces-new-characters-quests-and-more/,"Genshin Impact 3.5 Update Is Now Live; Introduces New Characters, Quests And More","A new Genshin Impact update is now live on all formats, introducing new content to the popular game developed by miHoYo, such as new characters, weapons, and quests, as well as adjustments and optimizations.

The 3.5 update, whose full patch notes can be checked out here, introduces new 5-Star Character ""Flame-Mane"" Dehya and 4-Star character ""Coordinates of Clear Frost"" Mika of the Pyro and Cryo vision, respectively. Armed with a Claymore and a Polearm, the two characters are able to unleash powerful Elemental Skills that will make short work of many different enemies.

The new Genshin Impact update also introduces two new weapons, the Beacon of the Reed Sea 5-Star Claymore and the Mailed Flower 4-Star Claymore, the new Archo Quest Chapter III: Act VI ""Caribert"", the Dehya’s Story Quest – Mantichora Chapter: Act I “Lionsblood”, a new Handgout Event, new enemies, new recipes and several adjustments and optimizations that improve the experience.

Genshin Impact is now available on PC, PlayStation 5, PlayStation 4, iOS, and Android worldwide. A Nintendo Switch version is currently in development, but no release date has been confirmed. You can learn more about the game by checking out Nathan's review.

Genshin Impact is a remarkable game in many respects, boasting vibrant visuals, a rich, sprawling world, deep systems, and finely-tuned action. Unfortunately, the game’s free-to-play gacha business model often undermines its own sense of adventure and excitement. Genshin Impact is a good -- potentially great -- game locked in a loot box it can’t quite escape.",Gaming
https://wccftech.com/zhihui-micro-develops-14nm-idm929-gpu-for-domestic-chinese-market-aiming-for-gtx-1650-performance/,"Zhihui Micro Develops 14nm IDM929 GPU For Domestic Chinese Market, Aiming For GTX 1650 Performance","Chinese GPU maker, Zhihui Microelectronics, has revealed its first GPU that is reported to perform equal to the NVIDIA GeForce GTX 1650.

Zhihui Micro reveals a new IDM929 GPU built on the 14nm process and aiming for GTX 1650 performance

The new IDM929 GPU utilizes the company's proprietary IDMV architecture, instruction set, and compiler. The new IDM929 has a compute performance of 2.5 TFLOPS, a texture fill rate of 76.8 GTexel/s, and a pixel fill rate of 19.2 GPixels/s.

The GPU clock frequency only reaches 1.2 GHz, which is unusual for a 14nm CMOS process-based product, but the company assures that this new chip's performance is eight times higher than its initial design. The new GPU chip is created on the 14nm process technology. It is speculated that the new chip is manufactured by Semiconductor Manufacturing International Corporation (SMIC).

The general-purpose GPU taped out this time — IDM929 has three major advantages: high computing power, high versatility , and high energy efficiency. The product supports 4K ultra-high-definition display , 4 independent display outputs, HDMI, VGA and DVI interfaces, and hardware codes in H264 , MPEG2, MPEG4, VC-1, DivX and VP6 formats . At present, IDM929 has completed internal tests with a variety of domestic CPUs and domestic operating systems , and will meet the application requirements of desktop office, graphics workstation, geographic information system and high-performance computing .

There is not much information from Zhihui Microelectronics about the new IDM929 GPU. Still, the compute performance is anticipated to be similar to the GTX 1650 from 2019 which offered around 3.0 TFLOPs of compute power while using the TSMC 12nm process node.

The press release said that Hangzhou Guoxin Technology is the leading investment company for Zhihui Microelectronics, which develops SoCs for intelligent televisions. The new IDM929 chip may find similar use in home and office electronics.

The IDM929 is the successor to the IDM919 commercial GPU chip launched in 2020. On the Zhihui Microelectronics website, there is also a listing for the IDM939, and the company has released no information about the product, only listing that it is currently in development. It will be interesting to see what the successor to the company's IDM929 will perform based on the information that they have provided about its newest GPU chip.

You can read the press release from Zhihui Microelectronics on the company's official website and stay up to date with the newest offerings from Zhihui Microelectronics.

News Sources: Zhihui Microelectronics, Tom's Hardware,","Press Release, Hardware"
https://wccftech.com/wild-hearts-1-05-update-is-now-live-on-pc-and-consoles-slightly-improving-performance-on-pc/,"Wild Hearts 1.05 Update Is Now Live On PC And Consoles, Slightly Improving Performance On PC","[Update] The Wild Hearts 1.05 update notes are now available, detailing the fixes and changes introduced by the update. You can find them here.

[Original Story] A new update is now live for Wild Hearts, the hunting game developed by EA, Koei Tecmo and Omega Force released last month on PC and consoles, introducing light performance improvements on PC and more.

The new 1.05 update, which is also live on consoles, is a rather small update, weighing at around 850 MB, went live without official notes, so we do not know exactly what it does yet. From some quick testing, the update brings some light performance improvements on PC that are, unfortunately, still not enough, as the game still suffers from major stuttering and generally unstable performance. We will update this post with the official update notes as soon as they become available.

It is a shame that Wild Hearts launched in such a state, as I have found the game to be a compelling experience that can rival the Monster Hunter series. While gameplay generally doesn't have the same level of depth seen in the CAPCOM series, with its unique Karakuri mechanics, Wild Hearts is a great starting point for a franchise that could reach some incredible heights, as I highlighted in my review.

Wild Hearts couldn't have been a better start for a new IP. While the experience shares more than a few similarities with that of the Monster Hunter series, the unique monster design, the great weapon variety and the Karakuri crafting mechanics give the game a unique flavor that makes it stand out easily among similar games. Performance issues, sadly, impact the experience considerably on all formats, preventing it from reaching greater heights, but even in its current state, the game is a more than worthy purchase for fans of the genre.

Wild Hearts is now available on PC, PlayStation 5, Xbox Series X, and Xbox Series S worldwide. We will let you know more about the game's future updates as soon as possible, so stay tuned for all the latest news.",Gaming
https://wccftech.com/teamgroup-unveils-ddr5-6800-overclockable-r-dimm-memory-with-ecc-support/,Teamgroup Unveils DDR5-6800 Overclockable R-DIMM Memory With ECC Support,"Teamgroup has also announced its overclockable DDR5-6800 RDIMM memory which features ECC support on Intel's W790 platform.

Intel W790 Ready DDR5-6800 RDIMM Memory With Overclocking Support Released By Teamgroup

Press Release: Leading memory provider TEAMGROUP today has announced a breakthrough in specs for its newest DDR5 ECC R-DIMM memory module, which has an increased clock rate of 5,600MHz, meeting the JEDEC standard for high-performance specifications.

In addition, the company has collaborated with well-known motherboard manufacturer ASRock to complete compatibility testing on HEDT platforms equipped with Intel 4th Gen Xeon processors, codenamed Sapphire Rapids, and W790 motherboards. The memory module not only fully supports XMP3.0, but it is also the overclocking DDR5 ECC R-DIMM memory in the market today with the highest clock rate of 6,800MHz.

Sapphire Rapids is Intel's first server processor to support DDR5 ECC R-DIMM memory. When it’s paired with the next-generation W790 workstation motherboard, users can adjust the CPU's overclocking settings in BIOS and enable the clock speed adjustment feature of DDR5 ECC R-DIMM memory.

Having undergone strict compatibility and stability testing, the JEDEC-compliant, high-frequency memory comes in both 16GB and 32GB capacity variants to meet the demand for workstation upgrades. The memory is also available in 6,400MHz and 6,800MHz models with XMP3.0 support, providing next-gen HEDT platforms with cutting-edge performance.

To meet the diverse needs of HEDT workstation applications, DDR5 ECC R-DIMM memory is designed with 30µ gold fingers, features dual ECC, and is equipped with a high-precision temperature sensor to increase endurance and reduce thermal issues during overclocking. TEAMGROUP is committed to creating the highest-quality products and offering innovative and diverse storage and memory solutions. As platform technologies continue to evolve, the company will work hand-in-hand with consumers around the world to create a new generation of high-speed DDR5 memory and provide revolutionary breakthroughs.","Press Release, Hardware"
https://wccftech.com/intel-releases-new-driver-to-mitigate-i226-i225-ethernet-controller-issues/,Intel Releases New Driver To Mitigate I226 & I225 Ethernet Controller Issues,"Intel is releasing a new driver to mitigate the connection drop issues faced by customers running boards with I226 & I225 ethernet controllers.

Intel Has A New Driver That Should Mitigate But Not Entirely Fix I226 & I225 Ethernet Controller Issues

Back in January, it was reported that the Intel I226-V Ethernet controller was affected by the same bug that was found within the older I225-V chip. What happened was that the controller randomly dropped the connection and sometimes didn't even make the Ethernet port run on certain PCs. It was an issue most prevalent on the Intel 700-series motherboards which were launched along with the Intel 13th Gen desktop CPU family.

Some customers have recently reported connection drops at random times, specifically on the newly launched 700 series motherboards with Intel Ethernet Controller I226-V. Intel has reproduced the issue and is diligently working on a root cause and fix. For any of our customers experiencing this problem, a mitigation option to explore is to disable the “Energy Efficient Ethernet (EEE)” mode in the Advanced Windows/ Linux driver setting. We believe this should help. We are continuing to assess the situation and will follow-up accordingly. via Intel Community

Intel released a small workaround to mitigate the problem last month and it looks like the same mitigations have now been implemented on the driver level within the new driver package for the 700-series motherboards. As published by MSI's HQ Technical Marketing over in the MSI Gaming subreddit, we can see that the new driver is now available on the product pages of various boards (the following is from the product support page of the MSI MEG Z790 ACE motherboard):

I did a quick check with the new drivers and it seems like the issue has been resolved for now as before, I had to restart the PC to make it work correctly but that wasn't the case with the newest drivers. With that said, it should be noted that mitigation doesn't necessarily mean a proper fix and if the problem is really on the hardware side, then a new revision of the chip must be issued to fully address the problem. Hardware leaker, chi11eddog, reports that Intel is still doing an investigation on the issue and plans to provide a robust solution soon:

Motherboard makers should be updating their product pages with the same driver for the I226 and I225 Ethernet controllers. MSI is definitely the first to offer them so others should follow suit too.","Report, Hardware"
https://wccftech.com/final-fantasy-xvi-developer-interview-new-engine-with-no-forspoken-tech-arcade-mode-global-leaderboards/,"Final Fantasy XVI Developer Interview – New Engine With No Forspoken Tech, Arcade Mode, Global Leaderboards","In the second half of our hands-on preview with Final Fantasy XVI, we had the pleasure of sitting in on a group interview between myself and The Verge's Ash Parrish along with three of the lead designers on Final Fantasy XVI with Michael-Christopher Koji Fox assisting in interpretation. Among those present were Producer Naoki Yoshida, Director Hiroshi Takai, and Combat Lead Ryota Suzuki for an intimate forty-minute session digging into some of the lore and story choices as well as what both RPG and hardcore character action fans can look forward to in Final Fantasy XVI.

Ash Parrish (The Verge): In an interview with IGN, you addressed Final Fantasy XVI’s struggle with diversity. In that interview, you said the homogeneity was chosen on purpose because of the isolated nature of the politics and the world in itself and that was the kind of story you wanted to tell. You wanted to focus on this isolated place [where] people all look this same. We respect that that’s the kind of story that you want to tell but from that interview, there have been a lot of concerns and comments from fans of color that feel a [certain] way about it, thinking that because this place [Valisthea] is based on European history, that automatically defaults it to an ‘All-White’ setting. I wanted to know if you had the opportunity to hear that feedback and what you might want to say to fans of color who are turned away from the game.

Naoki Yoshida: This is a very difficult question and it deserves great care with words and phrasing and nuance. It’s something that means a lot to different people and it can be very nuanced in how different people interpret the situation. I believe that with Final Fantasy XVI, we’ve weaved together a variety of peoples and cultures set in this sweeping fantasy narrative and world that we have strived to create with care and respect, something that’s being done with the Final Fantasy series. We hope that when players finally get able to take up [Final Fantasy XVI] in their own hands, they will be able to see what we have aimed for and will ultimately be able to connect with that unique experience. Other than that, going deep into it is something that we’ve already done and this is what we believe in and that’s all about when players get it into their hands and make that decision for themselves about what they see in the game.

Kai: Over the past decade and a half, Final Fantasy has been trending more in line with modern and futuristic settings. Why the return to High Fantasy for Final Fantasy XVI? And to follow-up: in the West, darker High Fantasy has been a very popular genre over the past few years. Is the story for Final Fantasy XVI reactionary to what’s popular in the West, or has that always been a part of your design philosophy?

Naoki Yoshida: You are correct in your observations that these past three Final Fantasy [titles] have all been very modern, but when you look back at the entire thirty-five-year history of Final Fantasy, more than half of [the titles] when you look back have been High Fantasy and it’s just that it has switched to a modern type of setting. When it came to [deciding] what kind of game to make with Final Fantasy XVI, the reason we chose High Fantasy is that, as creators, it’s the genre that we enjoy.

To your other question about if this was reactionary towards Dark Fantasy in the West, more than that, again, we really like Dark Fantasy as well and that’s what we want to create. The minute that we knew that our team was going to be creating the new Final Fantasy XVI, the first that came to us was that if we were going to be creating it and we are going to spend all of this time and effort doing it, let’s do something that we love and that’s why we chose this genre. And of course, as we were starting [development], dark fantasy was starting to get very popular in the world and this was the perfect time to do this as well.

Ash: I remember that at the beginning of the presentation that elsewhere you wanted Final Fantasy XVI to be a roller coaster and I wanted to know why. It seems like there’s this hard pivot away from the kinds of themes and experiences that fans have come to expect from Final Fantasy. After playing the Eikon battles, [it feels like] somebody woke up and watched Pacific Rim and [decided] to put Kaiju battles into Final Fantasy XVI. I just wanted to know what your thoughts or philosophies were on why you wanted to turn away from what fans would expect.

Naoki Yoshida: It’s not like we went into this thinking that we were going to step away from expectations. For me, I was a fan of the original Final Fantasy and around the same time, the original Dragon Quest had come out. Of course, having played both, I compared them and what I really enjoyed about Final Fantasy was that it felt like a movie. There’s no opening and you’re immediately in the game. Then you cross the Drawbridge and then you get that title screen and it really felt like you were playing in a movie. That was thirty-five years ago and now we have the PlayStation 5 technology where it actually does feel like you’re in a movie and controlling the movie. That’s the thing we wanted to create with Final Fantasy XVI and going back to those Final Fantasy roots.

Just over these past thirty-five years, we’ve seen that Final Fantasy fans are distancing themselves from the series and there aren’t as many people playing the series as time went on. It’s up to us to see how we’re going bring in new players and bring back players that left the series. Creating a game of this scale and scope costs a lot of money and if people aren’t playing your game, you can’t recoup your development costs *laughs*. There is a fear of the series becoming more niche. Final Fantasy has always been about a series where it would come out and everyone would buy it so it’s about bringing those people back and bringing new people in. To do that, the best way was to challenge ourselves and that one idea was to make [Final Fantasy XVI] full action.

Going back to your earlier comment about how it felt like the Kaiju battles in Pacific Rim, the battle that you got to play (Ifrit vs. Garuda), again, was designed to feel like a Kaiju battle that you’d see in Ultraman or Evangelion. But that’s only that battle and that style is only used in that one battle. We have other Eikon vs. Eikon battles that may resemble a 3D shooting game or a high-speed action kind of game. Each of these battles is created from the ground up and they’re all unique with a different type of feel to them. We are going to provide players with a unique experience for each individual battle.

Hiroshi Takai: I don’t think that, or at least it wasn’t our intent, to drift away too far from what the core series brings. We get asked by a lot of media about what we think constitutes a Final Fantasy game. I think that, for me, the one thing is how each game in the series always tries to do something new and challenge something one of the Final Fantasies in the past had done to bring something new to the series. With Final Fantasy XVI, our challenge was to go full action and have these Eikon-vs-Eikon battles. Because this change is so big, that’s what sticks out to players and they feel like it’s bigger than it actually is.

Again, up until now especially with this event, we’ve been putting a lot of focus on the action aspects of the game, but what we have here is an action RPG. Being Square-Enix, we put a lot of pride into our RPG elements. Those RPG elements, while we haven’t talked about them much, do exist in the game; we do have side quests and weapon customizations and things like that. Hopefully, in the near future, we can talk about that and ease the fears that fans feel like Final Fantasy XVI is only action. There is an RPG here as well. If you look at Final Fantasy XVI, one game that is kind of close to how the whole game works is the most recent God of War (2018).

Kai: With this being the first Final Fantasy developed specifically for PlayStation 5, has Luminous Productions assisted Creative Business Unit III with development? Will any of the newer technologies that were in Forspoken, such as DirectStorage, be utilized in Final Fantasy XVI?

Naoki Yoshida: To talk a little bit about business, Forspoken and Final Fantasy XVI began development around the same time. Final Fantasy XVI is actually using an engine we’ve created specifically for Final Fantasy XVI, so there isn’t much sharing of technology between the Forspoken and Final Fantasy teams.

Kai: There are the Timely Accessories that help guide players into Final Fantasy XVI if they’re more used to roleplaying games. Inversely, I wanted to ask if there will be opposite accessories that will make Final Fantasy XVI feel more like a character action game or more difficult for the player.

Ryota Suzuki: There are some accessories that you didn’t get to see in the game today that are more geared toward the action-heavy user.

Naoki Yoshida: The overall game design here is that, first and foremost, we wanted to tell our story. For the first run-through, we want players to focus and experience that story and rollercoaster ride. While we do have a lot of different accessories that enhance the experience for those high-end users, those accessories really shine on the second run-through.

When you clear the game, you’ll have the opportunity to carry that data over into New Game Plus. This means that you’ll have actions and accessories that you earned in late game but will have them at the beginning of the new game and force your way through the game with super strong abilities and actions and take advantage of fun there.

We always have a higher difficulty mode called the Final Fantasy mode which increases the difficulty of the game but also changes enemy placement and brings in high-level enemies into the early game to further challenge players. Again, using that data they’ve carried over [from completing the game once]. On top of that, we have other modes as well. The game is broken up into stages and we have a mode where you can go back and replay stages in what we call Arcade Mode. We’ll have global leaderboards so you can see how you stack up to players across the world.

Hiroshi Takai: Within the Arcade Mode, we have several levels of difficulty and the highest level of difficulty is one of the hardest things that we want to challenge our high-end users to see how far they can get. Speaking back to the Final Fantasy mode, it’s not an exact copy of the game that’s harder. We’ve changed it so that it feels like something new and will challenge the players.

We’re talking a lot about the difficulty and how hard Final Fantasy XVI is but again, we want to focus on that the first run-through is accessible for everyone to be able to complete the game. We’ve made a game where we feel everyone can get through because we’re very proud of our story so don’t worry.

Ash: I wanted to go back to where you said that you wanted Final Fantasy XVI to feel like God of War (2018). One of the things about both God of War titles is that there are a lot of really heartfelt, tender emotional moments in the game. One of the things I’m noticing in all of the media we’ve seen so far is that Final Fantasy XVI is very dark with a lot of blood and conflict and [being] super serious. It doesn’t seem like there’s a lot of space for lightheartedness and fun.

I wanted to know if you were also able to incorporate those moments of levity because I’m thinking of the campfire moment from the end of Final Fantasy XV and things like that. As a follow-up to that, also speaking of God of War, when you were in New Game Plus or after the story was over, you’d have special fights against Valkyries that weren’t accessible in the base game. I’m wondering if Final Fantasy XVI will include that as well and you’ll be able to fight special monsters that you unlock.

Naoki Yoshida: You’ve mentioned that a lot of the stuff so far seems to be very dark and sad and heavy. We’ve done that on purpose because that’s what we wanted to show that Final Fantasy has changed and we’ve gone back in a dark direction. That’s why a lot of what we’ve shown has been dark. One of the reasons that we are doing this is that in the past ten-plus years, Final Fantasy has been about how bright the series is. We still have these dark themes about how we’re going to save the world, but then it’s like we have these teens running around and going fishing even though the world is supposed to be ending. There’s not a sense of reality there.

This is because in the real world, where there’s light, there’s always darkness and that is with the people as well. People are not all good; they’re not all bad. There’s the stuff in between that exists. We wanted to create something that again felt very real and that’s why a lot of our promotion has been focused on it. That said, we understand again that Final Fantasy is about those emotional scenes. It’s about love and bonds, and yes, we do have that in Final Fantasy XVI as well. It’s just that a lot of that is connected directly with a lot of spoilers, so it’s hard to show in promotional material without spoiling.

There’s always the fear that if we show a lot of heartfelt and emotional stuff, we get people that say ‘oh, they’re just doing the same things they’ve done before’. We wanted to show that we’ve shifted in this direction, at least for this [media event].

Hiroshi Takai: Now about the New Game Plus question. Again, Final Fantasy XVI is designed for heavy action users who can have a lot of fun while it’s accessible for players that aren’t good at action games. What we didn’t want was content that was only accessible by only a small group of players. We wanted all of our content to be playable by everyone. In that sense, for that first run-through, again, we have created a story that all of the players will be able to experience the same thing without some players getting things that are only unlockable by someone that’s playing on a certain difficulty level. On that second [playthrough] on Final Fantasy mode, that again unlocks a difficulty that will further challenge players that want an action experience without taking away from the players that just want to play for the story.

Naoki Yoshida: As we mentioned before, we did want to put monsters in the Final Fantasy mode that wouldn’t be accessible to players outside of that difficulty [setting]. When I say difficulty, I don’t just mean the difficulty of the monsters that you face. It’s monster placement and late-game enemies showing up in early-game. It feels different and unique. It’s not just the same mode ramped up in difficulty. It’s a mixture of these different things. It’s not that there are any original bosses, the game will feel completely different the second time through. You’ll have to use certain techniques to beat the bosses and it will be much more challenging.

Kai: To follow up on that, we see a lot of inspiration from Final Fantasy XIV raid and boss fight mechanics in the design philosophy for these fights. I’m curious if we will see some similar design from the Savage tier of encounters [from Final Fantasy XIV] present in the combat.

Naoki Yoshida: Final Fantasy XVI, being a role-playing game, has aspects of leveling up. As you level up, your character gets stronger, your defense gets stronger and you deal more damage with your weapon. The game is based around that if players are not as good technique-wise, as long as they level up their character and get that better gear and use the Timely Accessories, then they’ll be able to enjoy the story.

You’ve mentioned the Savage tier, where you have the monster changing its actions to create a more difficult battle. We don’t have things like that. How we adjust the difficulty is by putting the player in a situation where it’s going to test the player's actions. We cap the level and stop the ability to level up. It becomes a situation where the player has to use their own technique to defeat the battle rather than the RPG parameters from leveling up. It’s really a test of the player’s skills.

Thank you for your time.","Interview, Gaming"
https://wccftech.com/chatgpts-gpu-demand-expected-to-exceed-30000-helping-nvidias-ai-business-boom/,"ChatGPT’s GPU Demand Expected To Exceed 30,000 Helping NVIDIA’s AI Business Boom","ChatGPT's growing demand for GPUs is going to directly benefit NVIDIA which is one of the largest players in the AI market, reports Trendforce.

ChatGPT's Demand For AI GPUs Surges, New Model To Require Over 30,000 NVIDIA GPUs

Previous estimates had put the number of GPUs powering the GPT model around 10-20K but with the new model, OpenAI is expected to utilize way more than that. According to the report, 30,000 is the number that is expected for the latest model that is going to power ChatGPT but it looks like we might see even more demand.

In the case of the Generative Pre-Trained Transformer (GPT) that underlays ChatGPT, the number of training parameters used in the development of this autoregressive language model rose from around 120 million in 2018 to almost 180 billion in 2020. According to TrendForce’s estimation, the number of GPUs that the GPT model needed to process training data in 2020 came to around 20,000. Going forward, the number of GPUs that will be needed for the commercialization of the GPT model (or ChatGPT) is projected to reach above 30,000. Note that these estimations use NVIDIA’s A100 as the basis for calculations. Hence, with generative AI becoming a trend, demand is expected to rise significantly for GPUs and thereby benefit the participants in the related supply chain. NVIDIA, for instance, will probably gain the most from the development of generative AI. Its DGX A100, which is a universal system for AI-related workloads, delivers 5 petaFLOPS and has nearly become the top choice for big data analysis and AI acceleration. via Trendforce

The research firm notes that the demand for AI GPUs is expected to reach beyond 30,000 and that estimation uses the A100 GPU which is one of the fastest AI chips around with up to 5 Petaflops of AI performance. That number can go higher or lower depending on the chips being used but that's going to put a lot of pressure on NVIDIA on whether they want to move their supply to AI GPUs or gaming GPUs.

NVIDIA's CEO, Jensen Huang, has praised OpenAI's ChatGPT tool multiple times, whether during interviews or during their financial earnings call. The company has made a lot of strides in the AI segment with the most recent introduction of the RTX Video Super Resolution which uses the AI prowess of its consumer GPUs to enhance the video and streaming quality across multiple apps. The company's AI tensor cores are being used by game developers and production houses in the form of DLSS 3 for better performance throughput while retaining visual fidelity.

The surge of ChatGPT is definitely going to be a blessing in disguise for NVIDIA as demand for PC hardware slumps due to rising inflation across the globe. At the same time, the demand for more AI power in instances such as ChatGPT can offset the differences in revenue. The industry predicts that NVIDIA can see the demand outstrip the overall supply in the next coming quarters.","Report, Hardware"
https://wccftech.com/amd-3d-v-cache-boosts-rdna-2-igpu-on-ryzen-9-7950x3d-by-over-4x-versus-7950x-cpu/,AMD 3D V-Cache Boosts RDNA 2 iGPU On Ryzen 9 7950X3D By Over 4x Versus 7950X CPU,"AMD's Ryzen 9 7950X3D CPU's integrated GPU seems to get a nice boost in gaming performance thanks to the 3D V-Cache technology.

AMD Ryzen 9 7950X3D's RDNA 2 iGPU Boosted By Over 4x Versus Standard 7950X CPU By 3D V-Cache

The AMD Ryzen 7000 Desktop CPUs come with an entry-level RDNA 2 iGPU that incorporates just 2 compute units or 128 stream processors. These cores run at a base clock speed of 400 MHz and a graphics frequency of 2200 MHz. Offering up to 0.563 TFLOPs of 563 GFLOPs of compute power, these chips deliver slightly better GPU performance than the Nintendo Switch which is rated at 500 GFLOPs.

We have already seen how these chips perform, stock and overclocked, on the standard Ryzen 7000 Desktop CPUs. PCMag took the iGPU on the newly released Ryzen 7000X3D CPUs to the test & the results are very fascinating, to say the least. The benchmarks done in games show a massive 4.3 times performance gain at 720p and up to 4 times at 1080p versus the non-3D V-Cache CPUs.

Games used for testing included F1 2022, Total War: Three Kingdoms, Tomb Raider, and Bioshock Infinite. While these performance figures are still not on par with Intel's iGPUs featured on its own desktop lineup, this radical improvement in performance shows the benefits that 3D V-Cache can bring to APUs.

AMD Ryzen 9 7950X3D iGPU Performance Benchmarks (Credits: PCMag):

2 of 9

We know that AMD's APUs feature some really strong iGPUs or integrated graphics. AMD will be bringing up to 12 RDNA 3 compute units on its latest Ryzen 7040 ""Phoenix"" APU lineup on laptops. While there is no desktop release imminent, we might see a future AMD desktop lineup that also incorporates RDNA 3 or enhanced GPU sub-sections on the same monolithic die. Considering just how bandwidth-starved these iGPUs are, a singular stack of 3D V-Cache such as the ones on Ryzen 7000 X3D parts, can bring some huge performance increases.

Given what we know, the idea of seeing a Ryzen 7000-series APU, a processor with a relatively powerful IGP and the 3D V-Cache together, would be exciting. On the Ryzen 9 7950X, however, this is interesting but not particularly useful. Few folks are likely to buy the Ryzen 9 7950X intending to play games on its IGP. This makes the performance gains technologically intriguing, but mostly just a footnote. via PCMag

AMD Ryzen 9 7950X3D vs 7950X iGPU Tests (via PCMag)

Game Ryzen 9 7950X3D Ryzen 9 7950X Improvement F1 22 (720P) 62 19 3.26x F1 22 (1080P) 33 N/A N/A Total War Three Kingdoms (720P) 34 9 3.77x Total War Three Kingdoms (1080P) 16 4 4.00x Bioshock Infinite (720P) 45 13 3.46x Bioshock Infinite (1080P) 22 7 3.14x Tomb Raider (720P) 26 6 4.33x Tomb Raider (1080P) 15 4 3.75x

The AMD 3D V-Cache technology has so far only been integrated into chiplet processors whereas the APUs utilize a monolithic design approach. Given the efficiency of 3D V-Cache chips for gaming, they can become an awesome platform for laptop gamers. AMD has brought the same desktop die to laptops in the form of Dragon Range ""Ryzen 7045 series"" but no 3D V-Cache implementation of an APU exists.

Once again, if AMD goes that route, it can be a game-changer & I believe that it might already be in consideration by the red team considering Intel's going to bring out its own powerful iGPU architecture known as tGPU (Tiled-GPU) on next-gen Meteor Lake and Arrow Lake chips. The multi-tile and disaggregated chiplet design is supposed to carry powerful iGPUs and may also incorporate a separate cache die that directly benefits the iGPU. To tackle that, AMD has its own 3D V-Cache technology but we will wait to see how long it takes them to incorporate it in future APUs.","Report, Hardware"
https://wccftech.com/google-is-making-esim-transfer-even-easier-on-android-smartphones/,Google Is Making eSIM Transfer Even Easier On Android Smartphones,"One of the best things about modern-day smartphones is the fact that you are getting eSIM capabilities. This ensures that you never really have to use a physical SIM in your smartphone and continue using your phone with full coverage without any issues. However, there are some issues when it comes to changing your device because you cannot just transfer your current eSIM to a new phone whenever you upgrade. Well, Google is bringing a change to Android that will make things better and more straightforward.

Google's new eSIM transfer feature is coming to all Android phones later this year, with Deutsche Telekom being the first carrier to support it

This is not the first time we heard about this. A month ago, it was discovered that Google is working on a feature that will let you transfer your eSIM from your old Android phone to a newer one. While at that time, we didn't know if it will ever see the light of day, Google has finally gone ahead and announced the new feature at MWC 2023.

However, Google has also mentioned that this feature will be coming out later this year, probably with the release of Android 14. But what's more important is that this will also need to be enabled on your carrier's side. The search engine giant has mentioned that the eSIM transfer feature will be offered by Deutsche Telekom as the first company. Once the feature starts rolling out to more carriers, you will have a lot easier time transferring your eSIM from an older phone to a new phone. Google has mentioned that you will no longer need a physical SIM, making the process all the more accessible.

Last but not least, Google has also mentioned how this feature is going to come to all Android devices later this year. We suspect that it will start rolling out with Android 14. The more interesting thing to look forward to is the implementation of this feature by mobile carriers around the world. Whatever the case might be, I am happy that this feature is going to come out soon. As someone who upgrades their phone every year, having the ability to transfer their eSIM without having to jump through hoops is definitely a feature that I am looking forward to.

What do you think about the latest eSIM feature? Let us know how you feel about seamless transfer to new Android phones in the comments below.",Mobile
https://wccftech.com/tiktok-introduces-new-features-to-help-teenagers-curb-their-usage/,TikTok Introduces New Features To Help Teenagers Curb Their Usage,"TikTok is easily the biggest and perhaps the best app if you are talking about short-form video content. Over the past couple of months, the platform has decided to make itself better not just for creators but for everyone using the app. Today, the company has introduced a new bunch of features that will make it easier for teenagers and their family curb the time they spent on the platform. This is a new step in ensuring the platform is safe and does not lead to excessive use.

TikTok does not want you to spend all your time on the platform, and it now has tools to remind you of it

TikTok users who are under the age of 18 are now going to see a daily usage limit that will be on by default. In order to make this possible, TikTok worked with Digital Wellness Lab at Boston Children's Hospital, and the platform will now implement a one-hour limit for teenagers who are under the age of 18. Sure, you can still bypass this and add in more time if you want to watch. However, you will be asked to enter a passcode if you want to watch content for a longer time.

On paper, it might seem like a feature that is not needed. However, being reminded every hour that you have spent this much time on TikTok is a good way to ensure the user thinks again before entering the passcode. Even TikTok believes that by showing a prompt, the app will make users make an active decision, and it is a great way of making people think about how much time they have spent. If you are under the age of 13, however, you will have to ask your parents to authorize it, and by doing so, you will get access to 30 more minutes.

Another new feature is that TikTok wants teens to set a daily screen time limit, especially if they have decided to ignore the 60-minute default and are using the app for over 100 minutes. Not just that, the platform will also send a weekly notification, telling the users about the time they have spent on the platform.

This is certainly a good step by TikTok as it will help people be more aware of what they are doing on the app. Surely, some users might think it is intrusive but considering how short-form videos are addictive regardless of the platform you are watching them on, this definitely is an excellent decision going forward and will help people cut down their usage time.",Mobile
https://wccftech.com/uh-oh-the-sec-has-stealthily-negated-its-own-chief-on-ethereum-status-as-a-security/,"Uh-oh, the SEC Has Stealthily Negated Its Own Chief on Ethereum’s Status as a Security","This is not investment advice. The author has no position in any of the stocks mentioned. Wccftech.com has a disclosure and ethics policy.

In the aftermath of FTX's spectacular fall from grace, the Securities and Exchange Commission (SEC) in the US has amped up its scrutiny of the entire crypto sector, and rightfully so. However, instead of providing clear-cut regulatory clarity, the apex financial regulator has opted for deliberate policy ambivalence as a cudgel to pummel crypto sector bigwigs, including Ethereum. More troubling still, the SEC's chair, Gary Gensler, is now issuing public statements that directly contradict the agency's position enunciated in the courts.

Recently, the SEC forced Kraken exchange to shutter its crypto staking program by alleging that the firm was dealing with ""unregistered securities."" With a vast segment of the crypto sphere having turned toward the staking model as a viable transaction authentication mechanism, including Ethereum, the negative ramifications of such an interpretation from the SEC are obvious.

This week the NYDFS ordered US-based Paxos to stop issuing US dollar-denominated stablecoin BUSD and the SEC issued a Wells notice to Paxos. We don’t know what aspects of BUSD might be of interest to the SEC.

What we do know: stablecoins are not securities 🧵 — Coinbase (@coinbase) February 15, 2023

Moreover, the SEC has also gone after the Binance USD (BUSD), a stablecoin that is issued by Paxos under a license arrangement with Binance. In both instances, the SEC has taken a position that the parties involved were dealing in unregistered securities.

For the uninitiated, the famous Howey test is used in the US to determine whether a financial instrument constitutes a security. This test has four main elements:

Investment of money

In a common enterprise

With the expectation of profit

Where such profits are derived from the efforts of others

Experts, however, have rightfully panned SEC's position in both instances. First, staking services for Ethereum and other coins do not constitute an investment of money. Instead, the stakers simply lock up a specific portion of their holdings in dedicated nodes with the understanding that they would forgo any claim to the staked coins if caught acting in bad faith. In return, these stakers win the opportunity to try to authenticate incoming blockchain transactions, receiving pre-determined staking rewards as consideration. As such, this consideration is not ""profit,"" nor is it derived from the efforts of others.

Similarly, the case for the classification of stablecoins as a security is even more flimsy, given that the value of these coins does not fluctuate and that there is no element of profit involved. Instead, these coins simply act as conduits for transferring money across the crypto sphere.

Gary Gensler, Ethereum, and the Liberal Application of the Howey Test

This brings us to the crux of the matter. The SEC's Gary Gensler recently roiled the sentiment in the crypto sphere when he pronounced that ""everything else other than Bitcoin"" was a security.

Interestingly, however, the SEC just admitted in a court document that it has not yet made a determination as to the security status of Ethereum.

1/ There is an important crypto case brewing in Federal Court in San Diego.@freddyriz of Hodl Law has sued the SEC, asking the Court to declare that Ether and the Ethereum Network are Not securities. Here is what you need to know. — MetaLawMan (@MetaLawMan) February 27, 2023

As detailed in the thread above, in its motion to have Hodl Law's suit dismissed, the SEC recently stated:

""Hodl Law's own allegations make clear that the SEC has not reached a final decision about the Ethereum network or Ether.""

This newfound proclivity of the SEC to preach what it is not practicing is quite disturbing. This policy of deliberate obfuscation and ambivalence is hurting the perception of the rule of law in the US.

America risks losing it's status as a financial hub long term, with no clear regs on crypto, and a hostile environment from regulators. Congress should act soon to pass clear legislation. Crypto is open to everyone in the world and others are leading. The EU, the UK, and now HK. https://t.co/i9WeUZ7K6H — Brian Armstrong (@brian_armstrong) February 16, 2023

More disturbing still, this policy is allowing Asia to emerge again as a crypto hub.

Gensler boycotts the ""SEC Speaks"" Conference. For 50 years, this Conference has been an annual tradition where the SEC Chairman and Division heads explained the SEC's objectives. These SEC officials would typically answer a few tough questions from those of us in the securities… https://t.co/iGXCs5P36t — MetaLawMan (@MetaLawMan) March 1, 2023

Perhaps, anticipating the adverse reaction that this policy is sure to garner, the Gensler has chosen to cancel this year's SEC Speaks"" conference.",Finance
https://wccftech.com/the-dragon-slaughters-the-raptor-amd-ryzen-9-7945hx-dragon-range-laptop-cpu-decimates-intel-13th-gen-lineup-in-performance-efficiency/,The Dragon Slaughters The Raptor: AMD Ryzen 9 7945HX “Dragon Range” Laptop CPU Decimates Intel 13th Gen Lineup In Performance & Efficiency,"The first preview of AMD's Ryzen 9 7945HX ""Dragon Range"" flagship CPU has been published by NotebookCheck and we see some stunning performance & efficiency numbers.

AMD's Flagship Ryzen 9 7945HX ""Dragon Range"" CPU Knocks Out Intel's 13th Gen Laptop CPUs In Performance & Efficiency

The Ryzen 9 7945HX is going to be AMD's fastest laptop chip ever made. It will rock the 5nm Zen 4 core architecture and offer a total of 16 cores and 32 threads, the same as the Ryzen 9 7950X CPU from the desktop lineup. These 16 cores will be running at a base frequency of 2.5 GHz and boost up to 5.4 GHz which is highly impressive for a mobility part. The CPU comes with 80 MB of cache & also offers a TDP range of 55-75W+. As further icing on the cake, AMD enables overclocking across its entire Dragon Range lineup which would make for some really powerful laptops.

The folks over at NotebookCheck were able to test the chip out in the ASUS ROG Zephyrus Duo 16 laptop and the results speak for themselves. Starting with the overall performance figures, Ryzen 9 7945HX ""Dragon Range"" CPU was able to come on par in single-thread and end up faster than the fastest Intel 13th Gen Laptop CPU in multi-threaded benchmarks. While the performance lead has a lot to talk about, what's even more impressive is the wattage.

AMD Ryzen 9 7945HX ""Dragon Range"" Laptop CPU Performance (Credits: Notebookcheck):

2 of 9

AMD Ryzen 9 7945HX ""Dragon Range"" Laptop Gaming Performance (Credits: Notebookcheck):

Intel's flagship consumed anywhere from 180-190W and even spiked beyond 200W with average temperatures hovering around 85C. Within a few seconds of operation, the CPU was throttling to sub 3.8 GHz clocks. Meanwhile, AMD's chip never broke past 120W which was its peak and temps were close to 80C but the chip remained steady with a 4.3-4.4 GHz clock speed.

The benchmark results above obviously do not give us a full picture yet, but the initial results are extremely positive. AMD managed to close the gap in terms of single-core performance with lower power consumption. The new Zen 4 chip is even faster in multi-core benchmarks and still consumes considerably less power at just 120 Watts, which means laptop manufacturer get more headroom for the cooling of the GPU, for example. via NotebookCheck

The results even compared to the previous-gen ROG Zephyrus Duo 16 which packed an AMD Ryzen 9 6900HX CPU are superb. The older chip did consume 80W power or 33% lower than the 7945HX but the Dragon Range CPU offers more than twice the performance uplift too.

AMD Ryzen 9 7945HX ""Dragon Range"" CPU Power / Thermals (Credits: NotebookCheck):

Intel Core i9-13980HX ""Raptor Lake"" CPU Power / Thermals (Credits: NotebookCheck):

In gaming benchmarks, the AMD Ryzen 9 7945HX CPU was very competitive given its higher chip efficiency and value proposition. The gaming performance mostly depends on the memory config and the power limits of the GPU itself. Having lower temps and power would mean that a certain range of laptops might utilize the available headroom to provide even higher performance in their designs.

This is just one result but it bodes really well for AMD's Ryzen 7045 ""Dragon Range"" laptops which are heading out to retail now. Reviews for the Dragon Range line of laptops are expected soon so stay tuned.

AMD Ryzen 7045 ""Dragon Range"" Laptop CPUs:

CPU Name Family Process Node Architecture Cores / Threads Base / Boost Clock L3 Cache iGPU iGPU Clock TDP AMD Ryzen 9 7945HX Dragon Range-H 5nm Zen 4 16/32 2.5 / 5.4 GHz 64 MB Radeon 610M (RDNA 2 2 CU) 400 MHz 55-75W+ AMD Ryzen 9 7845HX Dragon Range-H 5nm Zen 4 12/24 3.0 / 5.2 GHz 64 MB Radeon 610M (RDNA 2 2 CU) 400 MHz 45-75W+ AMD Ryzen 7 7745HX Dragon Range-H 5nm Zen 4 8/16 3.6 / 5.1 GHz 32 MB Radeon 610M (RDNA 2 2 CU) 400 MHz 45-75W+ AMD Ryzen 7 7645HX Dragon Range-H 5nm Zen 4 6/12 4.0 / 5.0 GHz 32 MB Radeon 610M (RDNA 2 2 CU) 400 MHz 45-75W+","Report, Hardware"
https://wccftech.com/atlas-fallen-release-date/,Atlas Fallen Delivers the Action on Next-Gen Platforms in May,"Atlas Fallen, the new action-RPG from Lords of the Fallen and The Surge developer Deck13, has locked down a May release date. This was initially leaked by the PlayStation Store, but with the cat out of the bag, publisher Focus Home Entertainment went and made it official.

Take on a heroic journey in a breath-taking world covered by sand, explore ancient ruins and unearth the mysteries of the land of Atlas!#AtlasFallen releases May 16 on PS5, Xbox Series X|S and PC. A Gameplay Reveal Trailer will be coming soon, stay tuned for new game footage! pic.twitter.com/Hw0orXtndB — Focus Entertainment (@Focus_entmt) March 1, 2023

Given Focus Home was seemingly forced to reveal the launch date for Atlas Fallen a bit earlier than they wanted to, there’s no new trailer or gameplay available. In fact, no gameplay has been shown for the game at all, with the following cinematic trailer being the extent of what we’ve been shown.

The trailer above may make Atlas Fallen look like it’s some sort of open-world adventure, but according to Deck13 the game is more akin to something like God of War – a relatively linear action-RPG experience, with some room to explore. Official descriptions of the game also hint there may be Monster-Hunter-style elements at play as well.

While Atlas Fallen gameplay hasn’t been publicly revealed just yet, Wccftech’s Chris Wray did get to see a presentation of the game in action at last year’s Gamescom. Here’s how he described the game's combat.

“Fighting is where Atlas Fallen appears to stand out. Inspired by games such as Monster Hunter, you can face giant monsters with multiple sections to take out. The example in the presentation was a massive crab monster with numerous areas to take out, destroying it in stages before you can finally finish it. The exciting thing is that it never looks like it loses the speed and fluidity that Deck 13 appear to be aiming for within the game.

Fighting is performed through multiple weapons linked to a few different attack types. I saw whips, swords, hammers, fists, and more in the short presentation. As your momentum increases, represented by a bar above your health, these weapons will become more deadly but leave you more vulnerable to damage from those you're fighting. Gain enough momentum, and you'll be able to use even more powerful and unique abilities.”

Overall, Chris’ impressions seemed to be positive…

“I can't say that Atlas Fallen will be exactly as described above. These are my impressions from a hands-off presentation, but it has caught my attention. I like Deck 13 as a developer, and it looks like they have taken their craft to a new level and direction.”

Atlas Fallen launches on PC, Xbox Series X/S, and PS5 on May 16.",Gaming
https://wccftech.com/armored-core-vi-september-launch-rumor-coming-before-elden-ring-dlc/,"Armored Core VI Reportedly Targeting a September Launch, Will Arrive Before Elden Ring DLC","Late last year, FromSoftware officially pulled the curtain back on Armored Core VI Fires of Rubicon, but beyond a broad “2023” window, they haven’t revealed exactly when their big battlin' robots will make their return. Well, according to insider “eXtas1s,” an early fall release date may be in the cards.

Per these latest rumors, FromSoftware aims to release Armored Core VI in September/October, with a late-September release being most likely. Interestingly, it’s also reported that Armored Core VI will arrive before the recently-announced Elden Ring Shadow of the Erdtree expansion. Our insider doesn’t indicate how big of a gap there will be between Armored Core VI and the Elden Ring DLC – hopefully, we won’t be waiting too long for the latter.

Of course, take this with a grain of salt until we get confirmation from FromSoftware or publisher Bandai Namco themselves. That said, eXtas1s has delivered the goods before, particularly in regards to Hideo Kojima’s plans, so hopefully, they have the inside track on FromSoftware as well.

Armored Core VI will represent somewhat of a break from other recent FromSoftware titles, as it will focus on the series’ traditional mech-building and battling gameplay, rather than Soulsborne mechanics. That said, it will still present the usual punishing From challenge. Here’s a quick overview of the game’s story.

""The subtitle Fires of Rubicon is derived from the world developed specifically for this new game. The game is set on a planet known as Rubicon 3, and the story begins with the discovery of a mysterious new material there. The overarching backbone of the game’s story features the struggle for control of this material between various corporations and organizations. The player character is an independent mercenary working amid these fires of conflict, and it is the task of the player to carry out a series of missions amid that backdrop.”

And here’s an official description of its gameplay…

“In Armored Core VI Fires of Rubicon, players will be able to freely move through massive three-dimensional environments with rapid maneuverability while experiencing visceral vehicular combat. Signature to FromSoftware’s carefully crafted game design, the game will feature challenging and memorable battles along with a fulfilling progression system and deep gameplay, all of it now powered by assembling mechs and going into combat with massive bosses. Players will recognize the sense of satisfaction and achievement when they overcome a difficult situation and relish momentary victory, and perhaps a boost to their standing, before encountering the next challenge.""

Armored Core VI Fires of Rubicon is coming to PC, Xbox One, Xbox Series X/S, PS4, and PS5.","Rumor, Gaming (AAA), Gaming"
https://wccftech.com/final-fantasy-xvi-ps5-exclusive-sony-co-developed-can-better-market/,Final Fantasy XVI PS5 Exclusive Because Sony Co-Developed The Game and Can Better Market It,"True third-party console exclusives are rare in this day and age, and yet, Square Enix’s much-anticipated Final Fantasy XVI will be available on PS5, and only PS5, when it launches later this summer. The game will eventually come to PC, but producer Naoki Yoshida has made it clear we’ll be waiting longer than the contractual 6-month PS5 exclusivity agreement for a port.

So, why is Final Fantasy XVI bucking industry trends and sticking to PS5? Well, according to an interview with Yoshida from Japanese gaming site 4Gamer, Sony is actually a co-developer of FF16, working closely with Square Enix to ensure the game is fully optimized on PS5. Getting the full heft of the PlayStation’s worldwide marketing team behind FF16 doesn’t hurt either.

“From our point of view, the technical support we receive from the hardware manufacturer is a big factor to signing [exclusivity] contracts.

This time, there was a [time period] where we were developing together with SIE engineers, who know the hardware thoroughly down to the core and we received generous support in optimization that we could not manage on our own and so on. Also, by not developing on the premise of multiple platforms, we could invest more man-hours into things such as building the game and optimization. In addition, we can also do promotions together globally that make me wonder, ‘How much would this be if it was converted to money?’ Technological and promotional support are things we would like to receive if we can receive them.”

Interestingly, in Wccftech’s recent interview with the producers of Final Fantasy XVI, Yoshida confirmed that the game is running on an all-new engine (rather than the Luminous Engine of FF15 and Forspoken) -- an engine it sounds like Sony may have helped develop. That may go a long way to explaining why the game will be debuting on PS5.

“To talk a little bit about business, Forspoken and Final Fantasy XVI began development around the same time. Final Fantasy XVI is actually using an engine we’ve created specifically for Final Fantasy XVI, so there isn’t much sharing of technology between the Forspoken and Final Fantasy teams.”

Final Fantasy XVI debuts on PS5 on June 22. What do you think? Excited to see Square Enix and Sony really make the PS5 sing?","Gaming (AAA), Gaming"
https://wccftech.com/mainframe-industries-reveals-pax-dei-a-sandbox-mmo-coming-to-pc-and-cloud-gaming-platforms/,Mainframe Industries Reveals Pax Dei; A Sandbox MMO Coming to PC and Cloud Gaming Platforms,"A new game by Mainframe Industries was revealed today. This new game takes inspiration from the mythologies of the medieval era to deliver an MMO experience that brings a sandbox for players to gather in. The game also brings the medieval era to the modern age of gaming thanks to the stunning visuals brought by Unreal Engine 5. This new game is called Pax Dei and sign ups for the game's Alpha are now available.

Before we talk about Pax Dei, you can watch the game's reveal trailer below:

Pax Dei is a game that invites players of all types to define their goals and challenges. Designed to maximize player interactions and allow different play styles to complement each other, the game opens up a vast, mysterious, and beautiful playground that players can fill with their own stories. The game is fully driven by the players, and as such, their choices are just as important as they have to shape the stories of the land.

The game will also have its fair share of PvP and PvE elements in which players will face off against legendary creatures, ancient mysteries, and increasingly difficult challenges. In Pax Dei, players can also choose to fight other players to assert dominance for their clan. Of course, every journey also comes with a risk, and the more players stray from their homes, the more dangerous things will become on their path toward adventure and riches.

What stands out the most about Pax Dei is its nature as a cloud-based MMO game. While the game will come out on PC, it will also be available on Cloud Gaming platforms. Thor Gunnarsson, co-founder and CEO at Mainframe talked about how cloud gaming brings social and immersive online games in a way previously unseen. The goal is to allow players to play the game regardless of the platform, be it mobile, PC, or even the TV itself.

Thor also spoke with Wccftech about why the folks at Mainframe are convinced that the industry is headed toward cloud-native games in the next few years. Stating that the industry is in the process of making a shift in both how games are made, how games are experienced, and how players engage with their favorite games.

Pax Dei will be available on PC and cloud streaming platforms. The game is about to enter its first Alpha, and interested players can sign up for it through its website. Additionally, the game can also be wishlisted on Steam.",Gaming
https://wccftech.com/no-mans-sky-fractal-patch-4-12/,"Latest No Man’s Sky Fractal Patch 4.12 Packs Various Fixes, Including PSVR2 and PS5-Specific Ones","Hello Games has just deployed No Man's Sky Fractal Patch 4.12 across all platforms, packing various fixes for encountered issues.

After last week's major 4.1 Fractal update, the studio has now rolled out a smaller hotfix. As said, this patch addresses various issues there were encountered following the release of last week's big update, including specific fixes for PSVR2 and PlayStation 5. In addition, this update also includes a fix for sky rendering on Xbox One and addresses several crashing issues. Down below you'll find the official release notes, as released by Hello Games.

No Man's Sky Fractal Patch 4.12 Release Notes

Bug fixes

Fixed an issue that caused bases built next to some building types to become buried in the ground.

Fixed an issue that prevented recolouring of portable base building objects constructed outside of a base.

Fixed an issue that caused ship cockpit screens to flicker.

Fixed an issue that caused the Galactic Trade Room on freighters to be non-interactable.

Fixed an issue that allowed cursor or stick sensitivity to be set to 0, preventing cursor use.

Fixed a bug that caused farmable plants to appear in the wrong visual state.

Fixed an issue that caused ByteBeat recordings to fail to save correctly.

Fixed an issue that prevented Featured Bases from being available to PSVR2 players.

The volume of the VR wrist projector’s opening sound effect has been reduced.

Fixed a hang that could occur when exiting an Exocraft in VR.

Fixed an issue that prevented terrain tessellation detail from being rendered on PlayStation 5.

Fixed an issue that prevented controller vibration from functioning correctly on PlayStation 5.

Fixed a PlayStation 5 issue that could cause graphical corruption during warp.

Fixed an issue with sky rendering on Xbox One.

Fixed an issue that prevented system language selection from working correctly.

Fixed a number of issues that could cause stuttering.

Fixed an issue that caused some metadata used by mods to be stripped.

Fixed an issue that could prevent discoveries from showing.

Fixed an issue that could prevent expedition data from being successfully downloaded.

Fixed an issue that could cause incorrect discovery counts to be reported for discovery-based expedition milestones.

Fixed a number of network connectivity issues.

Fixed a crash that could occur when playing with a controller on Linux OS.

Fixed a crash on boot that could affect PC players with integrated/multiple GPUs.

Fixed a crash related to derelict freighter procedural generation.

Fixed a number of rendering-related crashes.

Fixed a number of crashes related to multiplayer.

Fixed a rare crash[red.] related to planet rendering.

No Man's Sky is available globally now for PC and consoles.",Gaming
https://wccftech.com/a17-bionic-chip-in-iphone-15-pro-will-be-based-on-3nm-process-expected-to-bring-major-performance-gains/,A17 Bionic Based On 3nm Process Will Bring Major Performance And Battery Life Gains On iPhone 15 Pro Lineup,"Apple is gearing up to bring major changes with the iPhone 15 lineup later this year. We are expecting four iPhone 15 models, each rocking Apple's Dynamic Island cutout on the front. However, Apple will leash the standard models to keep a distance from the 'Pro' models. The latest suggests that the A17 Bionic chip in the forthcoming iPhone 15 Pro models will be fabricated on a 3nm process which will ensure enhanced performance and better battery life.

3nm A17 Bionic chip in iPhone 15 Pro models will focus on power efficiency and performance, leading the way for M3 chips

The iPhone 15 Pro models are expected to come with a wide range of exclusive features and changes. For instance, it was recently reported that the devices will feature titanium casing for improved durability. Now, DigiTimes corroborates earlier reports that Apple's A17 Bionic chip in the iPhone 15 Pro lineup will be based on TSMC's 3nm architecture. Apple's move to adopt a 3nm chip for the iPhone comes more than three years after the launch of 5nm chips.

If you are not familiar, the lower the nanometer count, the higher the performance and the better the battery life. Henceforth, the iPhone 15 Pro models will excel as far as performance and battery life are concerned compared to the 5nm chips (A16 Bionic). Apart from internals, Apple will also optimize the software to work in conjunction with the hardware for ideal performance.

Performance aside, Apple is also heavily working on additional power-efficient chips. For instance, Apple is also working on its custom 5G modems which will be fabricated on a 4nm process. With chips consuming less power in various instances, the overall battery life of the iPhone will increase. Take note that Apple's first in-house 5G modem is slated to arrive with the launch of the iPhone SE 4.

Other than this, the standard iPhone 15 models will come with the A16 Bionic chipset. This is Apple's way of keeping the 'Pro' models superior to the base models. Make no mistake, the A16 Bionic will still be a very capable chip and can easily handle anything that you throw at it. Nonetheless, the A17 Bionic's 3nm architecture will supersede any other mobile chip on the market.

This is all there is to it, folks. How well do you think the A17 Bionic chip will perform in comparison to Qualcomm's Snapdragon 8 Gen 3 chips? Let us know your thoughts in the comments below.",Mobile
https://wccftech.com/apple-silicon-mac-pro-still-in-pipeline-as-part-of-apples-transition-reveals-company-executive/,"Apple Silicon Mac Pro Still In Pipeline As Part of Apple’s Transition, Reveals Company Executive","Apple is gradually transitioning its entire Mac lineup to its custom silicon. Over the past few years, the Cupertino giant has gracefully managed to shift from Intel to its in-house M-series chips. These custom chips not only feature enhanced CPU and GPU capabilities, but the lower power consumption also contributes to improved battery life. However, Apple has failed to introduce an updated Mac Pro with an M-series chip as of yet. The company's global marketing president hinted that a Mac Pro is still in the pipeline, which will potentially feature the company's powerful M2 Ultra chip.

Apple executive suggests the company's devised Apple Silicon roadmap will include all Macs, potentially hinting at Mac Pro with an M2 Ultra chip

Apple's marketing head Bob Borchers was asked in an interview if Apple will fulfill its devised roadmap to transition the entire Mac lineup to Apple Silicon (including the Mac Pro). Borchers acknowledged and suggests that the company will move ahead with its plans and completely offer Macs with its in-house chips.

This is not the first time that we are hearing details on the Apple silicon Mac Pro. We have recently heard that the machine will look more or less like the Intel version that we are familiar with and that it will not be user-upgradeable as well. As for internals, the Mac Pro is slated to be powered by Apple's M2 Ultra chip. The reason why the Mac Pro's RAM will not be user-upgradeable is that the M2 Ultra chip features unified memory. What this means is that the RAM is part of the chipset, and upgrading it is nearly impossible.

It was also previously rumored that Apple might not upgrade the Mac Studio with an M2 Ultra chip due to similarities with the upcoming Mac Pro. At this point, there are no clear launch time frames in sight. However, we suspect that Apple will see fit to introduce the Mac Pro later this year. Apart from the Apple silicon Mac Pro, Brochers also talked about power efficiency and how its wearable could reap benefits with enhanced battery life. We will share more details on the subject as soon as further details are available.

Do you think Apple will launch the new Mac Pro with a new compact design or keep the original? Share your thoughts with us in the comments below.",Mobile
https://wccftech.com/the-wolf-among-us-2-delayed-beyond-2023-unreal-engine-5/,"The Wolf Among Us 2 Delayed Beyond 2023 to Avoid Crunch, Game Switching to Unreal Engine 5","Those eager for a return to Fabletown are going to have to practice their patience, because today Telltale Games announced The Wolf Among Us 2 will be delayed beyond 2023. A new release window for the game has not been set.

We’ve made the difficult decision to delay The Wolf Among Us 2 #TWAU2. To give more context, we spoke with IGN: https://t.co/afoCUHZwIy pic.twitter.com/KhrAfIrwYB — Telltale Games (@telltalegames) March 1, 2023

“...an important update for The Wolf Among Us 2. We've made the difficult decision to delay The Wolf Among Us 2 out of 2023. We know, it's frustrating to hear. We started work on this in 2020 and we're still determined to tell the ongoing story of Bigby and the rest of the Fabletown gang. However, it is going to require more time. As disappointed as you are hearing this, we feel even worse having to say it. But the work continues.

We're committed to delivering the sequel fans deserve and doing what's right for the game while protecting the health of our team. We appreciate your patience and understanding.”

The Wolf Among Us 2 is being developed by many of the same people who made the original, but the “Telltale” behind the game is actually a new company founded after the original studio went bankrupt. The OG Telltale was infamous for rushed schedules and backbreaking crunch, so it’s good to hear that the new Telltale is prioritizing the wellbeing of the development team. Telltale Games CEO Jamie Ottilie made his position on crunch clear in an IGN interview…

“I've done [crunch], and I don't want to do it again, and it's not fair to ask it. You can't plan a business around it. So yeah, part of it is about maintaining a healthy work culture. We don't want to burn out our good people. […] Burning people out or grinding them down is the wrong thing to do long-term. It's not how you build a business.”

Here’s hoping the extra time results in a sequel that not only lives up to the original game, but potentially surpasses it. Ottilie also confirms that The Wolf Among Us 2 has switched to Unreal Engine 5, which should result in a nicer-looking, better-optimized game, but also means some work originally made using UE4 has to be redone.

The Wolf Among Us 2 is coming to “PC and consoles,"" but further details have yet to be be provided.",Gaming
https://wccftech.com/hi-fi-rush-has-hit-two-million-players-adds-photo-mode-and-stability-fixes/,Hi-Fi Rush has Hit Two Million Players; Adds Photo Mode and Stability Fixes,"Hi-Fi Rush, a game that became an instant hit among the gaming community thanks to its stylish combat mechanics and incredible music, has two great updates to share with its players. The first is that it broke a massive milestone in the form of a report stating that the game has reached over 1 million players across its released platforms. Additionally, the game now has a new update that adds Photo Mode, allowing you to create pictures of your favorite moments.

Let's start with the first. It's no secret that Hi-FI Rush became a massive success among the crowds once it was announced and subsequently released at the Xbox Showcase earlier this year. However, it seems like the game attracted a packed stadium for its crowd as the game broke records during its launch, and now, the game has reached over 2 million players, as reported by Tango! Gameworks themselves in a celebratory Twitter statement which you can see below.

What a crowd! Two million players have enjoyed #HiFiRush, and we can't thank you enough! pic.twitter.com/WeESkn8MIw — Hi-Fi RUSH (@hifiRush) March 1, 2023

In addition to the celebration of this epic milestone, the developers also added a new feature to Hi-Fi Rush in the form of Photo Mode. This intricate tool lets you take pictures of your favorite moments in Hi-Fi Rush, immortalizing those epic moments or making new memories with Chai and his band. You can adjust different aspects of the picture in this mode, such as the colors of the picture, but you can also access various different frames to stylize your photo.

And yes, you didn't misread that; you can have Chai's friends joining in the picture through a variety of cool poses. On Xbox Series X|S, you can check out your photos in the “My Capture” menu on your console. On PC platforms, check the folder where your Hi-Fi RUSH saved games are stored for a folder called “Screenshots.”

The picture mode also brings with it a plethora of fixes that should correct crash errors and several other glitches that the game had, such as one in which players could get stuck in Track 11 if they were hit by the giant robot’s laser when using the magnet grapple. These fixes should allow players to keep having a great time with Hi-Fi Rush without any pesky bugs getting in the way. If you want to see the full patch notes, check them out here.

Hi-Fi Rush is currently available exclusively on Xbox Series X|S. The game is also available on PC through the Microsoft Store, Epic Games Store, and Steam.",Gaming
https://wccftech.com/spacex-celebrates-fourth-anniversary-of-crew-capsule-launch-by-launching-more-astronauts/,SpaceX Celebrates Fourth Anniversary Of Crew Capsule Launch By Launching More Astronauts,"This is not investment advice. The author has no position in any of the stocks mentioned. Wccftech.com has a disclosure and ethics policy.

NASA and SpaceX launched the Crew-6 mission from the Kennedy Space Center in Flordia earlier today after they stood down from a previous launch attempt earlier this week. The mission marks their sixth operational and seventh overall crewed launch to the ISS. SpaceX is the only company capable of launching astronauts from U.S. soil under the Commercial Crew Program. Crew-6 is flying four astronauts to the space station, with two from the U.S., one from Russia and another from the U.A.E., marking the first both the Russian and the Emirati cosmonaut and astronaut are making their way to space.

SpaceX's Falcon 9 Flies Smoothly To Space After Earlier Scrub

Today's launch came after teams had to stand down on Monday due to a problem with the ground systems fueling equipment for the Falcon 9. The rocket uses liquid oxygen and kerosene for liftoff, and these are ignited by a third fuel called TEA-TEB. During the previous launch attempt, controllers found that the rocket's monitoring system could not confirm that TEA-TEB was fully loaded onto the rocket, which made them cancel the attempt less than three minutes before engine ignition for liftoff.

Teams then investigated the issue and tested the systems before today's launch attempt to ensure the problem did not resurface. For today's launch attempt, propellant loading into the rokcet started roughly half an hour before liftoff. At the same time, SpaceX also ran its routine tests on the rocket, including testing its engine control systems to ensure that they can maneuver the rocket as it makes its way to space.

Around the same time that propellant started to make its way into the rocket, the astronauts took their seats in the Crew Dragon spacecraft and later confirmed that they were ready to launch.

The crew access arm retracts prior to liftoff today. Image: NASA

Preparing the rocket for launch also involves flowing some super cool fuel through its engines to ensure that they are cold enough to handle full flow at the time of launch. The Falcon 9 lifted off with the Crew-6 at 12:34 am eastern time, with the first stage separating from the second stage little before three minutes had passed after liftoff.

After this, the second stage continued the journey on its own, and it took roughly four minutes for the first stage to land back on SpaceX's drone ship. This new booster had flown for the first time, and the landing was nominal, with no issues demonstrated during its landing.

A little more than twelve minutes after launch, the Crew Dragon separated successfully from the second stage to continue its journey to the space station. The occasion marked the fourth year annniversy of the NASA and SpaceX Demo-1 mission which flew an uncrewed Crew Dragon to the ISS as part of a test flight.

The Crew-6 will make a roughly one day journey to the ISS, and they are currently scheduled to dock to the station at 1:17 am eastern time tomorrow. They are flying several unique payloads with them, such as those researching materials science and biology.",Finance
https://wccftech.com/spacex-explains-how-blocked-fluid-filters-led-to-nasa-mission-scrub/,SpaceX Explains How Blocked Fluid Filters Led To NASA Mission Scrub,"This is not investment advice. The author has no position in any of the stocks mentioned. Wccftech.com has a disclosure and ethics policy.

With the Crew-6 mission successfully lifting off from the Kennedy Space Center today, SpaceX shared more details about the scrub on Monday just moments before liftoff. NASA's Crew-6 mission was planned initially for liftoff early morning on Monday, but the mission was postponed as SpaceX engineers could not confirm that the ignition fluid for the rocket was successfully making its way out of the rocket as part of pre-flight procedures. At today's post-launch press conference, SpaceX's senior director for human spaceflight shared more details about the fault and how his company fixed the issue before today's successful launch.

SpaceX's NASA Crew-6 Launch Was Delayed Due To Clogged Ignition Fluid Filter

SpaceX's Falcon 9 rocket uses triethylaluminum-triethylborane (TEA-TEB) to light up the Merlin engines on its rockets. As part of the preflight procedures, this fluid is pumped through the system to ensure no gas bubbles are inside when the system is fired up for the flight.

SpaceX's Benji Reed gave a detailed explanation for the fault during today's press conference, as he explained that engineers were uncertain if the ignition fluid was successfully making its way into the tank during the procedures. He shared that:

We flow to make sure that there's enough of this TEA-TEB going into the engines when it's time to ignite them. We flow it up to the interface of the rocket, up to the interface of the engines to basically get all the gas out of the system. It's for like when you replace your brakes and you have to bleed the brake line system to make sure you got all the air bubbles out of the lines. Your want to make sure you just have brake fluid, it's the same idea. We want to bleed the line so we have any gas out of the system, and we're sure we have exactly enough TEA-TEB, the correct amount of TEA-TEB to ignite the engines right when it's time. So during the count on Sunday night, we were watching as we do all of the different data, all the different signatures of information, as we call them, coming in from the rocket and the ground system. And one piece of data looked a little bit funny, one of the signatures looked a little funny. Which was how much TEA-TEB is coming back into the catch tank. So coming out. So when you're bleeding in the TEA-TEB to the rocket interface, you're pushing the air out, or the gas out, but you also want to make sure you're bringing the TEA-TEB back to a catch tank and you want to see how much you're catching in that tank on the way out.

The green glow from the TEA-TEB ignition of the Merlin engine on SpaceX's Falcon 9 second stage as part of the NASA Crew-6 launch earlier today. Image: NASA

And we weren't getting clear data compared to what we would expect to see the amount of TEA-TEB coming into that tank. And that gave us pause for concern. At that point in the count, there was within an hour but still we had most of that hour to go. We had a very clean board, overall clean count. The teams weren't working other issues of anything significant, and so we were looking at, we said well we can go ahead and work this issue and try to understand it a little bit better And, so they did that. All of the engineers, in the back room, this was the key operators were looking at that and assessing, okay, are we okay? Are we really are we sure that we're not getting enough TEA-TEB into that catch tank or not. At the end of the day we couldn't be absolutely sure that we had enough TEA-TEB, enough of this ignition fluid, bled up to the interface of the rocket to make sure that we would get that consistent, exactly timed ignition that we need across all nine engines. So we scrubbed the launch because we needed to make sure we have that in place. Then in the interim, so after we scrubbed launch, we got into the system, and we discovered that there was a filter that was clogged. And just like most fluid systems that you have, in your house or your car, or in rockets, in ground systems, we've got filters. And this particular filter was clogged and that's why we weren't getting enough TEA-TEB into the catch tank.

The SpaceX Dragon docks with the ISS as part of the Crew-5 mission in October 2022. Image: NASA

Mr. Reed also shared details about an abnormal reading from a sensor on the Crew Dragon's hooks. There are twelve hooks on the spaceship, out of which six are used to hold its nose cone and all are used to dock to the space station. These 12 hooks have three sensors each, called limit switches. The sensors generate information to convey the status of the hooks to the teams to let them determine whether they are opening, open, closing or are closed.

According to the SpaceX executive, one of these switches is sending incorrect data, so the system transferred all the hooks to the backup motors. After the shift, all the clamps worked fine. So SpaceX has decided to ignore data from the errant switch and use the primary motors. Mr. Reed confirmed that this poses no risk to the crew for either docking or departing from the space station.

As far as the filter is concerned, it was clogged due to oxidization that resulted from regular maintenance. Air entered the system during maintenance after one of the system's fluids was changed. This led to some material's oxidation, which blocked the filter and the resulting incorrect catch tank readings.",Finance
https://wccftech.com/mario-rabbids-sparks-of-hope-free-demo-first-dlc-are-out-today/,"Mario + Rabbids Sparks Of Hope Free Demo, First DLC Are Out Today","Mario + Rabbids Sparks Of Hope, the second entry in the series developed by Ubisoft in collaboration with Nintendo, received a free demo that allows players to try out the game originally released last year before purchase.

The demo, which is available in all regions on the Nintendo Switch eShop, features the entire prologue of the full game, giving players the chance to explore Beacon Beach and get acquainted with the game's unique mechanics.

The first Mario + Rabbids Sparks Of Hope DLC also launches today. Called The Tower of Doooom, the new expansion, available as part of the game's Season Pass, sees Mario and his friends enter a mysterious tower, meet Madame Bwahstrella, hear her plight, and venture out to contain Cursa's minions and free Spawny. This, however, may be harder to do than anticipated, even for those who mastered the game, as the procedurally generated battles and Heroes lineups make the expansion quite challenging.

Mario + Rabbids Sparks Of Hope is among the best games released last year on Nintendo Switch. The second entry in the series is a great use of the two IPs, and a game like very few others, as highlighted by Kai in his review.

Whether you saved the world together in Mario + Rabbids Kingdom Battle or this is your first test of both the crossover spinoff and a tactical RPG, Sparks of Hope is an ingenious use of both IPs to create something unlike any other RPG out there. Filled with charm, explosions, and the incessant 'Bwahh'ing of Rabbid NPCs, there's a certain charm to this unlikely fusion. The smart changes to how combat plays out and capturing our sense of nostalgia once more make the game one Ubisoft adventure that you don't want to miss.

Mario + Rabbids Sparks Of Hope is now available on Nintendo Switch. The free demo and Tower of Doooom DLC are also available right now worldwide.",Gaming
https://wccftech.com/star-wars-jedi-survivor-is-likely-to-get-a-sequel-if-it-performs-well/,Star Wars Jedi: Survivor Is Likely To Get A Sequel If It Performs Well,"Star Wars Jedi: Survivor, the second entry in the series developed by Respawn Entertainment launching next month on PC and console, is likely to get a sequel if it performs well on the market, according to the game's director.

Speaking with IGN, Stig Asmussen commented on the series as a whole, saying that he always wanted it to be a trilogy. As such, the team already had a pretty good idea of the timeframe, tone, and events of the second entry in the series and even beyond before Jedi: Fallen Order was released in 2019. He added that if the upcoming second game performs well, a third entry in the series is likely coming.

Alongside roughly knowing how Cal's journey will continue, the Star Wars Jedi: Survivor developer also seems to have a good idea on the engine they will use for the hypothetical third entry in the series, as Stig Asmussen suggested that it would be built using Unreal Engine 5, which isn't a too surprising statement, considering such a game would release in a few years.

Star Wars Jedi: Survivor will be a big step up compared to its predecessor in pretty much every aspect. Instead of featuring several smaller locations, the new entry in the series is set on the big planet of Koboh, which allowed the developer to expand exploration, enemy variety, and combat, as highlighted in a recent video preview featuring some brand new footage.

Star Wars Jedi: Survivor releases on PC, PlayStation 5, Xbox Series X, and Xbox Series S on April 28th worldwide. The game was initially scheduled for a March 17th release but was eventually delayed for additional polishing.",Gaming
https://wccftech.com/tesla-disappoints-investors-with-a-nothingburger-investor-day/,Tesla Disappoints Investors With a “Nothingburger” Investor Day,"This is not investment advice. The author has no position in any of the stocks mentioned. Wccftech.com has a disclosure and ethics policy.

Judging by the current price action in Tesla shares, the company's much-hyped Investor Day 2023 has fallen flat against elevated expectations that the EV giant had implicitly encouraged in the runup to the event.

<TSLA>:🔻*TESLA SHARES FALL 5% IN US PREMARKET TRADING — Cable FX Macro (@cablefxmacro) March 2, 2023

In early pre-market trading today, Tesla shares are down a little over 5 percent. Given that the stock is up a whopping 80 percent so far this year, with this rally largely a function of improved demand outlook following aggressive price cuts of as much as 20 percent as well as the recent hype around Investor Day 2023, it remains a stark possibility that yesterday's disappointment might unleash a correction in the company's current nosebleed valuation.

In the runup to its Investor Day 2023, Tesla released marketing material that contained the renders of a coupe EV, leading to a frenzy of speculation that the EV giant might finally announce the oft-talked about sub-$30,000 model. A brand-new vehicle platform, as well as additional information on robotaxis, formed the other legs of this speculative exercise.

Tesla Investor Day 2023

Summary for those who don't have 3 hours:

1. Transition to sustainable energy is entirely feasible

2. global mining will *reduce* in this transition

3. next-gen vehicles will be manufactured very differently

4. no more rare earths in the next powertrains https://t.co/DgQ85oPZjl… https://t.co/3gnJS6dcqO — Martin Viecha (@MartinViecha) March 2, 2023

As is evident from the tweet above, Tesla's event was largely iterative in nature. Readers can view the entire event live stream below.

At the event, Tesla announced that a new vehicle platform was in the works. This next-gen platform will allow the company to build multiple vehicle models and configurations in standardized factories. However, Musk eschewed additional details on this count, including any morsel on which models this platform might serve.

Tesla's CFO, Zach Kirkhorn, revealed that the company will invest up to six times its already-invested CapEx to prepare for the long-term target of producing 20 million electric vehicles annually by 2030. This means that the company's CapEx requirements over the next few years might total as much as $175 billion.

According to Musk, Tesla will retail around 10 models by 2030, with each model capturing sales of around 2 million units per annum.

Elon Musk briefly touched on the company's newest $5 billion production facility that is expected to become operational in Mexico. Terming it ""probably the most significant announcement of the day,"" Musk said that the plant would supplement the output of all other Gigafactories.

In what might constitute the biggest indication for a sub-$30,000 model, Tesla's Chief Engineer, Lars Moravy, said that the company's next-gen models would bear a production cost that is around half of Model 3's and Model Y's. Moravy expanded on the ""unboxed"" production technique where sub-assemblies of future Tesla models would simply be snapped together to save time and money.

While touching on the 4680 battery cells that Tesla has been trying to perfect, the company's engineers noted that they were working on two different techniques to yield volume production by the end of 2023.

In a related development, Reuters reported on Wednesday that Tesla was working on a revamped version of Model Y under the codename Project Juniper. This revamped model might launch next year. Similarly, Tesla was also working on Project Highland, which centers on a Model 3 refresh and is expected to enter production by September 2023.

Additionally, Tesla also announced at its Investor Day 2023 event that the company's next-gen powertrains would not use rare earth metals. However, the company did not provide additional details as to how this feat would be achieved.

I liked it in general, though there were definitely things missing (HW4, next-gen vehicle design unveil, Highland, mining, 4680 rate, new megafactory location, & how exactly they'll get to their 20M scale, although maybe they don't want to share that). It is a little funny it's… https://t.co/PdusSUnQ7p — Sawyer Merritt (@SawyerMerritt) March 2, 2023

Overall, the event left investors and analysts a bit underwhelmed, with a feeling that the presentation was high on rhetoric but low on substance.

MUSK LOSES TOP SPOT AS WORLD'S RICHEST MAN IN 48 HOURS: INSIDER — FXHedge (@Fxhedgers) March 2, 2023

Perhaps, it is fitting that Musk has again lost the title of the world's richest person. Nonetheless, should Tesla even achieve half of what it promised during yesterday's event, it would render the company an unstoppable force.",Finance
https://wccftech.com/the-legend-of-heroes-kuro-no-kiseki-japanese-version-launched-on-steam-pc-exclusive-features-detailed/,The Legend of Heroes: Kuro no Kiseki Japanese Version Launched On Steam; PC-Exclusive Features Detailed,"The Legend of Heroes: Kuro no Kiseki, the first part of the new arc in the series, launched on PlayStation consoles back in 2021 in Japan, has now launched on Steam, complete with several PC-exclusive features.

The PC version of the start of the new arc in the series, which has yet to receive a release date for the West, made its debut today on Valve's digital store, complete with a variety of additional features, as detailed by Peter ""Durante"" Thoman of development studio PH3 which worked on the port. The PC version of the game supports, among other things, arbitrary resolution and aspect ratio, high frame rates up to 360 frames per second, field of view settings, and a variety of graphics options, including shadow resolution, filtering, and quality, draw distance adjustments for NPCs, map LOD and dynamic lights, quality settings for screen-space reflections and volumetric lighting. The studio also worked on Steam Deck Deck optimization to fix an issue that caused heavy performance drops.

Unfortunately, the Steam release of The Legend of Heroes: Kuro no Kiseki only comes with a Japanese language option, and a Western release date, as mentioned above, has yet to be confirmed. Work on it, however, seems to be underway, as original developer Falcom confirmed an English language option will be added with a future update. The game's files also suggest the game will be called Trails in the Dark in the West.

For those who who check in the files of the NISA/PH3 Steam version, they have it name as The Legend of Heroes: Trails in the Dark. — はお(はんすけ) (@Hansuke21) March 2, 2023

The Legend of Heroes: Kuro no Kiseki is now available in Japan on PC via Steam, PlayStation 5, and PlayStation 4. We will let you know when the game launches in North America and Europe as soon as an announcement is made, so stay tuned for all the latest news.",Gaming
https://wccftech.com/hogwarts-legacy-new-mod-introduces-handy-in-game-menu-for-instant-companions-spawning/,Hogwarts Legacy New Mod Introduces Handy In-Game Menu For Instant Companions Spawning,"Earlier this week, we reported that a companions system was introduced to Hogwarts Legacy with a mod. Installing this mod and summoning companions with this mod, however, wasn't exactly straightforward, but another developer came to the rescue to create another mod that makes this process much, much easier.

The AnyTimeCompanion mod, which can be downloaded from Nexus Mods, introduces an in-game menu that can be used to spawn companions at any time during the game. The list of available companions includes several classmates, as well as headmaster Phineas Black and professors Matilda Weasley and Aesop Sharp. Not all available companions, however, can use spells, so this mod is not as advanced as the already mentioned Companion Mod.

Since its release last month, several mods have been developed for Hogwarts Legacy, introducing gameplay tweaks and visual improvements. Earlier this week, a new mod introduced improved ray-traced reflections that make the game's world look incredible.

Hogwarts Legacy is now out on PC, PlayStation 5, and Xbox Series X|S worldwide. The game will release on PlayStation 4 and Xbox One on April 4th and on Nintendo Switch later this year, on July 25th. You can learn more about the game by checking out Chris' review.

Hogwarts Legacy is, for better or worse, an entertaining and engaging game. By far the best digital version of the wizarding world, it offers a vast swathe of things to do. Even the more mundane elements (bandit camps!) are improved by a robust combat system that genuinely makes you feel like you're a part of the Harry Potter universe.",Gaming
https://wccftech.com/final-fantasy-xvi-is-kind-of-like-god-of-war-2018-says-director/,"Final Fantasy XVI Is Kind of Like God of War (2018), Says Director","As part of the recent Final Fantasy XVI media blowout, we discovered several interesting tidbits of information on the new mainline installment of the popular RPG franchise. We learned why the game is a PlayStation 5 exclusive, for example, and that while a PC version may well appear, it won't be until quite some time after the launch on Sony's console.

In the roundtable interview that Wccftech participated in, Game Director Hiroshi Takai also shared some insights on how the game actually works. According to Takai-san, it is fairly similar to the God of War reboot when it comes to the balancing of action and RPG elements.

I don’t think that, or at least it wasn’t our intent, to drift away too far from what the core series brings. We get asked by a lot of media about what we think constitutes a Final Fantasy game. I think that, for me, the one thing is how each game in the series always tries to do something new and challenge something one of the Final Fantasies in the past had done to bring something new to the series. With Final Fantasy XVI, our challenge was to go full action and have these Eikon-vs-Eikon battles. Because this change is so big, that’s what sticks out to players and they feel like it’s bigger than it actually is.

Again, up until now especially with this event, we’ve been putting a lot of focus on the action aspects of the game, but what we have here is an action RPG. Being Square-Enix, we put a lot of pride into our RPG elements. Those RPG elements, while we haven’t talked about them much, do exist in the game; we do have side quests and weapon customizations and things like that. Hopefully, in the near future, we can talk about that and ease the fears that fans feel like Final Fantasy XVI is only action. There is an RPG here as well. If you look at Final Fantasy XVI, one game that is kind of close to how the whole game works is the most recent God of War (2018).

It's not that much of a surprise since the rebooted God of War games have received near-perfect critical and commercial acclaim. Then again, they're fairly light on RPG elements, which means Final Fantasy XVI may be more on the action side than some previous entries.

Square Enix is in the home stretch to release Final Fantasy XVI, due to launch on June 22nd for PlayStation 5. Check out Kai's hands-on preview if you haven't already.",Gaming
https://wccftech.com/intel-game-on-driver-31-0-101-4146-adds-support-for-destiny-2-lightfall-wo-long-fallen-dynasty/,Intel Game On Driver 31.0.101.4146 Adds Support For Destiny 2: Lightfall & Wo Long: Fallen Dynasty,"Intel drops the newest update to the company's Game On Driver (version 31.0.101.4146), which adds further support for the recently released Destiny 2: Lightfall expansion and Wo Long: Fallen Dynasty games. The driver also has fixes for Halo Infinite and Red Dead Redemption 2.

Intel's Game On Driver supports Destiny 2: Lightfall expansion and Wo Long: Fallen Dynasty, optimizes Halo Infinite

Below is the current changelog for the newest Intel Game On Driver update:

GAMING HIGHLIGHTS

Intel Game On Driver support on Intel Arc A-series Graphics for:

Destiny 2: Lightfall

Wo Long: Fallen Dynasty

Game performance optimizations on Intel Arc A-series Graphics for:

Halo Infinite (DX12)

Fixed Issues

Intel Arc Graphics Products:

Halo Infinite (DX12) may exhibit color corruption during gameplay when Reflections settings are enabled.

Red Dead Redemption 2 (Vulkan) may experience an application crash in benchmark mode when Screen Type is Fullscreen.

Intel Core Processor Products:

Uncharted: Legacy of Thieves Collection (DX12) may exhibit texture or striped corruption during gameplay.

Warhammer 40,000: Darktide (DX12) may exhibit texture or striped corruption during gameplay. Dirt 5 (DX12) may reveal texture corruption in the skybox.

Known Issues

Arc Graphics Products:

Sea of Thieves (DX11) may exhibit color corruption on water edges.

Conqueror's Blade (DX11) may reveal corruption in benchmark mode.

The Riftbreaker (DX12) may show black line corruption with the Xbox Game Pass version.

The system may hang while waking up from sleep. Users may need to power cycle the system for recovery.

GPU hardware acceleration may not be available for media playback and encoding with some versions of Adobe Premiere Pro.

Blender may exhibit corruption while using the Nishita Sky texture node.

Iris Xe MAX Graphics Products:

Driver installation may not complete successfully on specific notebook systems with both Intel Iris Xe + Iris Xe MAX devices. A system reboot and re-installation of the graphics driver may be required for a successful installation.

Core Processor Products:

Total War: Warhammer III (DX11) may experience an application crash when loading battle scenarios.

Conqueror's Blade (DX12) may experience an application crash during the game launch.

A Plague Tale: Requiem (DX12) may experience application instability during gameplay.

ARC CONTROL KNOWN ISSUES:

Windows UAC Admin is required to install and launch Arc Control.

The Live Performance Monitoring page may not apply the desired removal of some performance metric tiles.

The Resizable Bar status may show an incorrect value on systems with multiple Intel Graphics Adapters.

Arc Control Studio capture with certain games may incorrectly generate various video files.

Using Arc Control Studio capture with the AVC codec selected may incorrectly use the HEVC codec.

Modifying performance sliders may fail to apply back to their default values. A workaround is to use the ""Reset to Defaults"" button.

Package Contents

Intel Graphics Driver

Intel Media SDK Runtime (21.0.1.35)

Intel oneVPL GPU Runtime (21.0.2.8)

Intel Graphics Compute Runtime for OpenCL* Driver

Vulkan*3 Runtime Installer

Intel Graphics Driver Installer (1.0.737)

oneAPI Level Zero Loader and Validation Layer

Intel Graphics Compute Runtime for OneAPI Level Zero specification

Intel Arc Control installer (1.64.4584.4)

Intel Driver Support Assistant

Product Compatibility

Driver Compatibility

DESKTOP

Arc Alchemist Arc A770, Arc A750, Arc A380, Arc A310

DG1 Iris Xe, Iris Xe Max

MOBILE

Arc Alchemist Arc A770M, Arc A730M, Arc A550M, Arc A370M, Arc A350M

INTEGRATED

13th Gen Core Raptor Lake-S, Raptor Lake-HX, Raptor Lake-H, Raptor Lake-P

12th Gen Core Alder Lake-S, Alder Lake-H, Alder Lake-P, Alder Lake-U, Alder Lake-HX, Alder Lake-N

11th Gen Core Tiger Lake, Rocket Lake

Download the newest Intel Game On Driver (version 31.0.101.4146) here.

News Sources: Intel","Software, Hardware"
https://wccftech.com/viewsonic-launches-new-2k-27-inch-ips-gaming-display-with-170-hz-refresh-rate/,ViewSonic Launches New 2K 27-Inch IPS Gaming Display With 170 Hz Refresh Rate,"ViewSonic has revealed its new VX2758-2K-PRO display, offering a new 27-inch display with 2K resolution, IPS display, and 170 Hz refresh rate. Judging by the stand used for the display, this display will be part of the company's VX series frameless entertainment monitors.

ViewSonic reveals new 27-inch 2K IPS display with a max refresh rate of 170 Hz

As mentioned, the new ViewSonic VX2758-2K-PRO measures 27 inches diagonally and incorporates a seemingly three-sided, seemingly frameless design. The display offers 2K QHD high-definition resolution and the company's proprietary SuperClear IPS panel with a maximum screen resolution of 2560 x 1440. The refresh rate sits at a minimum of 144 Hz and can be boosted to 170 Hz. The VX2758-2K-PRO display offers 300 nits of peak brightness and a 1.07 billion color range. The weight is reportedly 5.82 kg, and it has a built-in power supply.

Not much information is provided on JD.com or the official ViewSonic website. The online retailer mentions that the display supports HDMI and DisplayPort connections but lacks USB Type-C, DVI, USB data transfers and charging, and VGA interfaces. The monitor also lacks internal speakers. The screen ratio is 16:9 with two to four-millisecond response times. The ViewSonic VX2758-2K-PRO offers HDR10 capability and has a contrast ratio of 1000:1.

It can be speculated that the display will support AMD FreeSync technology with compatibility with NVIDIA G-Sync and provide a 100% sRGB color gamut. IT Home reports that the display supports AMD FreeSync technology compatible with NVIDIA G-Sync. The website also mentions that the color gamut coverage is 100% sRGB.

Suppose this model is similar to previous ViewSonic VX series models. In that case, the display will allow users to utilize on-screen game crosshairs to assist with more precise aiming in popular shooters. It may also offer customized black stabilization functionality that the user can adjust. Features available to other monitors in this series are varying Game Modes to select depending on the genre of the game to enhance the picture and help the user with a higher advantage. Modes available have been FPS, RTS, and MOBA modes. Outside of gaming, the monitor series has offered enhanced modes for streaming video, browsing the web, word processing, and MAC, and also has included grayscale for medical scenarios.

2 of 9

Popular online retailer JD.com is offering a presale on the new VX2758-2K-PRO display by ViewSonic, presently offered for ¥999 (estimated $144). Once the new display is launched, the official website will provide more information, if not sooner. Interested users should check out viewsonic.com for updated details as they become available.

News Sources: IT Home, JD.com,","Report, Hardware"
https://wccftech.com/geforce-now-adds-19-new-games-for-march-including-disney-dreamlight-valley/,"GeForce NOW Adds 19 New Games for March, Including Disney Dreamlight Valley","GeForce NOW continues to become widely active in the gaming space, offering a great alternative for users with underpowered devices with a decent internet connection. Today, we saw a new announcement from NVIDIA detailing the games that are coming to the service over the course of the month of March. In total, 19 games will join the GeForce NOW catalog during March, one of the highlights is Gameloft's Disney Dreamlight Valley.

Before we talk about the games that are coming over the course of March, let's talk about the games that will be added to GeForce NOW this week. Here is the list of games that will be joining the service this week:

Monster Hunter Rise (Steam)

Scars Above (New release on Steam)

Voltaire: The Vegan Vampire (New release on Steam)

Rise of Industry (Free on Epic Games Store)

And now, here's what's coming for GeForce NOW over the course of March. The list also includes 11 day-and-date games including titles such as DREDGE, The Legend of Heroes: Trails to Azure, Ravenbound, and more.

Hotel Renovator (New release on Steam, Mar. 7)

Clash: Artifacts of Chaos (New release on Steam, Mar. 9)

Figment 2: Creed Valley (New release on Steam, Mar. 9)

Monster Energy Supercross - The Official Videogame 6 (New release on Steam, Mar. 9)

Big Ambitions (New release on Steam, Mar. 10)

The Legend of Heroes: Trails to Azure (New release on Steam, Mar. 14)

Smalland: Survive the Wilds (New release on Steam, Mar. 29)

Ravenbound (New release on Steam, Mar. 30)

DREDGE (New release on Steam, Mar. 30)

The Great War: Western Front (New release on Steam, Mar. 30)

System Shock (New release on Steam and Epic Games Store)

Amberial Dreams (Steam)

Disney Dreamlight Valley (Steam and Epic Games Store)

No One Survived (Steam)

Symphony of War: The Nelphilim Saga (Steam)

Tower of Fantasy (Steam)

As mentioned before, the key highlight is Disney Dreamlight Valley, a game in which players embark on a dreamy adventure in a life-sim game in which the players help restore Disney magic to the titular valley as they go on an enchanting journey filled with quests, exploration, and beloved friendly faces from the world of Disney and Pixar. The game will join the list of titles available in GeForce NOW on March 16.

NVIDIA also notes that a few games that were announced before to be part of GeForce NOW didn't make it into February due to shifts in their release dates. The titles that didn't make it include Above Snakes and Heads will Roll: Reforged. Some eagle-eyed subscribers might also have noticed that Command & Conquer Remastered Collection was also removed from the catalog. This happened due to a technical issue that's currently being fixed. Stay tuned for more details.

GeForce NOW is available on PC, iOS, Android, NVIDIA SHIELD, and select Smart TVs. You can also play your favorite games with the power of the cloud through the Logitech G Cloud and the Cloud Gaming Chromebooks.",Gaming
https://wccftech.com/garmin-introduces-forerunner-265-and-forerunner-965-to-the-popular-forerunner-lineup/,Garmin Introduces Forerunner 265 And Forerunner 965 To The Popular Forerunner Lineup,"Garmin has lifted the curtains of two new additions to its already impressive Forerunner lineup. You are getting the Forerunner 265 and Forerunner 965.

The Garmin Forerunner 265 and Forerunner 965 are excellent smartwatches if you want something different from the rest

With the Forerunner 265 and Forerunner 965, Garmin didn't go for reinventing the wheel. Instead, you are getting what you would expect from the company. Both smartwatches come with AMOLED displays; you are looking at excellent colors and bright, vivid screens that can be used any time you want. Aside from the screens, you are also getting the tried and tested features that Garmin is known for.

For starters, the Forerunner 265 and Forerunner 965 are getting Body Battery and all the metrics that would help you train. There is also a separate widget for racing and a Morning Report that should help you stay up to date.

Starting with the Forerunner 265, you are getting an excellent all-rounder at an affordable price. You are going to get all the advanced features such as PacePro, sleep tracking, Body Battery, and more. You also have music support, various payment supports, a safety feature called LiveTrack, and a slew of other features that will improve the experience.

Garmin is offering the Forerunner 265 in two sizes; you have the bigger 46mm for larger wrists, and there is a 42mm option available too. Battery life is stellar, with Garmin stating that the 42mm option will last you 15 days as a smartwatch and 24 hours when using it in GPS mode. The larger 46mm model will offer 13 days as a smartwatch and 20 hours with GPS mode turned on. If you are interested, the Forerunner can be yours for $449.99, regardless of the size you choose.

If you still want something higher-end, then the Garmin Forerunner 965 is what you should be going for. You are getting a 1.4-inch AMOLED screen, a massive 47mm case, and a lightweight and sturdy titanium bezel surrounding the case. However, a more significant case is not just the only thing. You can use built-in mapping, new features such as Garmins' load ratio, and more.

If you are looking for a smartwatch that lasts you a long time, the good news is that the Garmin Forerunner 965 lasts over 31 hours in GPS mode and 23 days when you are using it in smartwatch mode. This is a stellar option for those who don't prefer charging their smartwatches repeatedly. Unlike the Forerunner 265, this one only comes in a 47mm case size, which might feel larger, but the titanium bezel should cut down the overall weight. The Forerunner 965 will release next month and is going to cost you a hefty $599.99 from garmin.com and authorized retailers.",Mobile
https://wccftech.com/amd-ryzen-9-7900x3d-sold-more-than-50-percent-better-7900x-did-at-launch-7950x3d-cpu-mostly-out-of-stock/,"AMD Ryzen 9 7900X3D Sold More Than 50% Better Than What The 7900X Did At Launch, 7950X3D CPU Mostly Out of Stock","The first sales figures of AMD's Ryzen 7000 X3D CPUs are in and it looks like the Ryzen 9 7900X3D is selling quite well while the 7950X3D remains out of stock.

AMD Ryzen 9 7900X3D CPU Sales Strong At Launch, Ryzen 9 7950X3D CPU's Reception Mixed But Sold Out At Major Outlets

In numbers compiled by TechEpiphany, we can see the sales figures of the AMD Ryzen 7000 X3D CPUs at the retailer, Mindfactory. The numbers show the launch day figures and it looks like AMD Ryzen 9 7900X3D CPUs were quite popular. The retailer was able to sell 360 units which might be seen as lower than the Ryzen 7 5800X3D (490 units sold) and Ryzen 7 5800X (400 units sold) but at the same time, the chip sold much better than its non-3D brother, the Ryzen 9 7900X which only managed to sell 230 units during its launch week.

This shows that the AMD Ryzen 9 7900X3D CPU sold more than 50% better than the 7900X and as of right now, the sales were 3.6x higher versus the 7900X despite the former being lower down to $449 US versus the $599 US cost of the 3D V-Cache part. The AMD Ryzen 9 7950X3D was nowhere to be seen in the list but it is mentioned that there's far less stock of the flagship compared to the Ryzen 9 7900X3D which is available plenty.

It looks like the AMD Ryzen 9 7900X3D provides a balanced application and gaming performance at its price point which is about on par with the Intel Core i9-13900K. But the real game changer in the 3D V-Cache lineup is yet to launch. Most gamers are waiting for the Ryzen 7 7800X3D which is also evident by our own poll which shows more than 50% of our readers likely to purchase it. The Ryzen 9 7950X3D was in the second spot in our poll but that was before the reviews came in and it looks like most readers changed their minds and went for the 7900X3D.

The other possibility of the lower AMD Ryzen 9 7950X3D CPU could just be the lower supply which can be seen across major US/UK/EU retailers. The flagship is mostly out of stock and Newegg had the following to say about the supplies at launch:

The Ryzen 9 7950X3D sold out earlier this morning, but will be replenished as soon as possible. via Newegg

But it looks like the stock hasn't been replenished. In fact, even the Ryzen 9 7900X3D is now being sold at a much higher price of $794 US at the retailer which is 33% higher than its MSRP. We would like gamers to wait for the Ryzen 7 7800X3D as it would be the best deal for them. The chip might also potentially push AM5 sales higher and be as big of a hit as the Ryzen 7 5800X3D has been so far.

Which AMD Ryzen 7000 X3D CPU are you most likely to buy? AMD Ryzen 9 7950X3D ($699 US)

AMD Ryzen 9 7900X3D ($599 US)

AMD Ryzen 7 7800X3D ($449 US) Vote to see results Poll Options are limited because JavaScript is disabled in your browser.","Report, Hardware"
https://wccftech.com/resident-evil-4-preview/,"Resident Evil 4 First Look Preview – Come Into My Castle, Die By My Knife","Resident Evil 4 is rightly considered one of the best entries in the survival-horror series by CAPCOM and the classic entry in the series that has aged the best. Despite being released in 2005, the game still plays great to this day, which made CAPCOM's decision to remake it a little baffling, considering that Resident Evil: Code Veronica is way more in need of a remake.

After experiencing some sections of the Resident Evil 4 remake, however, I can confidently say that remaking the fourth entry in the series was the right call, as the number of improvements to the formula is sure to make the experience way more engaging.

Unlike the Resident Evil 2 and 3 remakes, which modernized the formula of the original games, the Resident Evil 4 remake doesn't bring the same radical changes and feels extremely familiar. Like in the original, Leon can shoot enemy parts, such as their legs, to disorient his foes, and knock them down using a melee attack, using his knife to parry their melee and ranged attacks. When fighting Ganado, the parasite's body can become exposed, which will increase the enemy's power and speed, making knife parries even more important.

With the Resident Evil 4 remake featuring a lot of different enemies, players will have to adapt to their unique characteristics, changing their strategies according to the situation. Explosive weapons, for example, can be shot to make short work of the enemies holding them. To make another example, the Garrador in the Castle is strong and quick, but its vision is impaired, so players need to move quietly to avoid alerting them. Even if discovered, however, players still have the chance to mitigate damage by parrying the Garrador's powerful claw strikes.

Knife parries will be even more important in the fight against Jack Krauser, which now players have to play actively instead of completing a quick-time event. This is an excellent change over the original, as it makes the iconic fight finally feel as involved as it should have been in the original. The ability to register multiple weapons to shortcuts is also a welcome addition that greatly expands combat.

With haunting locations like the Lake and the Castle, the Resident Evil 4 remake didn't need to touch up exploration that much, but it seems like CAPCOM had a very good idea on how to improve it as well, and it shows. Alongside the puzzles found in the original and environmental hazards such as catapults in the Castle, players can find request notes with requests that will reward players with Spinels. Defeating enemies and thoroughly exploring around will also reward players with Pesetas, which can be used to purchase new weapons and items from the iconic Merchant. From time to time, his stock will change, so players will have to check with him frequently to purchase important items such as different colors and charms for the Attaché Case, which grant a variety of minor effects, such as increased drop rate for ammo, improved healing and so on. Case customization is only available at typewriters, so even their role has expanded beyond simple save points.

While exploring the many haunting locations featured in the Resident Evil 4 remake, Leon will be followed by Ashley, the daughter of former US President Graham he has been sent to rescue from the Los Illuminados cult. The young woman will follow Leon the best she can, and players have some degree of control over how she should follow him with the Tight or Loose commands. During combat sequences, players will need to be aware of where Ashley is and what she is doing, as enemies will be going after her as soon as possible. If she is damaged too much, she will be knocked down and become easy prey for the enemy, and if she is carried off, it will be game over, so keeping an eye on Ashley at all times and using the available commands to keep her safe from harm will be extremely important.

With its incredible atmosphere kept intact and enhanced by the RE Engine and expanded gameplay, the Resident Evil 4 remake is setting out to be a great game for veterans and newcomers alike. How the many changes will hold up remains to be seen, but from what has been shown so far, it definitely looks like CAPCOM has done an amazing job remaking one of its most popular games.

The Resident Evil 4 remake launches on PC, PlayStation 5, PlayStation 4, Xbox Series X, and Xbox Series S on March 24th, 2023, worldwide. Find out more info in our recap article.",Gaming
https://wccftech.com/dead-island-2-gets-14-minute-long-extended-gameplay-trailer/,Dead Island 2 Gets 14-Minute-Long Extended Gameplay Trailer,"Dead Island 2, the long-awaited second main entry in the series, is launching in a little over a month, and today an extended gameplay trailer was shared online to prepare players for the upcoming zombie-slaying adventure.

The new extended gameplay trailer, which can be watched below, showcases the very beginning of the game as the slayer Dani attempts to make her way to Halperin Hotel. During her short journey, she gets to meet all sorts of zombies, ranging from Standard zombies to Variant and Apex zombies, all coming with unique abilities and behaviors. With a vast array of weapons and multiple Skill Cards, players will have all the tools at their disposal to get rid of the undead hordes and see the FLESH system in action in all of its glory.

Dead Island 2 has been in development for quite a long time, but the game is now right behind the corner, its release moved forward by one week last month. Among the many unique mechanics the game developed by Dambaster Studio will feature is the aforementioned FLESH system, a procedural dismemberment system that will make each zombie kill a glorious, gory affair.

Dead Island 2 launches on PC, PlayStation 5, PlayStation 4, Xbox Series X, Xbox Series S and Xbox One on April 21st, 2023 worldwide.",Gaming
https://wccftech.com/author/wccftech/,Wccftech Staff,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/omarsohail/,Omar Sohail,"Biography

Omar joined the Wccftech team back in 2014, with a keen interest surrounding the latest gadgets, tablets, and other consumer electronics. He’s also a hardcore PC gamer, has a love-and-hate relationship with consoles, and takes an interest in both hardware and gaming. When he’s not reporting about the latest happenings in the mobile industry, he likes to learn more about technology and how it works, appreciating the time and effort companies make in developing new products that simplify life for users","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/nate/,Nathan Birch,"Biography

Professional writer of trivial things. Nathan has been covering games, entertainment, and online culture for over a decade with bylines at IGN, GameSpy, Cracked, Uproxx, ComicBook, and more. Joined Wccftech in 2017, and has written dozens of game reviews and thousands of news stories since.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/alisalman/,Ali Salman,"Biography

Ali Salman is a writer with motive, a blogger with sense, and rightly can be called a human with a brain. He started his editorial journey with Wccftech in 2015, covering the latest in tech news and guides for iOS and Android platforms. He did not limit himself to tech but also prolonged his journey as a researcher and writer in other fields like fiction and poetry. Salman successfully tinkers and explores his investigative skills within the software industry. He is well equipped with a vast understanding of mobile hardware insights and has a keen eye on the industry trends. He has contributed to multiple publications before settling with Wccftech. Salman has also successfully served in dynamic digital and social media marketing roles for various national and international marketing agencies.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/agnesecarluccio/,Agnese Carluccio,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/sohail/,Sohail Abid,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/ramishz/,Ramish Zafar,"Biography

Ramish joined Wccftech in 2014 and since then has covered reports for high-end gadgets. Now, he has moved forward to covering pressing issues in the tech industry, earnings reports and analytical pieces for tech companies amongst other coverage.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/ulelopez/,Ule Lopez,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/kai/,Kai Powell,"Biography

Kai joined the gaming team of Wccftech in 2016 and has since penned over a hundred reviews and interview pieces, covering a bit of everything from one-man indie gems to AAA masterpieces and whatever lies in between. Over the recent months, Kai has expanded into preview and interview coverage of not only the gaming side of the industry but also tech and consumer electronics.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/jasonwilson/,Jason R. Wilson,"Biography

Jason R. Wilson is a member of the Hardware news team at Wccftech. Equipped with a background in graphic design and writing, Jason works daily to improve his craft and continues to create new and innovative ideas every day.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/guestauthor/,at Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/brittany/,Brittany Vincent,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/francesco/,Francesco De Meo,"Biography

Francesco has been writing about video games and tech since 2012, working for several online publications before joining the Wccftech gaming team in 2015. Starting as a reporter and reviewer, Francesco eventually moved up into the video games reporting world, interviewing developers and covering major events like Gamescom and E3. A man of multiple interests, Francesco juggles his time between reporting on all the latest gaming news, playing fighting games and RPGs, reading, and playing the drums and writing music for his progressive rock band.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/evan/,Evan Federowicz,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/aernout/,Aernout van de Velde,"Biography

Passionate gamer since the NES era and begun writing about games in 2014. Joined Wccftech in 2015. Has owned every console since then. Can never make up his mind on what console to play. Weird sense of humor but can be funny from time to time.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/furqan-shahid/,Furqan Shahid,"Biography

I have been tinkering with Android devices ever since the early days of the HTC Desire. Over time, I have grown a fondness for the ecosystem and now I cannot live without it. Although some might believe that I have sold my soul to Android, but I believe it is not the case. You can find me writing tutorials and posting guides on a number of different smartphones. When I am not writing here, I am wasting myself away in books, journals, or on Steam.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/rohail/,Rohail Saleem,"Biography

As a trader of multiple instruments in different asset classes, I'm an avid follower of global finance developments. My professional experience includes working as a bank treasury dealer. Currently, I'm also enrolled in the CFA program. Since I'm a passionate foodie and a travel junkie, I aspire to spend every second of my spare time traversing the globe.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/roshkelly/,Rosh Kelly,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/abdullah-saad/,Abdullah Saad,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/alexcasas/,Alex Casas,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/chriswray/,Chris Wray,"Biography

Chris Wray has been writing at Wccftech since 2015 and is an opinionated bloke from the north of the UK (think Ned Stark). He enjoys video games, films, books, beer, whisky and other alcohol. He also supports Manchester Utd and for some reason he writes profile pages in the third person. His expertise is in gaming and the games industry, primarily on the PC. In addition to this, he works with and contributes to the finance and tech sections.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/dealseditor/,Deals Editor,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/alessio/,Alessio Palumbo,"Biography

Alessio began writing about games as a teenager for websites like GameStar, Multiplayer, Everyeye and more. In 2013 he founded Worlds Factory, where he established a crew that would later follow him when he joined Wccftech in 2015 to rebuild the gaming section from the ground up. Since then, Wccftech has become a respected and trusted publication throughout the games industry, its reviews automatically featured on the biggest aggregator websites (MetaCritic, Game Rankings, Open Critic).","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/hms/,Hassan Mujtaba,"Biography

Hardware enthusiast and PC Gamer. Also in charge of the Illuminati clan at Wccftech.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/shaikhrafia/,Rafia Shaikh,"Biography

Rafia joined Wccftech in 2012 as a tech reporter. She is currently working on stories focusing on people and technologies that are turning Microsoft into a “company to watch” again. She is also responsible for collaborating with tech makers and e-commerce platforms to bring annoying but tempting deals to our readers.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/usmanpirzada/,Usman Pirzada,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/uzairghani/,Uzair Ghani,"Biography

Uzair has been writing about tech for a little under 10 years. Started off in the Symbian days, migrated to Android, eventually settling on iOS and Mac to make a living. Loves photography, drones, talking about the latest tech, and firmly believes that iPad is the future of computing. Served as Editor-in-Chief with Redmond Pie for five years, author at The Readers Eye and many other freelance gigs. Wccftech is now his current home.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/sethjohnson/,Seth Johnson,"Biography

Staff writer at Wccftech. Love F1, PC hardware and AI/ML. Covering the hardware and general technology beats with a dribble of software.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/author/ammarhaider/,Ammar Haider,"Biography

Ammar has been working in Social media and digital marketing for the past 9 years with the focus on audience insights, digital strategy, and paid media campaigns. He is often found exploring new places, experimenting with his beard, or trying his luck on Football Manager.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/wwdc/,WWDC 2023,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/windows-update/,Windows Update,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/web/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/wccftech-store/,Wccftech Store,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/wccf-podium/,WCCF Podium,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/tv/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/tga/,TGA 2022,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/teaser/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/statement/,Statement,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/sponsored/,Sponsored,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/software/,Software,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/singles-day/,Single's Day 2020,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/siggraph/,Siggraph,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/security/,Security,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/satire/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/samsung-unpacked/,Samsung Unpacked 2023,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/rumor/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/report/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/prime-day/,Prime Day 2022,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/press-release/,Press Release,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/podcast/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/pc/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/op-ed/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/notebooks/,Notebooks,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/mwc/,MWC 2020,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/movies/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/gadgets/,Mobile News,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/mini-editorial/,Mini-Editorial,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/livestream/,livestream,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/linux/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/leak/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/launch/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/iphone-launch/,iPhone 14 Event,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/ipad-pro-event/,iPad Pro Event,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/interview/,Interview,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/intel-innovation-2022/,Intel Innovation 2022,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/intel-architecture-day-2021/,Intel Architecture Day 2021,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/industry/,Industry,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/ifa/,IFA 2020,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/humor/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/hot-chips/,Hot Chips,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/hardware/,Hardware News,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/halloween/,Halloween,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/gtc/,GTC 2019,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/gtc-2/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/pixel-launch/,Google Pixel 5 Event,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/google-io/,Google I/O 2023,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/giveaway/,Giveaway,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/general/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/gdc/,GDC 2023,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/aaa-gaming/,Gaming (AAA),"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/games/,Gaming News,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/gamescom/,Gamescom 2022,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/galaxy-s10-launch/,Galaxy S10 Launch,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/finance/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/exclusive/,Exclusive,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/event/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/entertainment/,Entertainment,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/editorial/,Editorial,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/e3/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/deals/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/cyber-monday/,Cyber Monday 2022,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/covid19/,COVID-19,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/contest/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/computex/,Computex 2023,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/ces/,CES 2023,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/canada/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/black-friday/,Black Friday 2022,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/apple-show-time/,Apple Show Time,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/apple-event/,Apple Peak Performance,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/announcement/,Announcement,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/topic/analysis/,Analysis,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/category/sticky/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/category/sponsored/,Sponsored,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/category/review/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/category/news/,Latest Industry Updates by Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/category/guides/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/category/featured/,Featured,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/category/deals/,Wccftech,"Login to continue

You need to login to use this feature.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/apple-2023-15-inch-macbook-air/,Apple’s 15-Inch MacBook Air – Here’s Everything You Need To Know About The Larger Version,"Product Info 15-inch MacBook Air April 2023 Manufacturer Apple Type Notebook Platforms macOS Expected Price Starting from $1,299.99 (Rumored) Expected Release Date April 2023

The MacBook Air lineup will get a new, larger member to complement the 13-inch model. A bigger notebook comes with inherent benefits, but how will this 15-inch version raise the bar, and what sort of improvements can we hope to see from it? Our detailed rumor roundup answers every possible question you may have, so let us get started.

Unchanged design with a larger footprint should be expected, bringing two inherent benefits, but do not expect a display upgrade

It makes little sense for Apple to introduce a redesign for the 15-inch MacBook Air when it has already revamped the 13-inch model. This is the reason why we feel that the larger portable Mac will sport the same look but in a bigger footprint, which brings a ton of natural benefits to the table, which we will get into later. For now, expect to see a notch at the top that does not support Face ID but likely has a 1080p FaceTime HD camera.

Apart from a size difference, there should not be any major differences between the 13-inch and 15-inch MacBook Air

The display is said to measure 15.5 inches diagonally, so the panel will probably have a resolution that exceeds that of the 13-inch MacBook Air, which is 2560 x 1664. Also, like the smaller version, we do not see Apple adopting mini-LED or ProMotion technology for this model, meaning that potential buyers will be limited to a 60Hz, IPS LED-backlit screen. The advantage of a bigger display means you will get a larger battery than the 52.6WHr cell present in the current version.

M3 for the 13-inch and 15-inch MacBook Air, expect improved power efficiency from both models

Apple was previously said to have secured TSMC’s 3nm chip supply for the upcoming M3 and A17 Bionic, and according to a recent update, both the 13-inch and 15-inch MacBook Air with the codenames J513 and J515, respectively, will arrive with the M3 SoC. This will mean both machines will deliver tremendous battery endurance, though Apple could also choose to increase performance in exchange for a few hours of runtime. We have also learned that just like the M1 and M2, the M3 will be equipped with an 8-core CPU, but at this time, we do not know how many GPU cores the upcoming SoC will have.

The M2 could be equipped with a 10-core GPU, so the M3 should provide the option to offer 12 of them, though the final word will be Apple’s. Coming to the cooling capabilities now, we believe that just like the 13-inch version, the larger MacBook Air will feature a passive cooling solution, meaning no presence of any fan. While the lack of noise will make it a comfortable experience to use, it will mean the M2 will reach high temperatures within the snap of a finger. On the 13-inch model, we reported a 25 percent loss in multi-performance as the SoC was hitting its thermal throttling limit.

We have learned that instead of the M2, both the 13-inch and 15-inch MacBook Air will feature the cutting-edge M3 SoC

Though this was addressed using an inexpensive thermal pad that made proper contact with the chipset, we can understand some customers having reservations about the larger MacBook Air. Fortunately, the bigger size of the portable Mac means the M2 will have an increased heat dissipation area, leading to slightly better temperatures. This means that multi-core performance will not see that big of a hit, so any applications that require all cores to work in unison will greatly benefit from the larger footprint of the MacBook Air.

We still think that YouTubers will attempt to further reduce the temperatures through some form of modding, so that should be exciting. Base RAM and storage configurations should start from 8GB and 256GB, respectively, and since Apple switched to Wi-Fi 6E and Bluetooth 5.3 for the 2023 MacBook Pro lineup, it is more than possible these upgrades land for the 15-inch MacBook Air too. Given its larger size, slight upgrades, and increased cooling solution, all of this will come at a price, which we have discussed right at the end.

Ports selection, available colors at launch to remain the same as well

The I/O of the 13-inch MacBook Air is decent, but it will most likely remain unchanged on the 15-inch model. What you may get is the MagSafe charging port, a 3.5mm audio jack, and two Thunderbolt 4 ports.

Expect the same ports for the 15-inch MacBook Air

While this configuration is not as plentiful as the one found in the 2023 MacBook Pro models, it should be sufficient for the majority of users. Since Apple is not incorporating anything new to this model, we expect it to arrive in the same four finishes as the 13-inch MacBook Air: Midnight, Starlight, Space Gray, and Silver.

Four finishes might be announced during the April announcement

Expect a smaller price bump and an April launch

The 15-inch MacBook Air could start from $1,299.99 and may offer 8GB unified RAM, M2 SoC with 8-core CPU and 8-core GPU, and 256GB of storage. This is $100 more expensive than the 13-inch model, which is nominal, given the screen real estate bump, increased battery life, and potentially improved thermal performance. Of course, not all of this information is accurate, and as soon as we continue to come across reliable data, we will update our findings accordingly. For now, let all of us wait for a rumored launch in Spring.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/dead-island-2-everything-you-need-to-know-about-the-long-awaited-sequel/,Dead Island 2 – Everything You Need to Know About the Long-Awaited Sequel,"Product Info Dead Island 2 April 21st Platforms PC, PlayStation 4, PlayStation 5, Xbox One, Xbox Series S|X Publisher Deep Silver Developer Damber Studios Expected Price 59.99 Expected Release Date April 21st

Zombie games were the craze back in the early 2010s, and due to this phenomenon sprung by games like Dead Rising, we saw the release of a game called Dead Island. Developed by Techland, this game saw some critical acclaim. A sequel was announced, but unfortunately, it also spent a lot of time in development hell. But now, thanks to Dambuster Studios, players will have a chance to experience the long-awaited sequel, Dead Island 2.

After numerous delays and cancellations several at development studios, Dead Island 2 is finally going to become available after being in limbo for over 9 years. This game has been through a lot, especially when you consider the number of game development studios that have tried to bring it to life: Yager (Spec Ops: The Line) from 2012 to 2015, Sumo Digital (Crackdown 3) from 2015 until being removed, and now Dambuster (Homefront: The Revolution) from 2019 to the present.

Release Date, Pricing, Platforms

Dead Island 2 will be available on PC, Xbox One, Xbox Series X|S, PlayStation 4, and PlayStation 5 on April 21, 2023. The game will have several different editions available to players at launch. In fact, in a shocking move, there's a grand total of six different game editions with multiple goodies. These editions cover a broad set of prices, so below, you'll find what comes in each version.

DIGITAL EDITIONS

Standard - $70

Base Game

Pre-Order Bonus: Memories of Banoi Pack

Deluxe - $100

Base Game

Pre-Order Bonus: Memories of Banoi Pack

Bonus Content: Golden Weapons Pack

Bonus Content: Character Pack 1 & 2

Gold - $120

Base Game

Pre-Order Bonus: Memories of Banoi Pack

Bonus Content: Pulp Weapons Pack

Bonus Content: Golden Weapons Pack

Bonus Content: Character Pack 1 & 2

Expansion Pass

PHYSICAL EDITIONS

Day One Edition - $70

Base Game

Pre-Order Bonus: Memories of Banoi Pack

Pulp Edition - GameStop Exclusive ($70)

Base Game

Pre-Order Bonus: Memories of Banoi Pack

Bonus Content: Pulp Weapons Pack

Hell-A-Edition - $100

Base Game

Pre-Order Bonus: Memories of Banoi Pack

Bonus Content: Pulp Weapons Pack

Bonus Content: Golden Weapons Pack

Bonus Content: Character Pack 1 & 2

Expansion Pass

Steelbook + physical items

The physical items included with the Hell-A Edition of the game include a Venice Beach travel map, six slayer Tarot Cards, two pin badges, one patch, and the products mentioned above. In a unique move, Deep Silver is also offering a resin statue of the type that would usually be part of an ultra-expensive collector’s edition. Instead, they’re simply selling it on its own via their store for 120 euros.

Remember that Dead Island 2 will be exclusive to the Epic Games Store. Originally, the game was set to release on April 28, 2023. However, a recent announcement by the Dead Island Twitter account confirmed that the game has gone gold and that the new release date would be a week earlier: April 21, 2023.

Gameplay Details and Story

In Dead Island 2, a deadly virus spreads across the entirety of Los Angeles, turning its inhabitants into zombies. You are a survivor who has been infected during the pandemic. However, you are more than just immune to the virus as you also are capable of harnessing the tainted powers running through your veins.

The game takes players across the most iconic locations in Los Angeles. In the game, you have to fight off against the zombie horde while enjoying the procedural dismemberment tech known as FLESH. Technical Art Director Dan Evans-Lawes talked about Dead Island 2's FLESH system in an interview, stating that the game will let you see realistic damage as you swing your weapons around and slice or crush zombies with a wide variety of weapons.

The game will offer six characters that you can choose from, each with their own unique personality and dialogue. The player character's abilities can also be customized with the aid of the game's skill system, which allows players to re-spec instantly to try out new ability combinations and skills. Additionally, zombies in Dead Island 2 will also come with their distinct mutations, attacks, and hundreds of LA-themed variants.

Dead Island 2 also offers a co-op adventure experience for those players who want to experience the zombie madness with a bunch of friends. Up to three players will be able to experience the game's exciting quests with a thrilling pulp story to boot.

Trailers

World Premiere Trailer @ The Game Awards

Gamescom 2022 Gameplay Trailer

Welcome to HELL-A Gameplay Trailer

Alexa Game Control Trailer

Dead Island 2's FLESH System Explained","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/resident-evil-4-remake-everything-you-need-to-know-guide/,Resident Evil 4 Remake – Everything You Need to Know About Capcom’s Modernized Magnum Opus,"Product Info Resident Evil 4 March 24, 2023 Platforms PC, Xbox Series X/S, PlayStation 4, PlayStation 5 Publisher Capcom Developer Capcom Expected Price $59.99 Expected Release Date March 24, 2023

A remake of Resident Evil 4 has been a project fans have long dreamed of and, on some level, dreaded. Obviously, the prospect of a new Resident Evil 4 is an exciting thing, but how do you improve on one of the best games of all time? One that still feels relatively fresh and playable 20 years later? Well, Capcom is giving it the ol’ college try, as the Resident Evil 4 remake launches in March.

As with all Capcom’s recent REmakes, they’re rebuilding Resident Evil 4 from the ground up, but they seem to be remaining fairly faithful to the tone and spirit of the original. How is the game changing and will fans still have room in their inventory for this reimagining? Here’s everything you need to know about the Resident Evil 4 remake…

Setting and Story

Wait, you don’t know what happens in Resident Evil 4? Well, for the few of you just emerging from caves after 20 years, RE4 breaks from the usual Raccoon City/Umbrella saga, instead focusing on Leon Kennedy as he embarks on a mission to save the U.S. President’s daughter Ashley from a mysterious cult that’s overrun a small Spanish village. The village’s residents are infected by a mind-controlling parasite known as Las Plagas, which has the potential to be weaponized. As such, a couple of ghosts from Leon’s past – ex-special-forces comrade Jack Krauser and his mysterious on-and-off love interest Ada Wong – are also in the village pursuing ulterior interests.

Capcom has said they’re aiming to modernize Resident Evil 4’s story with a bit more character drama. It’s also rumored some side characters, like Ada Wong, will have bigger roles. That said, for the most part, expect Capcom to stick to familiar plot beats.

How is the Resident Evil 4 staying the same?

Capcom isn’t looking to fix what isn’t broke with Resident Evil 4. The game once again takes the form of an over-the-shoulder third-person shooter, with Leon having to deal with large mobs of possessed enemies. The game’s bombastic action-movie feel looks to be largely intact, with Leon spin-kicking enemies and parrying chainsaw attacks while dropping one-liners. Even quirky characters, like the little tyrant Ramon Salazar, and less popular sections, such as the later Island chapters, are making the cut. It seems like Capcom is trying its best to avoid a repeat of the Resident Evil 3 remake, which was criticized for cutting content. It’s all going into the pot this time.

How is the game changing?

Of course, this is still a remake, so things are changing. In addition to the obvious huge upgrade in visual quality and the aforementioned increased focus on character development, Capcom is opening up Resident Evil 4’s level design somewhat. Stealth will be more of an option this time around, with added paths through stages to accommodate sneaky types. New sidequests issued by the Merchant will encourage greater exploration of these redesigned levels. Ashley will also be more of a full-fledged partner to Leon this time around, helping him overcome obstacles and fight back against enemies, although you’ll still have to look out for her (she’s not invincible like Ellie in The Last of Us).

Zeroing in on game mechanics, the big change is that the quick-time events that were such a big part of the original Resident Evil 4 experience are now mostly gone. They’ve been replaced with a new parry system, which will give players more control over how they react to things. Yes, the infamous Krauser knife fight is still in the game, but it will now be designed around this parry system (and can catch a glimpse of the fight via the latest RE4 remake trailer, below).

What are the PC requirements?

Thanks to the well-optimized RE Engine, the PC requirements for Resident Evil 4 aren’t too demanding (they’re essentially identical to RE Village).

Minimum

Requires a 64-bit processor and operating system

OS: Windows 10 (64-bit)

Processor: AMD Ryzen 3 1200 / Intel Core i5-7500

Memory: 8 GB RAM

Graphics: AMD Radeon RX 560 with 4GB VRAM / NVIDIA GeForce GTX 1050 Ti with 4GB VRAM

DirectX: Version 12

Network: Broadband Internet connection

Additional Notes: Estimated performance 1080p/60fps.

Recommended

Requires a 64-bit processor and operating system

OS: Windows 10 (64-bit)

Processor: AMD Ryzen 5 3600 / Intel Core i7 8700

Memory: 16 GB RAM

Graphics: AMD Radeon RX 5700 / NVIDIA GeForce GTX 1070

DirectX: Version 12

Network: Broadband Internet connection

Additional Notes: Estimated performance: 1080p/60fps

Ray Tracing Requirements

AMD Radeon RX 6700 XT or NVIDIA GeForce RTX 2070 required to support ray tracing.

Will there be a VR version?

Yes, Capcom has announced they’ve begun development on a VR mode for Resident Evil 4, but it won’t be available at launch.

Is The Mercenaries coming back?

Yes, Mercenaries mode is returning, but like VR, it won’t be available at launch.

Price and Special Editions

The standard edition of Resident Evil 4 will set you back $60. A $70 Deluxe Edition is also available, which includes a variety of additional cosmetics and bonus items.

Resident Evil 4 Deluxe Edition contents:

Attaché Case: 'Gold'

Attaché Case: 'Classic'

Charm: 'Handgun Ammo'

Charm: 'Green Herb'

Leon & Ashley Costumes: 'Casual'

Leon & Ashley Costumes: 'Romantic'

Leon Costume & Filter: 'Hero'

Leon Costume & Filter: 'Villain'

Leon Accessory: 'Sunglasses (Sporty)'

Deluxe Weapon: 'Sentinel Nine'

Deluxe Weapon: 'Skull Shaker'

Mini Soundtrack

'Original Ver.' Soundtrack Swap

Treasure Map: Expansion

Platforms of Release Date

Resident Evil 4 launches on PC, Xbox Series X/S, PS4, and PS5 on March 24.

Can I try before I buy?

Yes! The Resident Evil 4 ""Chainsaw Demo"" is available on all platforms now. It lets you play through the iconic opening battle against the infected villagers, after which, the demo resets. That said, you can play through the demo as many times as you want.","Software, Mobile, Analysis, Resident Evil 3 remake, Exclusives, Web, Finance, Security, Hardware, Interviews, Resident Evil 4, Gaming, Deals"
https://wccftech.com/roundup/wo-long-fallen-dynasty-everything-you-need-to-know-about-demon-slaying-in-ancient-china/,Wo Long: Fallen Dynasty – Everything You Need To Know About Demon Slaying In Ancient China,"Product Info Wo Long: Fallen Dynasty March 3rd, 2023 Platforms PC, PlayStation 4, PlayStation 5, Xbox One, Xbox Series S|X Publisher Koei Tecmo Developer Team Ninja Expected Price 59.99/69.99 Expected Release Date March 3rd, 2023

Team NINJA is a development studio that needs no introduction, having made some of the best action games ever released, such as the Ninja Gaiden series. In the past few years, however, the Japanese studio branched into action role-playing games, releasing some extremely solid titles like the Nioh games and Stranger of Paradise: Final Fantasy Origin. With complex role-playing game mechanics and loot systems having taken the spotlight for a few years in its games, it is not surprising to see the developer try to go back to its roots with Wo Long: Fallen Dynasty, a new action role-playing game where the actual action gameplay will take precedence over every other gameplay system.

Here's everything you need to know about this demon-slaying adventure set in ancient China.

Release Date, Platforms, Editions

Wo Long: Fallen Dynasty releases on PC via Steam and the Microsoft Store, PlayStation 5, PlayStation 4, Xbox Series X, Xbox Series S, and Xbox One on March 3rd, 2023. The game will also be available from day one on Xbox Game Pass for both Xbox consoles and PC.

Alongside the game's Standard Edition, which will cost $59.99 / €69.99 in the United States and Europe respectively, and will include the Zhuque and Baihu Armor as pre-order bonuses, a Digital Deluxe Edition will also be available for the price of $84.99 / €94.99. This special edition includes a copy of the game, a digital mini soundtrack, a digital art book, the Season Pass granting access to all paid expansion, as well as the Zhuque and Baihu Armor pre-order bonuses.

A limited-edition Wo Long: Fallen Dynasty Steelbook Edition will also be available when the game launches on March 3rd for $79.99 / €79.99. This edition will include a copy of the game and an exclusive collectible case alongside the bonus DLC items Crown of Zhurong and Crown of Gonggong.

2 of 9

Setting, Genre, Mechanics

Wo Long: Fallen Dynasty's setting will be familiar to fans of the Dynasty Warriors series, as the game by Team NINJA will be set in 184 AD during the final days of the Han Dynasty, right before the beginning of what is known as the Three Kingdoms period. Like in the Nioh series, Wo Long: Fallen Dynasty will combine fantasy elements with historical figures such as Lu Bu, Zhang Jue of the Yellow Turban Rebellion, Liu Bei, Cao Cao, and many others. These important figures in ancient Chinese history will either join the player or fight against him as they try to put an end to the influence of the mysterious Elixir, which has brought demons and corruption into the world.

Wo Long: Fallen Dynasty is a ""masocore"" action role-playing game in the vein of the Nioh series, but many are the differences between them. For starters, the game set in ancient China will feature more streamlined role-playing game mechanics, with fewer stats to enhance upon level-up and a simplified, easier-to-understand loot system that will still allow for ample customization.

With action game mechanics being in the spotlight again, Wo Long: Fallen Dynasty will feature fewer combat options. Gone are the three different stances seen in the Nioh series and the many assignable skills, replaced with a simple system that allows players to use up to four different elemental spells and two weapon skills, which change depending on the equipped weapon. The Deflection system, which allows players to deflect an enemy attack and leave them open for a short while, is also way more central than the parry systems seen in the Nioh games have ever been, as it also ties into the new Spirit System, which replaces the classic Stamina or Ki system. Managing this resource is extremely important not only to be able to attack with greater strength but also to use spells, skills, Deflection, and dodges and avoid getting stunned. As Spirit can also go into negative values, players must carefully evaluate when to take risks.

Wo Long: Fallen Dynasty will also feature an interesting take on difficulty settings with the Morale system. Players and enemies all have a Morale level which can increase or decrease depending on successful deflection, damage dealt, and so on. The higher the Morale level, the more powerful the player or the enemy will be, so it will be possible to influence the difficulty of battles somewhat using this dynamic system. The ability to summon NPC allies with ease, as well as other human players, will make sure players will never be stuck fighting a particular enemy for too long. Speaking of multiplayer features, PvP will also return for some intense dueling.

The Wo Long: Fallen Dynasty Morale System ties in nicely with the game's exploration mechanics. By exploring the stages fully, which now feature much better verticality thanks to the introduction of a jump button, players will be able to activate Battle and Marking Flags, which increase the base Morale level for the stage, which is extremely beneficial in case of defeat, as the player is reset to the base level every time they are defeated.

PC System Requirements, Console Display Modes

The Wo Long: Fallen Dynasty official PC system requirements were originally shared on the game's official website, detailing the specs required to run the game at 720p and 1080p resolutions. Upscaling technologies like NVIDIA DLSS and Intel XeSS will help players boost performance, but only sometime after launch.

quote

The PlayStation 5 and Xbox Series X|S versions of the game will come with two different display modes, Resolution Mode and Performance Mode that will prioritize either resolution, with a maximum output resolution of 4K, and performance, with a 60 FPS target. 120Hz modes will not be supported.

Trailers

Playable Demos

The first Wo Long: Fallen Dynasty demo was made available exclusively for PlayStation 5 and Xbox Series X|S for a limited time, allowing players to try out one of the game's early missions. Following the demo's release, Team NINJA asked for players' feedback, which was used to improve the experience, as highlighted in a survey.

A second playable demo featuring said improvements will be available on all formats from February 24th until March 27th. This demo will feature the final game's first two chapters, and all progress made in the demo can be carried over to the full release.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-ryzen-7000-x3d-cpus/,"AMD Ryzen 7000 X3D CPUs, The 2nd Gen 3D V-Cache Gaming Chips – Here’s Everything We Know So Far","Product Info AMD Ryzen 7000 X3D 28th February, 2023 Manufacturer AMD Type CPUs Platforms PC Expected Price $449 US+ Expected Release Date 28th February, 2023

After showing the world how much of a benefit 3D V-Cache can be to gamers, AMD is now all set to launch its 2nd Gen 3D V-Cache chips, the Ryzen 7000 X3D. Launching later this month, the Zen 4 3D V-Cache CPUs are expected to bring similarly massive gaming performance increments and we are going to talk about what you can expect in terms of specifications, performance, and prices.

AMD Ryzen 7000 X3D 'Zen 4' CPUs: Bringing 3D V-Cache Goodness To The Zen 4 Architecture & AM5 Platform

Last year, AMD introduced the Ryzen 7 5800X3D, a CPU that was designed to offer the best value and performance to gamers by leveraging 3D V-Cache technology which allows AMD to stack large pools of cache on top of Zen chiplets, driving up performance in bandwidth starved games & applications. The benefit was clear right from the beginning with reviews showing a huge gaming performance boost that matched and even exceeded Intel's fastest CPU, the Core i9-12900K, at the time.

With the Ryzen 7000 X3D parts, AMD plans to repeat that and give gamers another boost that could potentially make AM5 the fastest platform to game on.

AMD Ryzen 7000 X3D 'Zen 4' 3D V-Cache Desktop CPUs Expected Features:

Minor optimization on TSMC's 5nm process node

Up to 64 MB of Stacked cache per CCD (96 MB L3 per CCD)

Increase In Gaming Performance (Avg & Mins)

Compatible With AM5 Platforms

AMD Ryzen 7000 X3D CPU Lineup & Specifications

The AMD Ryzen 7000 3D V-Cache CPUs are the 2nd generation consumer V-Cache parts featuring stacked cache. While the Zen 3 lineup featured just one 3D V-Cache SKU, the Zen 4 lineup is getting three SKUs at vastly different prices.

AMD Ryzen 9 7950X3D - 16 Cores With 144 MB Cache

Starting at the top, we have the AMD Ryzen 9 7950X3D which will be the flagship and the first 16-core CPU to feature 3D V-Cache technology. The chip will incorporate a total of 32 threads, a total of 144 MB cache (64 MB CCD, 64 MB V-Cache + 16 MB L2), and a TDP of 120W. As for the clocks, the chip is rated at a base clock of 4.2 GHz which is 300 MHz slower than the standard 7950X but boost clocks are rated at the same 5.7 GHz. This should give us a hint at why the TDP is 50W lower versus the Non-3D part.

The way AMD is arranging the 3D V-Cache structuring on the Ryzen 9 X3D parts is by putting the SRAM cache on a single CCD instead of both CCDs. This way, AMD can maximize the performance in gaming through a single CCD while retaining the secondary die to benefit from the higher clock speeds (1T). This means that there should be a balance of single-threaded gaming performance & multi-threaded applications without sacrificing overall clock speeds like the previous gen. This is first and foremost a gaming chip so the cache die is the more important aspect to optimize. It'll be rather interesting to see how things pan out in the final retail units and just how far AMD enables tuning on the new parts.

AMD Ryzen 9 7900X3D - 12 Cores With 140 MB Cache

The second chip is the AMD Ryzen 9 7900X3D which will feature 12 cores and 24 threads. This is also a 2 CCD configuration with one CCD configured with the V-Cache and the second without it. The chip features a total of 140 MB cache (64 MB CCD, 64 MB V-Cache + 12 MB L2). The clocks are rated at a 4.4 GHz base which is 200 MHz slower than the Non-3D SKU & the boost clock remains the same at 5.6 GHz. The CPU is also rated at a TDP of 120W.

AMD Ryzen 7 7800X3D - Replacing The 5800X3D As The New Gaming Champ!

Lastly, we have the successor to the Ryzen 7 5800X3D, and the Ryzen 7 7800X3D. This CPU is going to be the ideal choice for gamers with 8 cores, 16 threads, and the same 104 MB of cache (32 MB CCD, 64 MB V-Cache + 8 MB L2). The CPU comes with a base clock of around 4 GHz which could end up at least 500 MHz slower than the Ryzen 7 7700X and a boost clock of 5.0 GHz which is 400 MHz slower than the Ryzen 7 7700X.

AMD Ryzen 7000 Raphael Desktop CPU Specs:

CPU Name Architecture Process Node Cores / Threads Base Clock Boost Clock (SC Max) Cache TDP Prices (Updated 6/05/23) AMD Ryzen 9 7950X3D Zen 4 3D V-Cache 5nm 16/32 4.2 GHz 5.7 GHz 144 MB (64+64+16) 120W $627 US AMD Ryzen 9 7950X Zen 4 5nm 16/32 4.5 GHz 5.7 GHz 80 MB (64+16) 170W $540 US AMD Ryzen 9 7900X3D Zen 4 3D V-Cache 5nm 12/24 4.4 GHz 5.6 GHz 144 MB (64+64+12) 120W $459 US AMD Ryzen 9 7900X Zen 4 5nm 12/24 4.7 GHz 5.6 GHz 76 MB (64+12) 170W $419 US AMD Ryzen 9 7900 Zen 4 5nm 12/24 3.6 GHz 5.4 GHz 76 MB (64+12) 65W $365 US AMD Ryzen 7 7800X3D Zen 4 3D V-Cache 5nm 8/16 4.0 GHz 5.0 GHz 104 MB (32+64+8) 120W $406 US AMD Ryzen 7 7700X Zen 4 5nm 8/16 4.5 GHz 5.4 GHz 40 MB (32+8) 105W $295 US AMD Ryzen 7 7700 Zen 4 5nm 8/16 3.6 GHz 5.3 GHz 40 MB (32+8) 65W $270 US AMD Ryzen 5 7600X Zen 4 5nm 6/12 4.7 GHz 5.3 GHz 38 MB (32+6) 105W $240 US AMD Ryzen 5 7600 Zen 4 5nm 6/12 3.8 GHz 5.1 GHz 38 MB (32+6) 65W $215 US

AMD Ryzen 7000 X3D CPU Performance

In terms of performance, AMD hasn't shared a whole lot of data which is fair since they want the independent tech industry to test these chips out later this month and showcase their own data rather than relying on official figures. We did get to see performance numbers for the two Ryzen 7000 X3D CPUs, the Ryzen 9 7950X3D and Ryzen 7 7800X3D.

AMD compared the Ryzen 9 7950X3D CPU to Intel's top Core i9-13900K across several gaming and workload apps. The results show that the 3D V-Cache chip can offer up to 24% faster performance in gaming at 1080p with high image quality. Following are the game tests and the respective gains over the 13900K CPU:

AMD Ryzen 9 7950X3D Gaming Performance Test (via AMD):

Watch Dogs Legion (1080p) - Up To 9% Faster

Up To 9% Faster DOTA (1080p) - Up To 11% Faster

Up To 11% Faster Rainbow Six Siege (1080p) - Up To 13% Faster

Up To 13% Faster Horizon Zero Dawn (1080p) - Up To 24% Faster

As we mentioned above, the 7950X3D chips have a different CCD configuration with one running at higher clocks and the other with conservative limits set in place due to the 3D V-Cache stacking. But that doesn't change the overall performance a lot even in workload apps as the chip can outclass a Core i9-13900K CPU in various tests as shown below:

AMD Ryzen 9 7950X3D Workload Performance Test (via AMD):

File Encryption (VeraCrypt AES) - Up To 4% Faster

Up To 4% Faster 3D Graphics (PassMark 10) - Up To 11% Faster

Up To 11% Faster Adobe Premiere Pro (Playback) - Up To 17% Faster

Up To 17% Faster DaVinci Resolve (Extended Score) - Up To 24% Faster

Up To 24% Faster File Compression (7-Zip) - Up To 52% Faster

Lastly, we have the AMD Ryzen 7 7800X3D which has been compared against the Ryzen 7 5800X3D and the results are even more impressive. Using the same 1080p resolution and high-quality preset across various games, the CPU scored a gaming performance lead of up to 30% versus the first-gen X3D CPU. The gains can be seen below:

Rainbow Six Siege (1080p) - Up To 21% Faster

Up To 21% Faster Warhammer Dawn of War III (1080p) - Up To 22% Faster

Up To 22% Faster CS:GO (1080p) - Up To 23% Faster

Up To 23% Faster Dota 2 (1080p) - Up To 30% Faster

These are definitely big gains for gamers and the addition of the Ryzen 9 parts means that users will not only have the fastest gaming performance around but also the fastest content creation perf. There are also going to be some big uplifts to the minimum FPS range thanks to V-Cache which AMD's not showing yet but we can't wait to see more detailed performance numbers.

AMD Ryzen 7000 X3D CPU Power & Thermals

The power and thermal limits play an important role in the development of 3D V-Cache chips. The stacked V-Cache chips are unlike your regular Ryzen CPU since the SRAM itself is a very fragile chip component to work with. Hence, AMD has lowered down the overall TDP, locked down the voltage, and also lowered the temperature thermal limits otherwise known as TjMax.

The current Zen 4 lineup is currently rated at a TjMax of 95C and while the CPUs can easily hit that target, AMD confirms customers have nothing to worry about since this kind of operation is within spec. These high-temperature limits seem to be the norm for AMD these days as their GPUs also have a peak temperature limit of up to 110C which is considered as 'Normal Spec'.

The trio of AMD Ryzen 7000 X3D CPUs which include the Ryzen 9 7950X3D, Ryzen 9 7900X3D, and the Ryzen 7 7700X3D has been listed with a TjMax of just 89C which is 6C lower than the 95C TjMax of the Ryzen 7000 Non-3D CPUs.

AMD has a maximum voltage of the Ryzen 7000 X3D CPUs set at 1.4V which is a 0.3V increase over the Ryzen 7 5800X3D (1.1V). The new CPUs will come with auto OC options such as PBO and Curve Optimizer but the reason manual overclocking is restricted is due to the volatile nature of the 3D V-Cache stacked on top of the singular CCD. Both high voltages & high temperatures can lead to abnormal behavior or even damage the chip.

The hybrid layout of the dual CCD SKUs such as the Ryzen 9 7950X3D & Ryzen 9 7900X3D is already being optimized in the Windows 11 OS but it remains to be seen how high temperatures will affect the clock operation on these parts. You will definitely require some high-end cooling solutions to stay within the 89C limit. That might also explain why AMD chose to go with a lower 120W TDP on the higher-end SKUs to limit them from using excess power and running into the thermal wall. As expected, manual overclocking is a big No-No but AMD has done something that wasn't possible on the first-gen 3D parts and that's enabling Curve Optimizer and PBO support.

AMD Ryzen 7000 X3D Overclocking

Yes, Curve Optimizer and Precision Boost Overdrive overclocking features along with AMD EXPO memory support will be available across all three Ryzen 7000 X3D CPUs. AMD is recommending users go with Curve Optimizer as it delivers the best balance of overall CPU performance but hard frequency overclocking is locked just like the previous generation Zen 3D V-Cache chips.

AMD Ryzen 7000 X3D CPU Support

All AMD Ryzen 7000 X3D CPUs will be supported by AM5 motherboards. Users will have to require a manual BIOS firmware update & install the latest chipset drivers to ensure the best compatibility on the new hardware. There will also be new motherboards released this month that will support these CPUs without any BIOS updates.

AMD Ryzen 7000 X3D CPU Pricing & Availability

Lastly, we have the pricing and availability. The AMD Ryzen 9 X3D CPUs will be the first to hit retail shelves on the 28th of February followed by the Ryzen 7 X3D CPU which is expected to hit retail on the 6th of April so just over a month later. It can be seen that AMD wants to target premium users first before they enter the market with the sub-$500 US mainstream X3D solution. Having that out immediately would make it eat up the sales of the higher-end parts as is the case with the 5800X3D which has been the top-selling CPU at various retailers for several months owing to its unbeatable price-to-performance value in the gaming segment.

The AMD Ryzen 9 7950X3D will feature a price of $699 US at launch which is the same MSRP that the standard 7950X had before it was slashed down to $599 US. That's $100 US more than the i9-13900K from Intel.

The AMD Ryzen 9 7900X3D will feature the same pricing as the now 7950X at $599 US and will be launching with the 7950X3D on the 28th of February. It looks like AMD sees the 7900X3D sitting comfortably ahead of the i9-13900K at the same price point in gaming.

Lastly, we have the AMD Ryzen 7 7800X3D with a price of $449 US. That's around $100 US more than the Ryzen 7 7700X and $30 US higher than the Core i7-13700K but once again, this is the chip that many gamers have set their eyes on and it has the potential to be a truly disruptive gaming product by AMD.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/forspoken-everything-you-need-to-know-about-freys-journey-through-athia/,Forspoken – Everything You Need To Know About Frey’s Journey Through Athia,"Product Info Forspoken January Platforms PC, PS5 Publisher Square Enix Developer Luminous Productions Expected Price 69.99 Expected Release Date January

Square Enix has been on a roll in 2022 when it comes to both quantity and quality, and 2023 looks great, too, as the Japanese publisher is set to release multiple high-profile titles, starting with Forspoken, an open-world RPG developed by Luminous Productions (the team behind Final Fantasy XV). Attempting to improve the gameplay formula seen in FFXV through various additions, Forspoken is setting out to be an interesting product and a great way to kick off a year that could be among the best for video game releases.

Release Date, Platforms, Editions

Forspoken will release on January 24th, 2023, on PC via Steam and the Epic Games Store and PlayStation 5. The game was originally supposed to release on May 24th, 2022, but was later delayed to October 11th, 2022 before getting moved again to January 24th. The delays allowed the team to further polish the game to offer the best experience possible.

Forspoken will release both digitally and at retail. The standard retail edition, which is available for $69.99 in the United States and €79.99 in Europe, doesn't include any additional goodies. Still, it does come with retailer-exclusive pre-order bonuses such as the Best Buy exclusive free steelbook case and the GameStop exclusive premium character card set.

On the other hand, the Forspoken Digital Edition comes with different in-game exclusive bonuses on PC and PlayStation 5. The PC Digital Edition includes the Elite Cloak, Spectra Combo Necklace, and Overclock Nails, while the PlayStation 5 Digital Edition includes the No Limits Cloak, Symbol Combo Necklace, Trigger Happy Nails, and Crafting Starter Kit. No matter the format, the Digital Edition costs $69.99 in the United States and €79.99 in Europe.

A Forspoken Digital Deluxe Edition is also launching on PC and PlayStation 5. This edition, which costs $94.99 in the United States and €104.99 in Europe, includes a Mini Artbook, Mini Soundtrack, and the prequel story DLC In Tanta We Trust, with early access. The PlayStation 5 Digital Deluxe Edition also includes the Rare Resource Kit.

Setting, Genre, Mechanics

Forspoken stars Frey Holland (played by Ella Balinska, who recently starred in the short-lived Resident Evil Netflix TV show), a 20-year-old woman who is good-hearted and smart, albeit a little immature. Having had a difficult upbringing through the foster care system, she mistrusts the world around her, using sarcasm and humor as a defense against the perceived hostile world. Her life, however, suddenly changes on the day she is transported from her hometown of New York City to the magical and mysterious world of Athia.

Athia was once a peaceful land until a miasma plague widely known as The Break suddenly spread across the world, causing humans and animals to become monsters. The Break corrupts even the land itself, except for the haven city of Cipal. However, Frey is mysteriously immune to the plague and also gains incredibly powerful magic abilities when she finds the sentient bracelet Cuff (voiced by Jonathan Cake). At first, Frey just wants to go home, but eventually she is persuaded by the people of Athia to exploit her unique powers to rid the land of all evil.

The Break also corrupted the rulers of Athia, the Tantas, once beloved and powerful sorceresses. who each embody a different virtue and have unique strengths. So far, Square Enix shared information on Tanta Sila (voiced by Janina Gavankar, already seen as Iden Versio in Star Wars: Battlefront II), the strongest of all the Tantas and former commander of the Athian Army, and Tanta Prav (voiced by Pollyanna McIntosh, already seen as Shelob in Middle-earth: Shadow of War), known as the wisest of the group before the corruption.

The lore and story of Forspoken were penned by a rather famous team of writers, such as Gary Whitta (Rogue One: A Star Wars Story), Todd Stashwick (12 Monkeys), Allison Rymer (Shadowhunters: The Mortal Instruments), Amy Berg (Jack Ryan, Warrior Nun), Anne Toole (Horizon: Zero Dawn, Horizon: Forbidden West, Days Gone), and Amy Hennig (Legacy of Kain: Soul Reaver, Uncharted). The music was composed by Bear McCreary (Call of Duty: Vanguard, God of War Ragnarök) and Garry Schyman (BioShock, Middle-earth: Shadow of Mordor).

Luminous Productions is, of course, handling the gameplay. Since it's the same studio behind Final Fantasy XV, Forspoken shares a few similarities with that game, starting from its open-world setting. Athia is a big world, and players can explore the full extent of the map using Frey's special magical parkour abilities, which allow her to speed up regular traversal speed, scale mountains, and so on. As it is now obligatory for open-world games, Forspoken will feature a lot of different points of interest scattered all over the map, as well as main and optional story quests. According to the developer, it takes around 30 hours to complete the main story, although players will still want to complete side content, as optional quests will take them to areas that are not explored during the main story.

Alongside magical parkour, another of the features that sets Forspoken apart from other open-world games is its combat system. Frey can use different types of magic to defeat enemies. Alternating between long-range and short-range spells will be extremely important, as enemies are weak against certain types. With a vast selection of offensive and support spells (said to be over 100 in total), combat in Forspoken promises to be extremely varied and definitely has the potential to stay fresh for a long time. The game also rewards players for a good performance in battle, in the vein of the Devil May Cry series and other character-action games, pushing users to perform as best as they can during fights.

Playable Demo

PlayStation 5 owners don't have to wait until the game's release date to see what Forspoken is all about, as a playable demo is now available for download from the PlayStation Store in all regions. The demo, unlike a few others, doesn't allow players to carry over their progress over the full version of the game. It's not even cut from the actual game, so the area available in the demo has been handcrafted separately for this purpose. Nonetheless, it is still a good way to get accustomed to the game's unique mechanics before it launches.

There is no information on the availability of a PC demo.

Trailers

PC System Requirements

The Forspoken official PC system requirements have been officially revealed on January 17th, 2023. Being the first title to officially support Microsoft's DirectStorage technology, an NVMe SSD is among recommended requirements, although it's still possible to play the game on a regular HDD. Direct Storage will be available under Windows 11 only.

Minimum Recommended Ultra 4K OS Windows® 10 64-bit (After November 2019 Update) or Windows® 11 64-bit AMD Ryzen™ 5 1600 (3.7GHz or better) AMD Ryzen™5 3600 (3.7 GHz or better) AMD Ryzen™5 5800X (3.8 GHz or better) CPU Intel Core™ i7-3770 (3.7GHz or better) Intel® Core™ i7-8700K (3.7GHz or better) Intel Core™ i7-12700 Video Card AMD Radeon™ RX 5500 XT 8GB AMD Radeon™ RX 6700 XT 12GB AMD Radeon™ RX 6800 XT 16GB NVIDIA® GeForce GTX 1060 6 GB VRAM NVIDIA GeForce RTX 3070 8 GB VRAM NVIDIA® GeForce® RTX 4080 16 GB VRAM Memory 16GB 24GB 32GB Display resolution 720p 30fps 1440p 30fps 2160p 60fps HDD/SSD space HDD 150GB or more SSD 150GB or more NVMe SSD 150GB or more

The PC version of Forspoken will also support both the DualShock 4 and DualSense controllers, as well as any DirectInput or Xinput controllers, keyboard and mouse controllers, dynamic refresh rate and Auto HDR under Windows 11, ultrawide resolutions up to 32:9 and 7.1 audio.

Square Enix and Luminous Productions partnered with AMD on the PC version. The developers confirmed the following FidelityFX features:","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/hogwarts-legacy-everything-you-need-to-know-about-this-wizarding-adventure/,Hogwarts Legacy – Everything You Need To Know About This Wizarding Adventure,"2023 is setting out to be another great year for open-world role-playing games, thanks to the many games launching this year, including Avalanche Software's long-anticipated Hogwarts Legacy. Set in the Wizarding World, the game is a dream come true for all Harry Potter fans, as it will allow them to attend the legendary school of witchcraft and wizardry and live out their virtual life as if they were Harry Potter, Hermione Granger, Ron Weasley or any of the other iconic characters that have made the franchise one of the most popular ever.

If you are considering enrolling in Hogwarts but are still unsure about what a magical education entails, you have come to the right place. Here is everything you need to know about Hogwarts Legacy.

Release Date, Platforms, Editions

Hogwarts Legacy was originally announced during the September 2020 PlayStation 5 Showcase, but the game was already known to be in the works, as a mysterious trailer for a Harry Potter game leaked online in 2018. Originally scheduled for a 2021 release on PC (Steam, Epic Games Store), PlayStation 5, PlayStation 4, Xbox Series X, Xbox Series S, Xbox One, and Nintendo Switch, the open-world RPG by Avalanche Software was first delayed to 2022 and then later to February 10th, 2023. This wasn't the last of the delays for owners of old-generation consoles, as the game was further delayed on PlayStation 4 and Xbox One until April 4th, 2023. The Nintendo Switch version will be the last to release on July 25th, 2023.

Multiple Hogwarts Legacy editions will be available when the game launches on PC and current generation consoles on February 13th. The Standard Edition will include a copy of the game and the Onyx Hippogriff Mount as a pre-order bonus. The PlayStation 5 Standard Edition (and PlayStation 4 edition once it launches) will also include an exclusive quest, The Haunted Hogsmeade Shop quest, and the Felix Felicis potion recipe pre-order bonus.

The Hogwarts Legacy Deluxe Edition features some additional bonuses, such as 72-hours early access to the game and the Dark Arts pack featuring the Thestral Mount, the Dark Arts Battle Arena, the Dark Arts Cosmetic Set, and the Dark Arts Garrison Hat. The Dark Arts pack will also be made available for separate purchase.

The Hogwarts Legacy Collector's Edition will feature even more goodies on top of those offered in the Deluxe Edition. The game's ultimate edition will include a life-size figurine of a floating magic wand with a book base, a steel case, and the Kelpie Robe cosmetic DLC.

Setting, Genre, Mechanics

Hogwarts Legacy will be a single-player, open-world RPG set in the Wizarding World. Still, players shouldn't expect to meet many familiar faces outside of ghosts like Nearly Headless Nick, Peeves, and Professor Cuthbert Binns, as the game is set in the late 1800s, 100 years before the events of the Harry Potter novels. In this original story, players will take control of their custom-created character (including transgender options) as they start their fifth year at Hogwarts after surviving a mysterious incident.

This student has been granted late admittance as they are tied to ancient magic that could help deal with the goblin rebellion led by Ranrok and the Dark wizard Victor Rookwood. Both seek magic that wizards are trying to hide, which could lead to the end of the Wizarding World if it falls into the wrong hands. Harry Potter author J.K. Rowling is not directly involved in creating the game's story, as the developer is merely using her work as a foundation.

While Harry Potter fans shouldn't expect to meet the characters they have come to love over the years, school life in Hogwarts Legacy is sure to feel quite familiar. After creating their character, which can be customized in a variety of ways, players will be able to pick their House, attend classes to learn new spells, how to brew potions, how to defend against the Dark Arts, and so on, met fellow students and teachers and deepen their bonds with them. Getting to know students like Natsai Onai, Poppy Sweeting, and Sebastian Sallow better will come with plenty of benefits, as they will be able to teach you new spells and abilities and even follow you on your adventures as companions.

Magic spells will obviously play a major role in the Hogwarts Legacy experience. With the game featuring a major assortment of spells, players can approach the game's many combat challenges and puzzles in different ways. Whether you want to face your enemies head-on or take them out one by one stealthily, Hogwarts Legacy will offer you plenty of powerful options, although different approaches will be required depending on the situation. And if the dark arts are more to your liking, you can go down that path, as Hogwarts Legacy grants you ample freedom in how you want your live your wizarding life. The game will also deliver a solid challenge, as all gameplay showcases released before launch were played at normal difficulty by an expert player.

Combat, however, will only be a small part of what Hogwarts Legacy will offer to up-and-coming witches and wizards. When not busy with classes and assignments, players will be able to explore not only the entirety of the school, which will feature all of the iconic locations seen in the movies, such as the Hogwarts Houses common rooms, as well as some never-seen-before ones, but also the village of Hogsmeade and other smaller villages filled with NPCs and quests to complete. With multiple travel options available, including brooms and magical beasts like hippogriffs, exploring the beautiful world of Hogwarts Legacy will be as engaging as taking down enemies and completing all sorts of puzzles using your magic spells. While broom flight and broom racing challenges are in the game, Quidditch won't be available.

Customization options in Hogwarts Legacy won't be limited to the main character, as the game will feature the Room of Requirement, the main living space that can be fully customized with different cosmetic options. Additionally, it will be possible to add items like a potion station, gardens, and more to make Room of Requirement more than just a fancy room to visit every now and then. Also accessible via the Room of Requirement will also be the Vivarium, a place where your character will be able to interact with rescued beasts.

Voice Cast

Hogwarts Legacy will feature an all-star voice cast that will bring its characters to life. Playing the Headmaster of the Hogwarts School of Witchcraft and Wizardry Phineas Nigellus Black is renowned British actor Simon Pegg (Shaun of the Dead, Hott Fuzz, Star Trek). He is joined by Luke Youngblood, who returns to the Harry Potter universe to voice Everett Clopton, Sebastian Croft, and Amelia Gething, who play the playable avatar, Lesley Nicol, who plays professor Matilda Weasley, Kandace Caine, who plays professor Onai, Sohm Kapila, who voices professor Satyavati Shah, Asif Ali, who voices Amit Thakkar, Adam O' Connor, who voices Mahendra Pehlwaan, and Jason Anthony, who voices Nearly Headless Nick and the Sorting Hat.

PlayStation 5 Exclusive Features

Hogwarts Legacy will take full advantage of the PlayStation 5 exclusive features to offer a more immersive experience. The DualSense adaptive triggers allow for more flexibility in combat, while haptic feedback will also make each spell feel unique, isolating all of the effects to the right side of the controller to simulate the main character holding their wand in their right hand. Many other in-game activities, such as crushing ingredients for potions or flying around, will have their matching haptic feedback, further enhancing immersion. The DualSense controller light will also flash when using spells and show a glowing color of your chosen House when not in combat. These features may be available on PC as well when using a DualSense controller, as with other titles.

The PlayStation 5 version of Hogwarts Legacy will also come with two display modes, Fidelity and Performance, which will target 4K resolution and 60 frames per second gameplay, as well as support for Activity Cards and Game Help features.

PC System Requirements

While Hogwarts Legacy will run on a variety of system configurations, the system requirements, both minimum and recommended, are slightly higher than expected, considering it is a cross-gen title. While the game supports HDDs, an SSD is recommended to reduce load times and make the experience as smooth as possible. Upscaling technologies such as AMD FSR and NVIDIA DLSS will be supported, including the new DLSS 3.0, which RTX 40xx cards owners can use for even better performance.

Minimum

OS: Windows 10

Windows 10 Processor: Intel Core i5-8400 OR AMD Ryzen 5 2600

Intel Core i5-8400 OR AMD Ryzen 5 2600 Memory: 8 GB RAM

8 GB RAM Graphics: NVIDIA GeForce GTX 1070 or AMD RX Vega 56

NVIDIA GeForce GTX 1070 or AMD RX Vega 56 DirectX: Version 12

Version 12 Storage: 85 GB available space

85 GB available space Additional Notes: SSD (Preferred), HDD (Supported), 1080p/60 fps, Low Quality Settings, Upscale Performance Setting

Recommended

OS: Windows 10

Windows 10 Processor: Intel Core i7-8700 OR AMD Ryzen 5 3600

Intel Core i7-8700 OR AMD Ryzen 5 3600 Memory: 16 GB RAM

16 GB RAM Graphics: NVIDIA GeForce 1080 Ti or AMD RX 5700 XT

NVIDIA GeForce 1080 Ti or AMD RX 5700 XT DirectX: Version 12

Version 12 Storage: 85 GB available space

85 GB available space Additional Notes: SSD, 1080p/60 fps, High Quality Settings, Upscale Quality Setting

ULTRA:

OS: 64-bit Windows 10

64-bit Windows 10 Processor: Intel Core i7-10700K (3.8 GHz) or AMD Ryzen 7 5800x (3.8 GHz)

Intel Core i7-10700K (3.8 GHz) or AMD Ryzen 7 5800x (3.8 GHz) Memory: 32 GB RAM

32 GB RAM Graphics: NVIDIA GeForce RTX 2080Ti or AMD Radeon RX 6800 XT

NVIDIA GeForce RTX 2080Ti or AMD Radeon RX 6800 XT DirectX: Version 12

Version 12 Storage: 85 GB SSD

85 GB SSD Additional Notes: SSD, 1440p/60 fps, Ultra Quality Settings

ULTRA 4K:

OS: 64-bit Windows 10

64-bit Windows 10 Processor: Intel Core i7-10700K (3.8 GHz) or AMD Ryzen 7 5800x (3.8 GHz)

Intel Core i7-10700K (3.8 GHz) or AMD Ryzen 7 5800x (3.8 GHz) Memory: 32 GB RAM

32 GB RAM Graphics: NVIDIA GeForce RTX 3090Ti or AMD Radeon RX 7900 XT

NVIDIA GeForce RTX 3090Ti or AMD Radeon RX 7900 XT DirectX: Version 12

Version 12 Storage: 85 GB SSD

85 GB SSD Additional Notes: SSD, 2160p/60 fps, Ultra Quality Settings

Trailers and Gameplay Showcases","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/dead-space-remake-everything-you-need-to-know-about-this-refreshed-horror/,Dead Space Remake – Everything you Need to Know About this Refreshed Sci-Fi Shocker,"Product Info Dead Space January 27, 2023 Platforms PC, Xbox Series X/S, PlayStation5 Publisher Electronic Arts Developer Motive Studio Expected Price $69.99 Expected Release Date January 27, 2023

For years, fans of the Dead Space franchise didn’t have much to be excited about. Following 2013’s Dead Space 3, it seemed like EA was happy to let the horror franchise languish. Then, rather suddenly, everything changed. A new Dead Space successor from series co-creator Glen Schofield, entitled The Callisto Protocol, was unveiled in late 2020, and then a remake of the original Dead Space from Montreal-based developer Motive Studio was announced by EA only a few months later. The Callisto Protocol was released just weeks ago to somewhat mixed reviews, but fans don’t have to wait long for a bloody second course, as the Dead Space remake arrives in a few weeks.

The Dead Space remake sticks closely to the original game’s blueprint but expands some elements of the story and adds new features like a seamless open world, dynamic horror events, and even more gruesome combat. Will this new slice of sci-fi terror make you sweat as the original did? Here’s everything you need to know about the Dead Space remake…

Price and Special Editions

The standard edition of Dead Space will cost $70 on Xbox Series X/S and PS5. Surprisingly, PC players get a bit of a deal, as the game only costs $60 on that platform. For $10 more, there is a Digital Deluxe Edition that includes the following cosmetics:

3x Unique Suits (Infested, Lone Survivor, Venture)

2x Suit Textures (Sanctified, Bloody)

There is also a $275 Dead Space Collector’s Edition being offered by Limited Run Games. It includes a wearable version of Isaac’s helmet, prints, posters, and more. Get the full rundown below.

Dead Space Collector's Box

Physical Copy of Dead Space (not included in the PC version)

Isaac Helmet (full-size and wearable, with working lights)

Dead Space CD Soundtrack

Lithograph Print

Foil Stamped Lithograph Folio

Four Mini Posters

Ishimura Patch

Marker Enamel Pin

Metal 4"" Marker Statue

Dead Space SteelBook

Platforms and Release Date

Dead Space launches on PC, Xbox Series X/S, and PS5 on January 27, 2023. You can pre-order here.

Will Dead Space also come to last-gen platforms?

While there have been hints it could happen, nothing has been announced, so don’t count on it.

Setting and Story

The Dead Space remake once again casts players as Isaac Clarke, a regular working-class systems engineer who is part of a team sent to investigate when the massive “planetcracker” ship USS Ishimura stops sending signals. Upon arriving, it’s soon discovered most of the people on the Ishimura have been transformed into grotesquely-mutated undead “Necromorophs” created by an artifact called the Marker. As Isaac’s crew drops like flies, he must find a way to survive the horrors of the Ishimura on his own.

EA Motive is largely sticking to familiar plot beats with the Dead Space remake rather than offering a full reimagining ala Capcom’s Resident Evil remakes. That said, an all-new script has been written for the remake, largely because Isaac Clarke is no longer a silent protagonist. Some moments are also being restaged for greater impact, and aspects of the story – the fate of certain characters and some info about the world – have been expanded. Consider this a “director’s cut” – same story, but with more detail added to the margins.

How is the game staying the same?

For the most part, it seems this will be Dead Space as you remember it. An atmospheric Metroidvania survival horror game with a unique combat system. Unlike your typical horror game featuring undead monsters, aiming for the head isn’t the goal in Dead Space – instead, you’ll use unique weapons like the iconic plasma cutter to slice off necromorphs' arms and legs before finishing them off. Overall, you can expect the progression and flow of Dead Space’s campaign to be largely unchanged.

How is the game changing?

While EA Motive isn’t reinventing the wheel, they are updating the Dead Space experience in many ways beyond just improving the graphics. Arguably the biggest change is that the Ishimura is now a fully seamless open world, rather than the more segmented map connected by trams and elevators offered by the original game. This means some new connective areas have been created, which in turn led to the new Dead Space’s other big innovation – the Intensity Director. Motive wanted to make sure getting around the newly-expanded map didn’t get repetitive, so the Intensity Director will keep you on your toes by serving up a variety of dynamic events. Motive promises 1200 possible events, ranging from simple flickering lights and surprise enemy attacks to trippy “psychosis events.” According to the developers, the goal is to create dynamic moments that feel almost as intense as the game’s scripted events.

And the additions don’t end there. Necromorph dismemberment has been made even grosser with the new “peeling” system that allows you to strip the flesh off enemies in realistic ways. You’ll also have much greater control during the game’s zero-G sequences. This is a lot more than a straight remaster.

What are the PC Requirements?

While we don’t have high-end specs yet, the following Minimum and Recommended PC requirements have been revealed.

Minimum

Requires a 64-bit processor and operating system

OS: Windows 10 64-bit +

Processor: Ryzen 5 2600x, Core i5 8600

Memory: 16 GB RAM

Graphics: AMD RX 5700, GTX 1070

DirectX: Version 12

Network: Broadband Internet connection

Storage: 50 GB available space

Recommended","The Callisto Protocol, Software, Mobile, Analysis, Exclusives, Web, Finance, Dead Space, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/fire-emblem-engage-everything-you-need-to-know-guide/,Fire Emblem Engage – Everything You Need to Know About this Colorful Conflict,"Product Info Fire Emblem Engage January 20, 2023 Platforms Nintendo Switch Publisher Nintendo Developer Intelligent Systems, Koei Tecmo Expected Price $59.99 Expected Release Date January 20, 2023

The Fire Emblem series has gone from niche to legitimately mainstream over the past few years, with 2019’s Fire Emblem: Three Houses standing as the best-selling entry in the series to date and Fire Emblem Heroes being Nintendo’s highest-grossing mobile game. So, while a new entry in the series might have come and gone without too much fanfare outside of a certain hardcore fanbase in the past, the upcoming Fire Emblem Engage has a lot of eyes on it.

Featuring a vivid anime-infused presentation and a new “Engage” system that sees units teaming up with favorite characters of the past like Marth, Roy, and Lyn, Fire Emblem Engage looks to be a bit of a departure from other recent entries in the series. Will this new approach light your fire? Here’s everything you need to know about Fire Emblem Engage…

Setting and Story

Fire Emblem Engage takes place in the never-before-seen land of Elyos, which is divided between four nations that surround the holy island of Lythos. Players take on the role of the “Divine Dragon” in human form (named Alear officially, although you can determine your name and gender). After sleeping for a thousand years, you awaken to find the Fell Dragon has been revived by the nation of Elusia. It’s up to you to stop the Fell Dragon and Elusian forces from claiming the 12 Emblem Rings, which would return the Fell Dragon to its full power. Along the way, you’ll meet a wide range of colorful characters and weather various twists, turns, and setbacks, but that’s all in a day’s work for a good commander.

Does the tone feel a little different this time around?

It does indeed seem like Nintendo and developer Intelligent Systems are trying out something new here. The Fire Emblem series has a reputation for being more grounded and politically and morally complex than your average JRPG or Nintendo game. Some have even described it as “anime Game of Thrones.” Fire Emblem Engage, on the other hand, looks to stick to more traditional JRPG tropes and storytelling. Whether the series going full anime is a good thing or not will largely come down to personal taste.

Combat Gameplay

For the most part, Fire Emblem Engage adheres to series’ familiar blueprint when it comes to combat. This is a tactical RPG in which you and the enemy take turns moving all available units on various grid-based maps. Your units all have individual strengths, weaknesses, personalities, and backstories, rather than just being random grunts. Various rock-paper-scissors-style systems, most notably the classic Weapon Triangle (swords beat axes, axes beat lances, lances beat swords), are in place and will need to be kept in mind if you want to win the day.

The big addition is the new Engage system. As you progress through the story you’ll collect a number of Emblem Rings, each of which contains the spirit of a classic Fire Emblem character (Marth, Roy, Sigurd, Lyn, and other favorites are represented). These rings can be equipped to any unit, at which point, that unit will be accompanied by the spirit of the ring into battle. This essentially allows you to create impromptu tag teams, with the Emblem spirits granting the unit they’re attached to various bonuses and sometimes pitching in during fights.

You can also “Engage,” merging the unit and Emblem spirit into one, which further boosts stats and grants you some powerful special attacks. You can only remain Engaged for four turns, after which you’ll have to wait for a power gauge to refill before you can do it again. You can freely switch up who carries the Emblem rings between battles, but you get bonuses if you keep certain teams together longer term.

Is permadeath still a thing?

Yes, units can still die permanently, but it’s not forced on you. You can turn permadeath off altogether and even if you turn it on, you get access to an item that allows you to freely rewind turns to fix mistakes. Basically, you only have to accept deaths as permanent if you want to.

Are the social elements between battles still intact?

Yes. As in most Fire Emblem games, you can increase the bond between characters and learn more about them via various conversations. Your home base, called the Somniel, is where you can prepare for your next battle, socialize, and more. A number of quirky side activities, including fishing, exercising, and building up a farm full of fuzzy friends are also available to the player.

Will there be DLC?

Nintendo has announced a Fire Emblem Engage Expansion Pass, which includes additional Emblem characters, cosmetics, and, eventually, new story content. Here’s what’s included in the $30 pass…

DLC Wave 1 (January 20, 2023)

Additional Emblems

Emblem Bracelet for Edelgard/Dimitri/Claude will be added (three Emblems that dwell in one bracelet).

When a unit wears the Emblem Bracelet, they receive stat boosts (including a 20% increase in earned EXP). Note: Bracelet becomes available after clearing the newly added Divine Paralogue map.

Emblem bracelet for Tiki will be added. A unit wearing the bracelet will have improved stat growth. Note: Bracelet becomes available after clearing the newly added Divine Paralogue map.



Support Items

Boots, Seraph Robe, Energy Drop, Spirit Dust, Secret Book, Speedwing, Goddess Icon, Dracoshield, and Talisman

New Accessories

Rare Set, Frilled Band, Big Ribbon, Single Earring, Round Specs

Silver Card

While you possess this item, in-game purchases in the Armory and Item Shop will be discounted by 30%.

DLC Wave 2 (2023)

Additional Emblems

Support Items

New Accessories

DLC Wave 3 (2023)

Additional Emblems

Note: Details to be revealed later.

DLC Wave 4 (2023)

Additional story content. New characters, new maps and a separate story from the main, chapter-based story.

Additional Classes

Pricing, platform, release date, and special edition

Fire Emblem Engage launches on Nintendo Switch on January 20, 2023 at a price of $60. A $100 “Divine Edition” featuring an artbook, poster, and more was initially offered, but it’s currently sold out. You can pre-order a copy of the game here.","Fire Emblem: Three Houses, Software, Mobile, Analysis, Exclusives, Web, Finance, Fire Emblem Engage, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/need-for-speed-unbound-everything-you-need-to-know-about-eas-stylish-racing-game/,Need for Speed Unbound – Everything You Need to Know About EA’s Stylish Racing Game,"Product Info Need for Speed Unbound December 2nd, 2022 Platforms PlayStation 5, Xbox Series, and PC Publisher Electronic Arts Developer Criterion Games Expected Price $69.99 Expected Release Date December 2nd, 2022

The Need for Speed series has been around since 1994, spanning many consoles, mobile phones, and PCs, culminating in 2019’s Need for Speed Heat. A few years have passed, and publisher Electronic Arts revealed the latest in the series, Need for Speed Unbound. It is the first to be released since EA decided to hand it back from Ghost Games (which is now once again a support studio) to Criterion Games, the team behind the acclaimed Hot Pursuit and Most Wanted installments. A few months after that news, EA confirmed that a new entry was being developed.

The development of Need for Speed Unbound was halted in 2021 when EA temporarily conscripted Criterion Games to help DICE with Battlefield 2042 ahead of the game’s launch. However, it has since resumed, and we are now a bit over a month before it will be available. Let’s discuss what we actually know about Unbound before it hits physical and virtual store shelves.

Release date, Pricing, Platforms

Need for Speed Unbound will launch on December 2nd, 2022, for PlayStation 5, Xbox Series, and PC via Steam, the Epic Games Store, and the Origin store. Pre-orders are open right now, and the game is being sold at a base price of $69.99. Pre-orders will get players the following:

A unique Driving Effect

A unique License Plate

Unique Banner artwork and sticker

$150,000 in Multiplayer funds

A deluxe edition of Need for Speed Unbound is also available, the Palace Edition. Players who purchase the Palace Edition gain access to the following:

The game

Four “Stunningly Intense Custom Cars”

New Gassy Driving Effects

A Mashman-themed Decal and License Plate pack

An exclusive character pose and banner artwork

A Special Clothing Pack with 20 unique items

(if pre-ordered) A unique Driving Effect

(if pre-ordered) A unique License Plate

(if pre-ordered) Unique Banner artwork and sticker

(if pre-ordered) $150,000 in Multiplayer funds

Need for Speed Unbound’s Palace Edition will run you $79.99 from whichever storefront you plan to buy it from. Unfortunately, PlayStation 4 and Xbox One users will have to sit this game out since there won’t be any last-gen versions in development.

PC System Requirements and Features

PC players will want to pay attention here, as the Epic Games Store page for Need for Speed Unbound has the game’s required and recommended hardware. To even run Need for Speed Unbound, you’ll need to have the following specifications:

OS - Windows 10 64-bit

CPU - Ryzen 5 2600, Core i5-8600

Memory - 8GB

Storage - 50GB

Direct X Version 124

GPU - RX 570, GTX 1050 Ti

Meanwhile, the game’s recommended specs are as follows:

OS - Windows 10 64-bit

CPU - Ryzen 5 3600, Core i7-8700

Memory - 16GB

Storage - 50GB

Direct X Version 12

GPU - Radeon RX5700 (8GB), GeForce RTX 2070 (8GB)

Visiting Need for Speed Unbound’s Steam page will reveal that the game has NVIDIA DLSS support for higher framerates and resolutions, though we don’t know yet if that is DLSS 2 or DLSS 3. The game will also support HDR10 displays. Variable refresh rate support is available on PC builds of the game, allowing for less screen tear and smoother picture quality.

Gameplay and Cars Details

The first details of the game were leaked by Jeff Grebb, who mentioned that the game’s aesthetic would borrow from anime. That turned out to be true when the game was unveiled, showing a blend of realistic style and anime effects coming out of cars (though these can be disabled). Character models are also cel-shaded, and the overall visuals are heavily graffiti-inspired.

A bit of time after the game’s initial reveal, EA revealed the game’s expansive car list, which can be seen at this link. Various brands can be found within, including Chevrolet, Dodge, BMW, Ferrari, Lamborghini, and more, will be available for players to drive and unlock throughout the game (though given the presentation and art style, the fact that cars like the Toyota AE86 Trueno are missing is outright criminal).

A grand total of 143 vehicles will be available to players at launch (excluding the four unique cars within the Palace Edition). As for gameplay, there’s a risk versus reward with every race (or overworld driving, really) that players enter. Certain actions throughout the in-game weeks will be high payouts or high entry fees, and players will also be able to bet against other racers.

Police chases very evidently return, as they can find you and chase you throughout the game world. If the game’s trailers are anything to go off of, the police are a fair bit more refined and aggressive than they were in games like NFS Heat or Most Wanted 2012. Anyways, it is unclear if the police would have weapons like spike strips or EMPs in their arsenal (though roadblocks make a return).

The fictional Lakeshore City is based on Chicago. The heat system from Need for Speed heat will also come back.

Trailers

Need for Speed Unbound has seen a few trailers come out since its announcement, which you can see below.

Official Reveal Trailer.

Official Risk and Reward Trailer.

Stay tuned for more Need for Speed Unbound details and information as they are released by Electronic Arts.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-ryzen-7000x3d-zen-4-3dv-cache-desktop-cpus-specs-performance-price-availability-everything-we-know-so-far/,"AMD Ryzen 7000X3D ‘Zen 4’ 3DV-Cache Desktop CPUs Specs, Performance, Price, & Availability – Everything We Know So Far","Product Info AMD Ryzen 7000X3D 1H 2023 Manufacturer AMD Type CPUs Platforms Desktop PC Expected Price TBA Expected Release Date 1H 2023

AMD Ryzen 7000 CPUs are the first to feature the Zen 4 core architecture and the upcoming Ryzen 7000X3D chips will be the first to feature 3D V-Cache coupled with the same Zen 4 architecture. The CPU lineup is expected to be introduced in early 2023 and we are going to talk about what you can expect in terms of specifications, performance, and prices.

AMD Ryzen 7000X3D 'Zen 4' CPUs: Bringing 3D V-Cache Goodness To The Zen 4 Architecture & AM5 Platform

Earlier this year, AMD introduced the Ryzen 7 5800X3D, a CPU that was designed to offer the best value and performance to gamers by leveraging 3D V-Cache technology which allows AMD to stack large pools of cache on top of Zen chiplets, driving up performance in bandwidth starved games & applications. The benefit was clear right from the beginning with reviews showing a huge gaming performance boost that matched and even exceeded Intel's fastest CPU, the Core i9-12900K, at the time. With the Ryzen 7000X3D parts, AMD plans to repeat that and give gamers another boost that could potentially make AM5 the fastest platform to game on.

AMD Ryzen 7000X3D 'Zen 4' 3D V-Cache Desktop CPUs Expected Features:

Minor optimization on TSMC's 5nm process node

Up to 64 MB of Stacked cache per CCD (96 MB L3 per CCD)

Increase In Gaming Performance (Avg & Mins)

Compatible With AM5 Platforms

There are certain rumors and some official information from AMD that we know about the Ryzen 7000X3D CPUs already.

AMD Ryzen 7000X3D 'Zen 4' 3D V-Cache CPU Specifications

The first 3D V-Cache CPU from AMD came in just one flavor, the Ryzen 7 5800X3D. With the Ryzen 7000X3D, AMD is rumored to offer more than just one SKU. Current rumors have pointed to an 8-core and 6-core variant but there's a room open for 16-core and 12-core variants too. We cannot say for sure how many variants will be coming to the market but in the case that we see a full-on 3D V-Cache lineup with four SKUs featuring 16, 12, 8, and 6 core SKUs, then the lineup would look something like the below:

Ryzen 9 7950X3D 16-Core (2-CCD)

Ryzen 9 7900X3D 12-Core (2-CCD)

Ryzen 7 7800X3D 8-Core (1-CCD)

Ryzen 5 7600X3D 6-Core (1-CCD)

The other thing to talk about is the amount of 3D V-Cache we would get to see on each variant. The first 3D V-Cache chip featured 64 MB of stacked cache on a single CCD. If AMD is to keep the exact same cache count, we would get up to 96 MB of L3 cache on the single CCD & 192 MB of L3 cache on the dual CCD SKUs. AMD can go out and offer increased stacked cache amounts on their newer chips but that's something we cannot confirm at the moment.

Another important thing to talk about is the overclocking support. The first generation of 3D V-Cache CPUs didn't get any tuning options and the voltage options were locked (only to be opened up by certain motherboard vendors using BETA/Non-Public BIOS). However, AMD's Robert Hallock (Ex-Head of Technical Marketing) confirmed that while overclocking was disabled for the first chip, AMD could have future generations of 3D V-Cache CPUs that may support overclocking just like any other CPU.

Frequency is important, frequency is important but every processor, every game is always a series of tradeoffs, bottleneck mitigations and in our architecture, when you are in the range of four and a half to five GIgahertz, four or five is enough when you put a ton of memory on top you know you are not limited by frequency anymore, you are not giving anything up to target that frequency, its the performance limiters or the performance accelerators move up, move elsewhere in the architecture so we can dial back on the frequency a bit ease up on the thermals, make it easier to cool and drop in a big extra blob of cache on top which is more transistor density, more thermal density so that's a trade-off that was very easy. Robert Hallock (AMD Head of Technical Marketing) via PCWorld

Another tradeoff besides overclocking was the slightly reduced clock speeds and that may still be a thing on the AMD Ryzen 7000X3D CPUs given that the performance benefit that comes from cache makes up for the losses that occur due to the reduced clocks.

AMD Zen CPU / APU Roadmap:

Zen Architecture Zen 6 Zen 5 Zen 4 Zen 3+ Zen 3 Zen 2 Zen+ Zen 1 Core Codename Morpheus Nirvana Persphone Warhol Cerebrus Valhalla Zen+ Zen CCD Codename TBA Eldora Durango TBC Brekenridge Aspen Highlands N/A N/A Process Node 3nm/2nm? 4nm/3nm 5nm/4nm 6nm 7nm 7nm 12nm 14nm Server EPYC Venice (7th Gen) EPYC Turin (6th Gen) EPYC Genoa (4th Gen)

EPYC Siena (4th Gen)

EPYC Bergamo (4th Gen) N/A EPYC Milan (3rd Gen) EPYC Rome (2nd Gen) N/A EPYC Naples (1st Gen) High-End Desktop TBA Ryzen Threadripper 8000 (Shamida Peak) Ryzen Threadripper 7000 (Storm Peak) N/A Ryzen Threadripper 5000 (Chagal) Ryzen Threadripper 3000 (Castle Peak) Ryzen Threadripper 2000 (Coflax) Ryzen Threadripper 1000 (White Haven) Mainstream Desktop CPUs TBA Ryzen 8000 (Granite Ridge) Ryzen 7000 (Raphael) Ryzen 6000 (Warhol / Cancelled) Ryzen 5000 (Vermeer) Ryzen 3000 (Matisse) Ryzen 2000 (Pinnacle Ridge) Ryzen 1000 (Summit Ridge) Mainstream Desktop . Notebook APU TBA Ryzen 8000 (Strix Point)

Ryzen **** (Krackan Point) Ryzen 7000 (Phoenix) Ryzen 6000 (Rembrandt) Ryzen 5000 (Cezanne)

Ryzen 6000 (Barcelo) Ryzen 4000 (Renoir)

Ryzen 5000 (Lucienne) Ryzen 3000 (Picasso) Ryzen 2000 (Raven Ridge) Low-Power Mobile TBA Ryzen 8000 (Escher) Ryzen 7000 (Mendocino) TBA TBA Ryzen 5000 (Van Gogh)

Ryzen 6000 (Dragon Crest) N/A N/A

AMD Ryzen 7000X3D 'Zen 4' 3D V-Cache CPU Performance

AMD currently markets its Ryzen 7000 CPUs against the 13th Gen Raptor Lake CPUs comfortably although the competition does tend to offer slightly better performance and better value at the moment.

The AMD Ryzen 7 5800X3D brought up to 40% and an average of 15% performance increase across a variety of games over the non-3D parts and if AMD makes optimization to the 3D Stacked cache & makes it run slightly higher than the existing cache, then we can see a similar performance boost. If the performance sees a similar or slightly higher performance boost, that would put the X3D chips a good bit ahead of the Intel 13th Gen lineup. But without benchmarks, we cannot verify any of the performance claims yet so it's better to wait a bit for more information.

AMD Ryzen 7000X3D 'Zen 4' 3D V-Cache CPU Price & Availability

Pricing will be the most important aspect of the AMD Ryzen 7000X3D 'Zen 4' CPUs. The Ryzen 7 5800X3D was priced at the same level as the Ryzen 7 5800X but more than a year later. By that time, the Ryzen 7 5800X was already discounted down to $329-$349 US. So the price difference ended up around $100 US so around a 25-30% price bump.

The upcoming AM5 AMD Ryzen 7000X3D 3D V-Cache CPUs can end up around $50 to $100 US higher than the Non-3D part. We can expect the following price points for the 3D V-Cache parts:

Ryzen 9 7950X3D - $799 US (+$100 US)

- $799 US (+$100 US) Ryzen 9 7900X3D - $649 US (+$100 US)

- $649 US (+$100 US) Ryzen 7 7800X3D - $449 US (+$50 US)

- $449 US (+$50 US) Ryzen 5 7600X3D - $349 US (+$50 US)

Now these are preliminary prices and once again, none of the SKUs have been confirmed but this is what we believe that the pricing structure might look like. As for the launch, we have managed to get hold of an internal roadmap that more or less confirms that AMD will be unveiling its Zen 4 3D V-Cache parts at CES 2023. The processors will be positioned as the fastest gaming chips on the market and will be taking the gaming performance crown from Intel's Raptor Lake 13th Gen CPUs.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-radeon-rx-7900-xt/,"AMD Radeon RX 7900 XTX RDNA 3 “Navi 31” Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info AMD Radeon RX 7900 XT 2022 Manufacturer AMD Type Graphics Card Platforms Desktop PC Expected Price ~$1000 US Expected Release Date 2022

AMD Radeon RX 7900 XTX graphics card based on the RDNA 3 ""Navi 31"" GPU is going to be the next-gen flagship for the red team, ushering in performance levels never before seen in the PC gaming segment, and here's everything from specs, price, and performance that you need to know.

AMD Radeon RX 7900 XTX RDNA 3 Graphics Card: The Next-Gen Navi 31 Flagship Infused With Chiplet Architecture

[Updated- 26/11/22]

The AMD Radeon RX 6000 RDNA 2 graphics cards proved that the red team can offer performance on par and even exceed that of the competing GeForce RTX lineup. Each segment saw a massive increase in performance but the Navi 21 series was where the real action was, with performance higher than the RTX 3090 Ti graphics card across the board.

AMD not just delivered a brand new GPU package to its gaming audience but a package that was uplifted with a wide variety of architectural and software innovations such as Infinity Cache tech, FSR, and Smart Access Memory. All of these features combined to give Radeon users a fluid and smooth gaming experience while enjoying all the benefits that modern-day games have to offer such as Ray Tracing, DirectX 12 Ultimate, and visual upscalers technologies.

We should expect similar things with the next-generation flagship too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new RDNA 3 GPU core that is expected to debut on the next-gen Radeon RX 7000 series graphics card lineup.

AMD Navi 31 'Plum Bonito' GPU - The Next-Gen RDNA 3 Powerhouse

At the top of the RDNA 3 SKU lineup is the Navi 31 GPU. Although there's an even faster chip in the works that is expected to debut next year, the 2022 flagship is said to be based on the Navi 31 GPU. The AMD RDNA 3 GPUs will be part of the 'GFX11' family and the flagship Navi 31 GPU is internally codenamed 'Plum Bonito' whereas the RDNA 2 flagship, the Navi 21 GPU was internally known as 'Sienna Cichlid'. AMD has become quite fond of using fish names as its internal codenames for the gaming GPU lineup and that's expected to continue with the RDNA 3 lineup.

AMD confirmed that its RDNA 3 GPUs will be coming later this year with a huge performance uplift. The company's Senior Vice President of Engineering, Radeon Technologies Group, David Wang, said that the next-gen GPUs for Radeon RX 7000 series will offer over 50% performance per watt uplift vs the existing RDNA 2 GPUs. Some of the key features of the RDNA 3 GPUs highlighted by AMD will include:

5nm Process Node

Advanced Chiplet Packaging

Rearchitected Compute Unit

Optimized Graphics Pipeline

Next-Gen AMD Infinity Cache

>50% Perf/Watt vs RDNA 2

In the information published by AMD, the company highlighted a few key features of its RDNA 3 GPUs that will power the next generation of Radeon RX graphics cards. The RDNA 3 GPU will be based on a 5nm process node and utilize an advanced chiplet packaging that delivers increased performance per watt. Furthermore, the GPU will house a range of new technologies such as a brand new and rearchitected Compute Unit, an optimized graphics pipeline, and the next-gen of Infinity Cache.

AAMD will be rearchitecting the compute units within RDNA 3 to deliver enhanced raytracing capabilities. Although there's no mention of what these capabilities are if we were to guess, we would say it's definitely talking about performance and a set of advanced features on the RDNA 3 GPU core for Radeon RX 7000 graphics cards.

AMD's RDNA 2 GPU-powered Radeon RX 6000 series were the first to feature raytracing capabilities on the red camp. They were a generation behind NVIDIA who introduced their first raytracing GPUs two years prior on the Turing graphics architecture and fine-tuned it further to deliver better performance in the second generation on Ampere. With RDNA 3 GPU-powered Radeon RX 7000 pitted for launch later this year, we can expect AMD to offer a similar jump in performance or even exceed Ampere's ray-tracing capabilities. But the real challenge ahead would be to rival NVIDIA's 3rd Gen RT (Raytracing) cores which are expected to debut on the Ada Lovelace-powered GeForce RTX 40 series.

Besides raytracing, AMD will also be adding an Optimized Graphics Pipeline for RDNA 3 GPUs will allow for even higher clock speeds than RDNA 2 GPUs. The AMD Radeon RX 6000 cards already run close to 3 GHz so, with an improved 5nm process node, we can expect AMD to breach past the 3 GHz clock limit. This is essential for AMD as their competitor isn't holding back either with RTX 40 series rumors also hinting at up to 3 GHz clock speeds utilizing the more efficient 4N (optimized 5nm process node).

In addition to these, AMD will also be leveraging advanced GPU capabilities of its RDNA 3 graphics architecture to deliver a richer software ecosystem such as support for AV1 and brand new WMMA Instructions which will allow AI-Learning through the assistance of dedicated hardware blocks. The company is expected to debut its next-gen FSR 3.0 technology with RDNA 3 GPUs which will tackle NVIDIA's AI-Assisted DLSS feature suite.

The GPUs will also be amongst the first to utilize the brand new PCIe Gen 5.0 protocol, allowing for up to 128 GB/s transfer rates. This will be a crucial step in enhancing the Smart Access Memory feature and also drive the way forward for SAS (Smart Access Storage) which is a brand new feature designed in compliance with Microsoft's Direct Storage API to deliver faster loading times and better texture streaming in game. Display capabilities such as DP2.0 and HDMI 2.1 will also be present on the new graphics cards.

AMD RDNA GPU (Generational Comparison) Preliminary:

GPU Name Navi 10 Navi 21 Navi 31 GPU Process 7nm 7nm 5nm/6nm GPU Package Monolithic Monolithic MCD (Multi-Chiplet Die) Shader Engines 2 4 6 GPU WGPs 20 40 48 SPs Per WGP 128 128 256 Compute Units (Per Die) 40 80 192 Cores (Per Die) 2560 5120 12288 Cores (Total) 2560 5120 12288 Peak Clock 1905 MHz 2250 MHz ~3000 MHz FP32 Compute 9.7 23 ~75 Memory Bus 256-bit 256-bit 384-bit Memory Type GDDR6 GDDR6 GDDR6 Memory Capacity 8 GB 16 GB 24 GB Infinity Cache N/A 128 MB 96-192 MB Flagship SKU Radeon RX 5700 XT Radeon RX 6900 XTX Radeon RX 7900 XT TBP 225W 330W 350W Launch Q3 2019 Q4 2020 Q4 2022

AMD Radeon RX 7900 XTX Graphics Card Specifications

The AMD Navi 31 GPU, the flagship RDNA 3 chip, would power the next-gen enthusiast cards such as the Radeon RX 7900 XTX/XT graphics card. We have heard that AMD will drop CU (Compute Units) in favor of WGP (Work Group Processors) on its next-gen RDNA 3 GPUs. Each WGP will house dual CU (Compute Units) but with twice the SIMD32 clusters as opposed to just 2 on each CU within RDNA 2.

AMD Navi 31 XTX: 12288 Cores, 384-bit Bus, 192 MB Infinity Cache, 308mm2 GPU Die @5nm

12288 Cores, 384-bit Bus, 192 MB Infinity Cache, 308mm2 GPU Die @5nm AMD Navi 21 XTX: 5120 Cores, 384-bit Bus, 128 MB Infinity Cache, 520mm2 GPU Die @7nm

The AMD Navi 31 GPU with RDNA 3 architecture will offer a single GCD with 48 WGPs, 96 Compute Units, 12 SAs, and 6 SEs. This will give out a total of 12,288 SPs or stream processors. This is an increase of 2.4x in cores compared to the 5120 SPs featured on the Navi 21 GPU. The GPU or the Navi 31 GCD is said to measure 300mm2 and will come packaged on TSMC's 5nm process node. AMD's latest RDNA 3 GPU packs a total of 58 Billion transistors and the top die can deliver up to 61 TFLOPs of Compute performance.

Starting with the RDNA 3 generation, AMD will be decoupling the clocks with the shader clock being a more conservative but power-efficiency-focused 2.3 GHz while the front-end clock speed will be at 2.5 GHz (a 15% frequency boost).

2 of 9

The Navi 31 GPU will also carry 6 MCD's which will feature 16 MB Infinity Cache per die and are also likely to carry the 64-bit (32-bit x 2) memory controllers that will provide the chip with a 384-bit bus interface.

While this equals 96 MB of Infinity Cache which is lower than the 128 MB featured on the current Navi 21 GPUs, there's also a 3D-Stacked solution in the works which was pointed out recently and that would double the Infinity Cache with 32 MB (16 MB 0-hi + 16 MB 1-hi) capacities for a total of 192 MB of cache. This is a 50% increase versus the current Navi 21 design and it also makes Navi 31 the first GPU with both, chiplet and 3D stacked designs. These chiplets or MCD's will be fabricated on TSMC's 6nm process node and measure 37mm2 each. The latest 2nd Generation Infinity offers up to 5.3 TB/s of bandwidth, an increase of 2.7x versus the previous generation design.

In terms of multimedia, the AMD RDNA 3 Radiance Display Engine comes with support for Display Port 2.1, Display link bandwidth of up to 54 Gbps, and 12-bit per channel color for up to 68 Billion transistors. With the new multimedia engines, gamers will be able to take advantage of 8K 165Hz and 4K 480Hz panels (AMD FreeSync Premium Pro). The new dual media engine also enables the RDNA 3 chips to simultaneously encode/decode for AVC/HVEC, 8K60 AV1 Encode/Decode, and AI-enhanced Video Encode.

AMD Radeon RX 7900 XTX ""RDNA 3"" Graphics Card Reference Design

The graphics card will come with a gorgeous new reference cooler that comes with a 2.5-slot cooler which is slightly thicker and incorporates triple dual-axial fans, each with 9 fan blades. These fans push air towards a massive aluminum heatsink that is featured underneath the shroud and over the vital components such as the GPU, VRAM, and VRMs. The shroud extends just a tad bit beyond the PCB and measures 287mm.

The card also packs a really futuristic shroud design which looks absolutely great. There are two RGB accent bars on the front around the middle fan and two metallic frames in the center too. The ""Radeon"" logo can be seen on the side and once again, this should illuminate with RGB LEDs. The sides of the card show that the card is much longer than the previous RDNA 2 flagship. The Radeon RX 7000 series have more heatsink real estate and also has a distinct 3-red stripe design. There is also more room on the sides for the air to pass through. The graphics card utilized an enhanced vapor chamber cooling design.

The most interesting aspect of this AMD Radeon RX 7900 ""RDNA 3"" graphics card is that it comes with just two 8-pin connectors which is something that AMD itself confirmed a few days ago when Scott Herkelman stated that they won't be using the 16-Pin connector which is utilized by NVIDIA. The graphics card will feature a TBP of 355W which is an increase of 20W over the Radeon RX 6950 XT graphics card.

2 of 9

AMD Radeon RX 7900 XTX Graphics Card Performance

In terms of performance, AMD is promising up to 70% better performance in rasterization and 60% in ray tracing versus the Radeon RX 6950 XT graphics card at 4K resolution in various popular AAA titles.

As for the performance of these monster GPUs, we can only use theoretical numbers here since the launch is a bit far away but based on what we know from the expected theoretical compute numbers, the performance is going to see over a 2.56x gain over the existing cards. This is a major leap

AMD Radeon RX 7900 XTX: 61.00 TFLOPs (FP32) (2500 MHz Boost Clock)

61.00 TFLOPs (FP32) (2500 MHz Boost Clock) AMD Radeon RX 6950 XT: 23.80 TFLOPs (FP32) (2324 MHz Boost Clock)

23.80 TFLOPs (FP32) (2324 MHz Boost Clock) AMD Radeon RX 6900 XT: 23.04 TFLOPs (FP32) (2250 MHz Boost clock)

23.04 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800 XT: 20.74 TFLOPs (FP32) (2250 MHz Boost clock)

20.74 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800: 16.17 TFLOPs (FP32) (2105 MHz Boost clock)

Based on a clock speed of 2.5 GHz, you get up to 61 TFLOPs of compute performance. But one should keep in mind that compute performance doesn't necessarily indicate the overall gaming performance but despite that, it will be a huge upgrade for gaming PCs and a 6.2x increase over the current fastest console, the Xbox Series X.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RX 7900 XTX 75 RX 6950 XT 23.8 RX 6900 XT 23 RX 6800 XT 20.7 RX 6800 16.2 Xbox Series X 12.1 PlayStation 5 10.2

This will be over a 2x compute performance uplift for each graphics card versus its predecessor and this is without even factoring in the brand-new architectural features that are expected to bring major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison. A 2-2.5x gain over the RX 6900 XT & RX 6800 XT would be huge for AMD and is definitely going to be required if they are going to tackle the likes of NVIDIA's Geforce RTX 40 series.

Gamers should expect fluid 4K gaming to be buttery smooth on these graphics cards and with the FidelityFX suite offering next-gen FSR, SAS, and SAM support, we might even see playable 60 FPS at 8K resolution.

AMD Radeon RX 7900 XTX Graphics Card Price & Availability

The AMD Radeon RX 7000 series graphics cards will be focusing on the high-end variants first with the likes of the Navi 31, Navi 32, and Navi 33 GPUs. Previous rumors had mentioned Navi 33 to be followed by Navi 31 and then Navi 32 GPU-based graphics cards but the leaker had earlier pointed out that those plans were no longer applicable. We don't know which GPUs will hit the market first but AMD is likely to unveil its Navi 33 and Navi 31 variants first. As for the launch, the cards are either expected in Late October or Mid-November which means a Q4 2022 launch.

This will be a similar timeframe as the AMD Ryzen 7000 'Zen 4' Desktop CPUs which will also be launching in Fall 2022. Furthermore, NVIDIA is also aiming for a Q4 2022 launch and that's not all, even Intel is planning a Q4 2022 launch for its very own 13th-Gen Raptor Lake CPU family. So in total, we are looking at four major desktop PC launches later this fall which means it's going to be one heated Q4 this time around but consumers are in for a treat as they will have lots of tech to choose from for their next-gen gaming PC builds.

The AMD Radeon RX 7900 XTX 24 GB and Radeon RX 7900 XT 20 GB graphics cards will be available on 13th December for prices of $999 US and $899 US, respectively.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-ryzen-7000-zen-4-am5-cpus/,"AMD Ryzen 7000 ‘5nm Zen 4’ AM5 Desktop CPUs Specs, Performance, Price, & Availability – Everything We Know So Far","Product Info AMD Ryzen 7000 Desktop CPUs 2H 2022 Manufacturer AMD Type CPU Platforms AM5 Expected Price TBA Expected Release Date 2H 2022

AMD officially lifted the curtains off its next-generation Ryzen 7000 Dekstop CPUs that are going to feature the Zen 4 core architecture at CES 2022 & Computex 2022. The next-generation lineup will be bringing some drastic changes, not only limited to the CPU and we are going to talk about what you can expect in terms of specifications, performance, and prices.

AMD Ryzen 7000 'Zen 4' Desktop CPUs, The First 5nm Consumer CPUs For The Latest AM5 Platform

[Launched - 27/09/22]

While Intel may have managed to take the performance, value, and efficiency throne from AMD with its 12th-Gen Alder Lake lineup, AMD isn't going to sit silent. They have planned two brand new CPU launches this year with the upcoming one being a demonstration of how 3D V-Cache can allow gamers to benefit from faster performance in a mainstream package. But that's just one chip, the bigger launch is scheduled for the second half of 2022 in the form of the Ryzen 7000 and it's going to fundamentally change everything for the Ryzen Desktop CPU platform.

AMD Ryzen 'Zen 4' Desktop CPU Expected Features:

Up To 16 Zen 4 Cores and 32 Threads

+29% Performance Uplift In Single-Threaded Apps

Brand New Zen 4 CPU Cores (IPC / Architectural Improvements)

Brand New TSMC 5nm process node with 6nm IOD

25% Performance Per Watt Improvement Vs Zen 3

>35% Overall Performance Improvement Vs Zen 3

~13% Instructions Per Clock (IPC) Improvement Vs Zen 3

Support on AM5 Platform With LGA1718 Socket

New X670E, X670, B650E, B650 Motherboards

Dual-Channel DDR5 Memory Support

Up To DDR5-5600 Native (JEDEC) Speeds

28 PCIe Lanes (CPU Exclusive)

105-120W TDPs (Upper Bound Range ~170W)

AMD AM5 Platform - A New Beginning

Before we talk about CPUs, we have to talk about the platform itself. The AMD Ryzen 7000 CPUs will be migrating to a new home known as AM5, the successor to the long-lasting AM4 platform. It marks a fresh start for the Ryzen Desktop family and as such, existing Ryzen CPUs starting with Ryzen 1000 & all the way up to Ryzen 5000 won't be supported by the new platform we will tell you why it is so.

The AM5 platform will first and foremost feature the brand-new LGA 1718 socket. That's correct, AMD isn't going the PGA (Pin Grid Array) route anymore and now focusing on LGA (Land Grid Array), similar to what Intel uses on its existing desktop processors. The main reason to go LGA is due to the addition of enhanced and next-gen features such as PCIe Gen 5, DDR5, etc that we will get to see on the AM5 platform. The socket has a single latch & gone are the days of worrying about pins underneath your precious processors.

In terms of features, the AM5 platform will initially support AMD's Ryzen 7000 'Zen 4' Desktop CPUs and extend that support to future Ryzen CPUs and APUs. The platform offers DDR5-5200 (JEDEC) memory support, up to 28 PCIe lanes (Gen 5 standard), increased NVMe 4.0, and USB 3.2 I/O lanes & we have also heard chatter about native USB 4.0 support which will be a game-changer.

A new feature called EXPO (AMD Extended Profiles for overclocking) will allow enhanced DDR5 memory OC on the new platform, similar to Intel's XMP. It has been a rough road for AM4 to offer decent DDR4 OC capabilities but that has more or less been sorted out by now, we can only expect DDR5 to have a much better OC and compatibility experience compared to DDR4 on AM4 platforms. Furthermore, it looks like the platform will only be DDR5 compatible and we won't see DDR4 options as we do on Intel's existing platform. But with DDR5 prices and availability improving, that won't be that big of a deal for most high-end consumers for who AMD will be aiming first.

AMD X670 Series Platform

The AM5-compliant AMD 600-series motherboards are currently being prepped up by the board makers, The 600-series lineup will initially consist of three chipsets, the X670E, X670, B650E, and B650.

In terms of features, the X670E (Extreme) is designed for the higher-echelon of motherboards with unparalleled capabilities, and extreme overclocking, and will have PCIe 5.0 support for both GPU and storage.

The X670 motherboards will be very similar in offering enthusiast-level overclocking but PCIe Gen 5.0 support for storage and graphics will depend on the manufacturers. It is likely that some board makers will go to the cost-effective route and enable PCIe 5.0 support only for the GPU while keeping storage limited to PCIe 4.0. Both X670 chipsets will come in a dual-PCH solution on the motherboard to allow for the increased I/O for the next-gen platform.

AMD B650 Series Platform

Finally, there are the B650E & B650 chipsets which will be aimed as a mainstream motherboard solution with the Extreme series featuring both PCIe Gen 5.0 and M.2 while the non-E boards will adopt only PCIe 5.0 slot designs.

The B650 motherboards will be the successor to the B550 motherboards and come in a similar price range. Compared to the X670/E offerings, the B650 chipset will come in a single PCH design. The motherboards will carry support for RDNA 2 iGPU too which will be featured on Ryzen 7000 'Raphael' CPUs and offer both HDMI / DP outputs.

2 of 9

One of the highlighted features of the AMD AM5 600-series platform is SAS or Smart Access Storage. This technology will enable GPU decompression with supported Microsoft DirectStorage games. Although there aren't many of those out there yet but expect industry-wide support for this on newer platforms.

As for longevity, AMD hasn't promised anything but they have stated that they want to see the new AM5 socket last at least four to five years, similar to AM4. While there has been a lot of controversy regarding Ryzen support on the initial AM4 motherboards, I believe that AMD has learned and will not follow the same route as AM5. With that said, the AM4 platform will still continue forward & will be supported in the foreseeable future (possibly with newer hardware and software launches).

SmartAccess Storage gets you out of the load screen and into your gameplay

Traditional game loading takes a significant amount of compute power to decompress the game’s data, requiring the CPU to do the decompression and data transfer, which introduces latency and takes up considerable system resources.

To help bypass these bottlenecks, AMD has created SmartAccess Storage, a suite of technologies supporting Microsoft DirectStorage that utilizes Smart Access Memory with new AMD platform technologies along with Radeon GPU asset decompression to improve both game load times and texture streaming.

2 of 9

AMD Chipset Features and Specifications:

Wccftech X670E/X670 B650E/B650 A620 X570 X399 Refresh X399 X470 X370 B450 B350 A320 X300 A300 CrossfireX/SLI 2-Way CFX 2-Way CFX N/A Triple CFX/2-Way SLI Quad SLI/CFX

(Max 6 GPU Support) Quad SLI/CFX

(Max 6 GPU Support) Triple CFX/2-Way SLI Triple CFX/2-Way SLI N/A N/A N/A N/A N/A CPU Lanes 24 Gen 5 (with Ryzen 7000 CPUs & above) 24 Gen 5 (with Ryzen 7000 CPUs & above) 24 Gen 4 (with Ryzen 7000 CPUs & above) N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A PCH Lanes 12 Gen 4

8 Gen 3 8 Gen 4

4 Gen 3 8 Gen 3 30 +16 (with Ryzen 7 CPU) 60 (With Threadripper CPU)

4 Lanes Reserved for PCH 60 (With Threadripper CPU)

4 Lanes Reserved for PCH 16 (with Ryzen 7 CPU) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) PCIe Gen 2 Lanes N/A N/A N/A N/A 8 PCIe Lanes (reserved) 8 PCIe Lanes (reserved) 8 (plus x2 PCIe Gen3 when no x4 NVMe) 8 (plus x2 PCIe Gen3 when no x4 NVMe) 6 (plus x2 PCIe Gen3 when no x4 NVMe) 6 (plus x2 PCIe Gen3 when no x4 NVMe) 4 (plus x2 PCIe Gen3 when no x4 NVMe) 4 (plus x2 PCIe Gen3 when no x4 NVMe) 4 (plus x2 PCIe Gen3 when no x4 NVMe) USB 3.1/3.2 Gen2 2 1 0 8 2 2 2 2 2 2 1 0 0 USB 3.1/3.2 Gen1 12 6 2 12 (PCH + CPU) 13 (PCH+CPU) 13 (PCH+CPU) 10 10 6 6 6 4 4 USB 2.0 8 6 6 N/A 6 6 6 6 6 6 6 0 0 SATA 6Gb/s 8 4 4 8 8 8 6 6 4 4 4 2 2 SATA Express N/A N/A N/A 2 2 2 2 2 2 2 2 1 1 DDR5 DIMMs 4 4 4 N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A DDR4 DIMMs N/A N/A N/A 4 8 8 4 4 4 4 2 2 2 Overclocking

Support Yes Yes N/A Yes Yes Yes Yes Yes Yes Yes No Yes No XFR2 Enhanced Yes Yes N/A Yes Yes No Yes No Yes No No No No Precision Boost Overdrive Yes Yes N/A Yes Yes No Yes No Yes No No No No NVMe Yes (Gen 5.0) Yes (Gen 5.0) N/A Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Form Factor ATX/mATX/ITX ATX/mATX/ITX mATX/ITX ATX, MATX ATX, MATX ATX, MATX ATX, MITX ATX ATX, M-ATX ATX, M-ATX M-ATX, Mini-ITX Mini-ITX M-ATX, Mini-ITX

AMD Ryzen 7000 'Zen 4 Raphael' CPUs Specifications

Coming to the CPUs now, we have managed to get hold of the final specifications of AMD's Ryzen 7000 Desktop CPU family which, as expected, are going to feature four SKUs based on the Zen 4 core architecture. Once again, these SKUs include:

AMD Ryzen 9 7950X

AMD Ryzen 9 7900X

AMD Ryzen 7 7700X

AMD Ryzen 5 7600X

2 of 9

So before getting into the core specifications of these four SKUs, we have to point out that the AMD Ryzen 7000 CPUs are based on a TSMC 5nm process node with a CCD die size of 70mm2 compared to 83mm2 for Zen 3 and feature a total of 6.57 Billion transistors, a 58% increase over the Zen 3 CCD with 4.15 Billion transistors, The CPUs adopt the Zen 4 architecture, bringing with it a 13% IPC uplift but the majority of the performance benefit comes from the higher clock speeds and a higher TDP that is supplemented to each chip versus the prior generation.

AMD has highlighted a +29% Single-Threaded, >35% Multi-Threaded and >25% Perf/Watt increases when comparing Zen 4 to Zen 3 cores. The IOD is fabricated on the 6nm process node and houses an iGPU which comes with 2 RDNA 2 Compute Units running at up to 2200 MHz as detailed here. It features a die size of 124.7mm2 which is almost the same size as the Zen 3 IOD which measured 124.9mm2.

AMD Ryzen 7000 Desktop CPU Render (With/Without IHS):

2 of 9

As per AMD, the main improvements for IPC come from a new Front End & Load/Store + Branch Predictor that makes up for 80% of the gains while the L2 cache structuring and Execution Engines offer the remaining 20% uplifts.

AMD also highlighted that AVX-512 & VNNI add up to 30% faster FP32 (multi-thread) inferencing performance and a 2.5x gain in INT8 (multi-thread) CPU performance uplift. In addition to the larger caches, the Micro-op cache has been increased from 4 KB to 6.75 KB, the L1I and L1D cache stick to 32 KB, the L2 cache size has doubled to 1 MB and now runs at 14 cycles instead of 12 while the L3 cache also features slightly higher latency, going up from 46 cycles to 50 cycles. The L1 BTB has also been increased from 1 KB to 1.5 KB.

2 of 9

Compared to Zen 3, Zen 4 architecture is also going to be really efficient, offering 62% lower power at the same performance, and 49% more performance at the same power. The CPUs also feature 50% less area versus the competition (10nmESF Alder Lake) thanks to their 5nm process node and up to 47% higher power efficiency.

AMD Ryzen 'Zen 4' Desktop CPU Features:

Up To 16 Zen 4 Cores and 32 Threads

+29% Performance Uplift In Single-Threaded Apps

Brand New Zen 4 CPU Cores (IPC / Architectural Improvements)

Brand New TSMC 5nm process node with 6nm IOD

25% Performance Per Watt Improvement Vs Zen 3

>35% Overall Performance Improvement Vs Zen 3

~13% Instructions Per Clock (IPC) Improvement Vs Zen 3

Support on AM5 Platform With LGA1718 Socket

New X670E, X670, B650E, B650 Motherboards

Dual-Channel DDR5 Memory Support

Up To DDR5-5600 Native (JEDEC) Speeds

28 PCIe Lanes (CPU Exclusive)

105-120W TDPs (Upper Bound Range ~170W)

2 of 9

The CPUs will come with an optimized cache restructuring, featuring double the L2 cache (1 MB vs 512 KB), a shared L3 cache like the previous generation, support for DDR5 memory with EXPO (AMD's Extended Profiles For Memory Overclocking), PCIe Gen 5.0 graphics card, and M.2 SSD support. Overclocking features such as PBO and XFR will also carry over from the past chips. So with all of that said, let's get on with the specifications.

AMD Ryzen 7000 CPU Box Packages:

2 of 9

AMD Ryzen 9 7950X 16 Core ""Zen 4"" Desktop CPU

Starting with the flagship of them all, we have the AMD Ryzen 9 7950X which retains its healthy 16 core and 32 thread count from the previous two generations. The CPU will feature an impressive base frequency of 4.5 GHz and a boost clock of up to 5.7 GHz (5.85 GHz F-Max) which should make it 200 MHz faster than Intel's Alder Lake Core i9-12900KS which has a boost frequency of 5.5 GHz on a single-core.

It looks like AMD is extracting every ounce of Hertz that it could within that 170W TDP (230W PPT) for the Ryzen 9 chips. As for the cache, the CPU comes with 80 MB of that which includes 64 MB from L3 (32 MB per CCD) and 16 MB from L2 (1 MB per core). The flagship is going to cost $699 US which means that it will be priced slightly higher than the Core i9-12900K while offering a significant performance leap in multi-threading apps such as Chaos V-Ray of up to +57% and doing so with up to 47% higher energy efficiency.

In terms of gaming performance, the AMD Ryzen 9 7950X will be offering up to 35% higher uplift in games such as Shadow of The Tomb Raider versus the Core i9-12900K.

AMD also showcased the performance of the AMD Ryzen 9 7950X against the Intel Core i9-12900K in both gaming and content creation tasks. The CPU was anywhere from -1% to +23% faster in the gaming benchmarks and +36 to +62% faster in creation workloads.

AMD Ryzen 9 7900X 12 Core ""Zen 4"" Desktop CPU

Next up, we have another AMD Ryzen 9 chip, the 7900X, which as the name suggests, would come equipped with 12 cores and 24 threads. The CPU comes with an even higher base clock of 4.7 GHz and a boost clock adjusted at 5.6 GHz across a single core. The CPU retains its 170W TDP and gets 76 MB of cache (64 MB L3 + 12 MB L2). The CPU will be positioned in the same ballpark as the AMD Ryzen 9 5900X but with performance that would shake the ground from below the Core i7-12700K. The Ryzen 9 7900X will retain the same prices as the Ryzen 9 5900X while offering better processor capabilities.

AMD Ryzen 7 7700X 8 Core ""Zen 4"" Desktop CPU

Moving over to the Ryzen 7 family, here we have the AMD Ryzen 7 7700X, an 8-core and 16-thread part. AMD positions this as the sweet spot for gamers and as such, the CPU will feature a base clock of 4.5 GHz and a boost clock of 5.4 GHz but at a lower 105W TDP (142W PPT). The CPU will get a 40 MB cache pool which consists of 32 MB L3 from the singular CCD &8 MB L2 from the Zen 4 cores.

Now one interesting thing to mention is that there is so far no update by AMD on a Ryzen 7 7800X chip. It is likely that AMD wants to replace that part with a successor to the Ryzen 7 5800X3D with Zen 4 cores (3D V-Cache). If that was the case, we can expect an update later this year to the CPU lineup since the V-Cache parts have been confirmed for a late Q4 2022 launch by AMD themselves. The Ryzen 7 7700X will be priced at $399 US and will be competing with the Core i7-12700K during launch.

AMD Ryzen 5 7600X 6 Core ""Zen 4"" Desktop CPU

Last up, we have the most budget-tier chip (if you can call it that but the pricing won't be reflective of that), the Ryzen 5 7600X. This will be a 6-core and a 12-thread part that features a high 4.7 GHz base clock and a 5.3 GHz single-core boost frequency. The CPU will also run at a 105W TDP (142W PPT) which is much higher than its 65W predecessor though once again, that's the sacrifice you've to pay to achieve the faster clock speeds. The CPU will carry 38 MB of cache which comes from 32 MB of L3 and 6 MB of L2 on the die. This chip is going to be priced at $299 US and will be offering a 5% performance gain over the Core i9-12900K in gaming.

2 of 9

AMD will be bringing back its PBO and XFR overclocking features to the Ryzen 7000 Zen 4 CPUs along with enhanced DDR5 memory and overclocking support through EXPO technology. The CPUs will also come equipped with RDNA 2 iGPU with up to 2 Compute Units running at 2.2 GHz which would be usable through HDMI 2.1 FRL and DP 1.4 connectors on the latest AM5 motherboards. In addition to the CPU & GPU, there will be an expanded instruction set for AI acceleration (AVX-512 anyone?).

AMD Ryzen 7000 'Raphael' Desktop CPU Specs (Official):

CPU Name Architecture Process Node Cores / Threads Base Clock Boost Clock (SC Max) Cache TDP Prices (USD) AMD Ryzen 9 7950X Zen 4 5nm 16/32 4.5 GHz 5.7 GHz 80 MB (64+16) 170W $699 US AMD Ryzen 9 7900X Zen 4 5nm 12/24 4.7 GHz 5.6 GHz 76 MB (64+12) 170W $549 US AMD Ryzen 7 7700X Zen 4 5nm 8/16 4.5 GHz 5.4 GHz 40 MB (32+8) 105W $399 US AMD Ryzen 5 7600X Zen 4 5nm 6/12 4.7 GHz 5.3 GHz 38 MB (32+6) 105W $299 US

AMD Ryzen 7000 'Zen 4' CPUs Performance

AMD showcased a ton of gaming and workloads-specific performance numbers which we have posted above but the most impressive result is in Geekbench 5. Based on the overall Single-Threaded performance increase in Geekbench 5, we can compile the following chart:

AMD Ryzen 7000 CPU ST Benchmarks Official (Geekbench 5) Single-Core 0 500 1000 1500 2000 2500 3000 0 500 1000 1500 2000 2500 3000 Core i9-13900K 2.3k Ryzen 9 7950X 2.3k Ryzen 9 7900X 2.3k Ryzen 7 7700X 2.2k Ryzen 5 7600X 2.2k Core i9-13900 2.1k Core i7-13700K 2.1k Core i5-13600K 2k Core i9-12900K 1.9k Core i7-12700K 1.9k Core i5-12600K 1.9k Ryzen 9 5950X 1.7k Ryzen 7 5800X 1.7k Ryzen 9 5900X 1.7k Ryzen 5 5600X 1.6k

In the performance metrics posted above, you can tell how AMD is positioning each CPU based on its strength. The AMD Ryzen 9 7950X is going to be a beast with best-in-class multi-threading CPU efficiency and strong single-core performance at $100 US cheaper than the previous flagship while the Ryzen 5 7600X will be aimed purely at gamers who want the best gaming performance, tackling, and even exceeding the Core i9-12900K at a price of just $299 US. It will definitely be a big blow for Intel to see its best gaming chip being crushed by a competitor that costs half the amount.

The cost also makes it an interesting proposition for gamers as they can build a PC with a $299 US CPU, a $150 US motherboard, and a $150-$200 US DDR5 kit, all for around $600-$650 US which is the cost of Intel's flagship CPU alone. With DDR5 prices coming down, gamers will be able to build the same PC for even less. And with that said, we also have some leaked benchmark figures for the Ryzen 9 7950X which show multi-threaded performance on par with Intel's upcoming Raptor Lake Core i9-13900K CPU.

AMD Ryzen 9 7950X ""Alleged"" Cinebench R23 Performance (Single-Core) ST 0 500 1000 1500 2000 2500 3000 0 500 1000 1500 2000 2500 3000 Core i9-13900K 2.3k Ryzen 9 7950X 2.2k Core i7-13700K 2.1k Core i9-12900K 2k Core i5-13600K 2k Core i7-12700K 2k Ryzen 7 7700X 2k Core i5-12600K 2k Ryzen 5 7600X 1.9k Core i9-11900K 1.7k Ryzen 9 5950X 1.6k Ryzen 9 5900X 1.6k Ryzen 7 5800X 1.6k Ryzen 5 5600X 1.5k

AMD Ryzen 9 7950X ""Alleged"" Cinebench R23 Performance (Multi-Core) MT 0 9000 18000 27000 36000 45000 54000 0 9000 18000 27000 36000 45000 54000 Core i9-13900K (Unlimited Power) 40.2k Ryzen 9 7950X 39k Core i9-13900K (Limited Power) 35.7k Core i7-13700K 28.9k Core i9-12900K 27.5k Core i5-13600K 24.4k Ryzen 9 5950X 24.2k Core i7-12700K 23k Ryzen 9 5900X 21.1k Ryzen 7 7700X 19.8k Core i5-12600K 17.9k Ryzen 7 5800X 15.4k Ryzen 5 7600X 15.1k Ryzen 5 5600X 11.3k

The AMD Ryzen 9 7950X scored an impressive 38984 points in multi-core tests. Now comparing it to the Ryzen 9 5950X, the Ryzen 9 7950X blazes ahead with a 61% better multi-threaded uplift. It also crushes the Core i9-12900K with an impressive 42% performance uplift. Finally, the chip does lose out to the Intel Core i9-13900K with 3% slower performance but that's almost on par with what the 13th Gen flagship produces. The Intel Core i9-13900K does consume much higher power rated at 350W with the Unlimited Power Setting and that gives Zen 4 a major power efficiency advantage over its rival.

AMD Ryzen 7000 RDNA 2 iGPUs: Video Encode/Decode, APUs Still Happening For Desktops!

As for what the new RDNA 2 iGPUs on the Ryzen 7000 Desktop CPUs bring to the table, AMD states that with integrated graphics on their entire CPU portfolio, they can expand their business into the commercial segment and that makes a lot of sense since a lot of consumers there don't require a discrete graphics card and want something that is as simple as plug-and-play.

For DIY builders, the RDNA 2 iGPU can provide troubleshooting and diagnostic capabilities where users with graphics cards can debug if their graphics card is faulty or not or for other purposes. The same can be applied to users without graphics cards or those waiting on one who can't turn on their PC until they get their discrete GPU.

Frank Azor took the topic to a more interesting space by stating that while AMD Ryzen 7000 CPUs will have 'little graphics' cores compared to the 'bigger graphics' cores on APUs, they will still host some of the Smart Eco technologies boasted by notebooks. While AMD's RDNA 2 iGPUs can allow for sub-50W power usage in idle mode, Smart Shift on Desktop CPUs with RDNA 2 iGPUs can switch from discrete graphics to integrated graphics for light-weight workloads and offer sub-5W power or even mW power.

The other thing is that, unlike AMD's Navi 24 GPUs, the Ryzen 7000 iGPU based on the same RDNA 2 core architecture (but on a 6nm Rembrandt revision) will come with a VCN engine that supports both AV1 Video Encode and Decode.

We still think of the Ryzen 7000 series as a CPU. The graphics cores in that IO die are not many, the purpose of adding graphics is three-fold. One, it greatly expands these products in the commercial market where they don't buy discrete at all, they just want to turn it on, have video encode/decode and light up some displays for office work and that's what the GPU in the IO die will offer so that's a huge business opportunity for us on the Ryzen PRO side as we start migrating these components over to that business. The second is for diagnostic purposes, how do you know that you have a bad graphics card? Well, you have to swap in another graphics card but with the graphics core we have, you can do a little bit of troubleshooting thirdly, we were thinking about users who are planning to buy a discrete graphics, and it's still in transit in the mail but all the other hardware has arrived first so it's all sat there, looking at a pile of components and don't have a GPU to actually set that all up. That would go away with the Ryzen 7000 series. We are still going to do APUs with big graphics so APUs 'BIG GRAPHICS', CPUs 'little graphics'. That would be our strategy going forward. Robert Hallock (AMD Director of Technical Marketing) We are developing a lot of technologies that make use of integrated graphics in many ways and there are things that we are able to do with technologies such as Smart Shift ECO where we can turn off the discrete graphics and we can run the notebook off of the iGPU and say you want that because you want less heat, longer battery life (even when you are playing a game) or you want less fan noise or lower power consumption, there's all these benefits to it. Because we have that thin integrated graphics in Ryzen 7000 series, it's going to allow us to bring more of these types of smart technologies over to the desktops aswell so those customers can get some of these benefits. Frank Azor (Chief Architect of Gaming Solutions)

As for whether we will see an iGPU disabled variant of Ryzen 7000 Desktop CPUs, Robert did state that all Zen 4 chips will have integrated RDNA 2 graphics so those in hopes of seeing a 'KF-esque' variant should be a bit disappointed.

The AMD Ryzen 7000 Desktop CPUs will feature a perfect square shape (45x45mm) but will house a very chonky integrated heat spreader or IHS. The CPUs will be the same length, width, and height as the existing Ryzen Desktop CPUs and are sealed across the sides so applying thermal paste won't fill the interior of the IHS with TIM. That's also why current coolers will be fully compatible with Ryzen 7000 chips.

As for TDP requirements, the AMD AM5 CPU platform will feature six different segments starting with the flagship 170W CPU class which is recommended for Liquid coolers (280mm or higher). It looks like this will be an aggressively clocked chip with higher voltages and with CPU overclocking support. This segment is followed by 120W TDP CPUs which are recommended to utilize a high-performance air cooler. Interestingly, the 45-105W variants are listed as SR1/SR2a/SR4 thermal segments which means they would require standard heatsink solutions when running in a stock configuration so not much else is required to keep them cool.

First of all, the TDP (Thermal Dissipation Power) figures for AMD Ryzen 7000 CPUs are going to be up to 170W while the PPT (Package Power Tracking) is going to be 230W. AMD provided this information in a reply to whether the 170W figure was an actual TDP for the upcoming chips or an upper-bound limit for the package.

As per AMD, this is an increase of around 88W over the AM4 package power limit (PPT) which was 142W while the CPUs had a TDP of 105W. According to AMD, motherboard manufacturers will now be able to deploy more premium power characteristics on their motherboards which should allow for better overclocking opportunities for enthusiasts and overclockers.

""AMD would like to issue a correction to the socket power and TDP limits of the upcoming AMD Socket AM5. AMD Socket AM5 supports up to a 170W TDP with a PPT up to 230W. TDP*1.35 is the standard calculation for TDP v. PPT for AMD sockets in the “Zen” era, and the new 170W TDP group is no exception (170*1.35=229.5). ""This new TDP group will enable considerably more compute performance for high core count CPUs in heavy compute workloads, which will sit alongside the 65W and 105W TDP groups that Ryzen is known for today. AMD takes great pride in providing the enthusiast community with transparent and forthright product capabilities, and we want to take this opportunity to apologize for our error and any subsequent confusion we may have caused on this topic."" -- AMD Representative to Tom's Hardware (emphasis added) AMD spokesperson via Tomshardware So what we want to clarify is that it's a 170 Watt socket power which with AMD, that spec is PPT (Package Power) for us. That doesn't mean that every CPU is going to go up to 170 Watts but it's 30 (Watt) higher than the socket AM4 power cap which was a 142 (watts). And we did this to mainly improve multi-thread performance as many of the core count chips were actually held back in overall compute performance by relatively modest socket power. The other point that I want to make is that by raising the minimum required socket power or minimum spec, you also raise the power delivery with every motherboard built to that spec so you get more robust power characteristics on all the boards which we are pretty excited about as well, It should be good for people who want to experiment with overclocking, people who appreciate premium board designs. Robert Hallock (AMD Director of Technical Marketing)

AMD Ryzen 7000 Desktop 'AM5 LGA 1718 Socket' TDP Segments:

The Ryzen 7000 Desktop CPUs are also expected to feature RDNA 2 onboard graphics which means that just like Intel's mainstream desktop lineup, AMD's mainstream lineup will also feature iGPU graphics support. In regards to how many GPU cores there will be on the new chips, rumors say anywhere from 2-4 (128-256 cores) clocked at up to 1100 MHz for up to 0.5 TFLOPs of horsepower. This will be lesser than the RDNA 2 CU count featured on the soon-to-be-released Ryzen 6000 APUs 'Rembrandt' but enough to keep Intel's Iris Xe iGPUs at bay.

The company states that Zen 4 offers:

Significant generational performance per watt and frequency improvement

~13% IPC increase

+29% single-thread performance gain

Up To 125% memory bandwidth per core

ISA extensions for AI and AVX-512

Furthermore, it is also confirmed that Zen 4 will come in 3D V-Cache flavors as early as late 2022. It is not said what core counts we can expect in 3D V-Cache flavors but they will definitely be tackling Intel's 13th-Gen Raptor Lake CPU lineup.

AMD Ryzen 7000 EXPO Memory Overclocking Technology

AMD's EXPO tech which stands for ""Extended Profiles For Overclocking"" for Ryzen 7000 Desktop CPUs will be aiming for the high-end ""Extreme"" series 600-series motherboards in the X670 and B650 family. The profile will be an extension for XMP (Extreme Memory Profile) which will also be available on the AM5 platform but to benefit from higher speeds, AMD has designed the EXPO technology.

Based on what AMD has shown, EXPO will enable one-click DDR5 to overclock support on AM5 motherboards and offer up to 11% faster performance at 1080p resolution. The EXPO memory kits from various memory makers will be designed to hit low latencies of around 63ns and there will be a range of public certification reports that will provide users with full specifications and OC settings that they can work with.

New for the Ryzen 7000 Series Desktop processors and optimized for AMD Socket AM5 motherboards, AMD EXPO technology provides users with advanced profile settings for DDR5 memory overclocking. When optimized for high-performance gaming, consumers can expect to see up to 11% faster gaming performance with AMD EXPO technology in F1® 2022. AMD EXPO technology was designed to achieve higher gaming performance from pre-configured overclocking profiles and is easy to implement. PC enthusiasts who want to understand the finer details of an AMD EXPO technology-enabled module can find public self-certification reports, which clearly lay out the module’s full timing table, components, and the system configuration used to finalize the memory’s specifications. AMD is offering EXPO technology to its industry memory partners without royalties or licensing fees. AMD EXPO technology arrives to market alongside the AMD Ryzen 7000 Series processors, with offerings from ADATA, Corsair, GeIL, G.SKILL, and Kingston. Over 15 AMD EXPO technology-enabled memory kits will be initially available, with memory speeds up to DDR5-6400. via AMD

As for the first EXPO products, AMD announced that their memory partners such as ADATA, Corsair, GeIL, G.Skill, and Kingston, will have a total of 15 kits at launch with speeds of up to DDR5-6400. The native speeds will be rated at:

1x1R - 5200 MT/s

1x2R - 5200 MT/s

2x1R - 3600 MT/s

2x2R - 3600 MT/s

We also had previously reported that DDR5-6000 will be the sweet spot for AMD Ryzen 7000 CPUs based on the Zen 4 core architecture using the EXPO technology. The DDR5-6000 memory kits that are optimized with EXPO support will offer the best performance with the lowest latency in a 1:1 FCLK mode.

Now as per Robert, we now know that the default FCLK for AMD Ryzen 7000 CPUs is set to 1733 MHz. Robert also states that memory overclocking is a little bit different with Ryzen 7000 since 1:1:1 (FCLK:UCLK:MCLK) isn't important anymore. It is mentioned that to achieve the best results, you should leave the FCLK to auto and overclock the memory modules and memory controller in 1:1 mode. There will be some corner cases where users will be able to get better performance results by hitting over 2 GHz FCLK speeds but those aren't a big priority, as AMD mentions.

At the native setting, DDR5-5200 will operate in a 2:1:1 mode or 1733:2600:2600 clock. Robert also confirmed something that we had stated early on that DDR5-6000 will ""Roughly"" the sweet spot & by sweet spot, he means the best compromise to cost/stability/performance/availability/ease. So as of right now, we have the following sweet spots as mentioned directly by AMD:

Ryzen 3000 ""Zen 2"" Sweet Spot - DDR4-3800 (Official AMD)

Ryzen 5000 ""Zen 3"" Sweet Spot - DDR4-4000 (Official AMD)

Ryzen 7000 ""Zen 4"" Sweet Spot - DDR5-6000 (Official AMD)

It is stated that DDR5-5200 C28 kits should go really well with Ryzen 7000 too as they are pretty fast but there aren't a lot of kits in those configurations available right now.

AMD's Robert Hallock responds to various queries regarding DDR5 support on AMD Ryzen 7000 & confirms DDR5-6000 as the sweet spot. (Credits: AMD Discord)

As Robert states:

The reason why we say ""AUTO:1:1"" is now ideal because the FCLK will automatically change depending on what memory speed is in the DIMM slots. There's no ""one size fits all"" ideal fabric frequency. For example: JEDEC 5300 fclk goes to 1767, 6000 RAM should go to 2000 fclk. Each memory speed has its own optimal fclk, which is why I'm gently guiding people to not worry about what the fclk is because it's going to change with RAM speed and the AUTO setting will usually give the most performant result unless you have an astonishing overclocker. And ""get the highest possible fclk"" is no longer the rule like it was on AM4. In short.

In addition to these, MSI's in-house overclocker, TOPPC, has revealed that EXPO memory kits will be fully compatible with Intel XMP profiles. Simply put, Intel XMP memory can still support EXPO but it is worth it to have an EXPO-enabled kit to ensure the best possible profile for AMD's Ryzen 7000 CPU lineup.

As for the first EXPO products, AMD announced that their memory partners such as ADATA, Corsair, GeIL, G.Skill, and Kingston, will have a total of 15 kits at launch with speeds of up to DDR5-6400. The native speeds will be rated at:

1x1R - 5200 MT/s

1x2R - 5200 MT/s

2x1R - 3600 MT/s

2x2R - 3600 MT/s

2 of 9

The AMD EXPO DDR5 memory kits will launch alongside the Ryzen 7000 Desktop CPUs and AM5

AMD Ryzen 7000 'Zen 4' CPUs Pricing

Pricing is a much bigger topic to discuss this time around as we saw with AMD Ryzen 5000 CPUs. The Vermeer chips saw a bump in prices across all segments which was not welcomed by the PC consumers but still managed to break record sales figures, shipping over a million units in the first few months. AMD knows that they have the upper hand over Intel in terms of performance & that users are willing to pay extra for their chips. But despite that, the company chose a competitive route and offered similar or better prices than last-generation CPUs.

The AMD Ryzen 9 7950X has an MSRP of $100 US cheaper than the Ryzen 9 5950X, the Ryzen 9 7900X retains the Ryzen 9 5900X pricing, and the Ryzen 7 7700X will be priced the same as the Ryzen 7 5700X and the same would be true for the Ryzen 5 7600X.

AMD Ryzen 9 7950X - $699 US

AMD Ryzen 9 7900X - $549 US

AMD Ryzen 7 7700X - $399 US

AMD Ryzen 5 7600X - $299 US

The current Ryzen flagship, the Ryzen 9 5950X costs $799.99 US and can be found on retail for around $700-$750 (discounted prices) even after more than a year since launch. The $800 US price tag is already the enthusiast category & anything more will be a hard pill to swallow for consumers but that's just where the whole tech industry is at right now.

AMD Ryzen 7000 'Zen 4' CPUs Launch & Availability

Availability is something that AMD has reaffirmed recently. AMD's CEO has stated that we can expect Ryzen 7000 Desktop CPUs in Fall 2022. This will mark two years since the launch of AMD's Ryzen 5000 Desktop CPUs. The AMD Ryzen 7000 CPUs and AM5 platform are officially planned to hit retail shelves on the 27th of September.

Product announcement: August 29, 2022, at 7:00PM ET / August 30, 2022, at 1:00AM CET / 7:00AM TW

August 29, 2022, at 7:00PM ET / August 30, 2022, at 1:00AM CET / 7:00AM TW Press embargo: September 20, 2022, at 9AM ET / 3PM CET / 9PM TW

September 20, 2022, at 9AM ET / 3PM CET / 9PM TW Sales embargo: September 27, 2022, at 9AM ET / 3PM CET / 9PM TW

AMD Ryzen 5000 Desktop CPUs faced severe supply shortages when they launched but things got better in the same quarter. AMD has confirmed that they won't face any supply constraints with 5nm CPUs at launch.

AMD Mainstream Desktop CPU Generations Comparison:

AMD CPU Family Codename Processor Process Processors Cores/Threads (Max) TDPs (Max) Platform Platform Chipset Memory Support PCIe Support Launch Ryzen 1000 Summit Ridge 14nm (Zen 1) 8/16 95W AM4 300-Series DDR4-2677 Gen 3.0 2017 Ryzen 2000 Pinnacle Ridge 12nm (Zen +) 8/16 105W AM4 400-Series DDR4-2933 Gen 3.0 2018 Ryzen 3000 Matisse 7nm (Zen 2) 16/32 105W AM4 500-Series DDR4-3200 Gen 4.0 2019 Ryzen 5000 Vermeer 7nm (Zen 3) 16/32 105W AM4 500-Series DDR4-3200 Gen 4.0 2020 Ryzen 5000 3D Warhol? 7nm (Zen 3D) 8/16 105W AM4 500-Series DDR4-3200 Gen 4.0 2022 Ryzen 7000 Raphael 5nm (Zen 4) 16/32 170W AM5 600-Series DDR5-5200 Gen 5.0 2022 Ryzen 7000 3D Raphael 5nm (Zen 4) 16/32? 105-170W AM5 600-Series DDR5-5200/5600? Gen 5.0 2023 Ryzen 8000 Granite Ridge 3nm (Zen 5)? TBA TBA AM5 700-Series? DDR5-5600+ Gen 5.0 2024-2025?

What are you most excited to see in AMD's next-generation Zen 4 Ryzen Desktop CPUs? Increased Core / Thread Count

Increased IPC (Single-Core Performance)

Increased Core Clocks (More Tuning Options / Headroom)

Increased Cache (Plus Vertical Stacks)

Better Integrated Graphics (RDNA 2)

More Performance Per Watt

More Overclocking Capabilities

Better Platform Support (Good BIOS at launch)

Cheaper Prices Than Ryzen 5000

More Enthusiast Options

More Entry-Level Options

New Features / Tech (PBO3/IFC2/etc) Vote to see results Poll Options are limited because JavaScript is disabled in your browser.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/intel-arc-alchemist/,"Intel Arc Alchemist ‘Xe-HPG’ GPUs Specs, Performance, Price & Availability – Everything You Need To Know","Product Info Intel Arc Alchemist Q1 2022 Manufacturer Intel Type GPUs Platforms Desktop / Notebook Expected Price TBA Expected Release Date Q1 2022

The much-awaited entry of Intel in the discrete graphics segment is getting closer and closer as the company gets ready to launch its first Arc Alchemist GPUs for gamers, based on the brand-new Xe-HPG architecture.

Intel Arc Alchemist GPU: First Major Discrete Graphics Architecture For All Kinds of Gamers

[Launched - 12/10/22]

When we talk about GPUs, only two names come to mind, AMD or NVIDIA. Both companies have been offering their latest GPUs for a diverse range of markets. These include desktops, mobility, workstations, and servers. Intel hasn't had a profound presence within the graphics segment yet, they have the highest GPU share of all companies. Why's that the case? Well, Intel has had GPUs, but only integrated ones that are found on almost all of their CPUs. Whether consumers use those GPUs is a whole different thing.

Intel is now aiming to change that, in fact, for the last couple of years and ever since the formation of their Visual Technologies Group which is headed by Raja Koduri, the company is set to release a brand new graphics architecture that is all set to enter the GPU world in 2022. Meet Arc, the brand new chapter in Intel's graphics vision!

Intel Arc Alchemist GPU - So What Are We Going To Call Them?

So we know the brand name from Intel is Arc and the first graphics lineup is going to be called Alchemist and they are going to feature the Xe-HPG (High-Performance Graphics) graphics architecture. Now the Alchemist name sounds a little too geeky but it's also a nice touch compared to all the Scientists & Star codenames that NVIDIA and AMD have been using. Also, Intel doesn't stop at Alchemist and has even more codenames detailed that they plan on launching in the future. Keep on reading to know more about that.

To make things simple, this is how each company brands its current graphics lineup [Company][Branding][Identifer][Family]:

Intel Arc A-Series

NVIDIA GeForce 30

AMD Radeon 6000

Alchemist, the mascot of Intel's 1st discrete graphics lineup. (Image Credits: Intel)

But that's not all, we also have come to know what the products will be called. Intel is confirming today at least 5 products based on the Discrete Arc A-Series GPUs, all of which are aimed at the mobility segment first. So we know the nomenclature of these graphics chips will be something like the following:

Intel Arc A300, A500, and A700 (performance-wise)

So the full branding would be something like (Note: following products are just used for naming comparisons and may not fall in the same performance category):

Intel Arc A770M

NVIDIA GeForce RTX 3080

AMD Radeon RX 6800

So now that we know what Intel is going to call their Arc Alchemist graphics products, let's move over to the specifications.

Intel Arc Alchemist GPU Architecture

The Intel ARC Alchemist GPUs are designed primarily for desktop and notebook platforms. From the information that we have currently gathered, the lineup will consist of two GPUs and each of those will have various SKUs, and each of those SKUs will be featured in a range of solutions for desktop graphics cards and mobility GPUs.

All Intel ARC Alchemist GPUs will utilize the TSMC 6nm process node and from what we already know, the Intel Xe-HPG Alchemist GPU features a Xe-Core which is the fundamental DNA of the 1st Gen ARC lineup. The Xe-Core is a compute block that is composed of 16 Vector Engines (256-bit per engine) and 16 Matrix Engines (1024-bit per engine).

Each Vector Engine is composed of 8 ALUs so, in total, we are looking at 128 ALUs per Xe-Core. The Xe-Core further features its own dedicated 192 KB L1 cache so that is a total of 6 MB of L1 cache on the complete chip.

2 of 9

Intel fuses four Xe-Cores together to form a Render Slice which is composed of 4 Ray Tracing Units, four Sampler Units, Geometry/Rasterize/HiZ engines, and two Pixel Backend blocks with 8 units on each. These Render Slices are put together to form the main GPUs. The flagship is composed of an 8 Render Slice configuration which features 32 Xe-Cores, 512 Vector Engines, and 4096 ALUs. There will be different configurations with 2, 4, 6 Render Slices but we are focusing on the flagship part in this report.

Intel’s Xe HPG architecture will be able to achieve 1.5x higher clock rates than Xe LP and also deliver 1.5x higher performance per watt. This means we are looking at clocks in the 2.1 GHz range considering the Xe LP discrete GPUs were clocked at 1.4 GHz. It also means that Intel will be able to squeeze additional power out of the architecture, should they want to, without increasing the power draw (or reducing the power draw while keeping performance constant.

2 of 9

Out of the two GPUs, the first one will be known as ACM-G10. This is the top SKU and will be featured in mainstream and high-end designs. The second GPU is known as ACM-G11. This is an entry-level SKU and as such, will be featured in entry-level and mainstream designs. Each GPU has its own SKUs with different specifications.

2 of 9

Each Matrix Engine block is also referred to as an XMX block which will handle tensor operations in both FP16 (128 FP16 ops/clock), INT8 (256 INT8 ops/clock), & INT4 (512 INT4/INT2 ops/clocks) mode. The XMX engines allow for up to 16 times the compute capabilities for INT8 inferencing. This helps boost the performance through the dedicated XeSS (Xe Super Sampling) technology.

Coming to the media engine, the Intel Arc Alchemist discrete GPUs are equipped with the latest tech which includes up to 8K60 12-bit HDR decode, up to 8k 10-bit HDR encode, VP9, AVC, HEVC, and AV1. Intel is partnering with top brands to leverage the AV1 capabilities of their Arc GPUs through the Alliance for Open Media. The new AV1 engine will provide 50x faster GPU encoding capabilities versus software mode. The tech will be integrated into several creation tools such as FFMPEG, Handbrake, Adobe Premiere Pro, DaVinci Resolve, and XSplit on launch.

2 of 9

In addition to that, the Intel Arc Xe Display Engine will support the latest display standards such as HDMI 2.1, and DisplayPort 2.0. Support for a variety of high-resolution and high refresh rate modes is also going to be available which include:

2x 8k60 HDR

4x 4k120 HDR

1080p360

1440p360

2 of 9

As for adaptive syncing technology, Intel's discrete Arc Alchemist GPUs will support both Adaptive-Sync and Speed Sync technology. The former will sync the display's refresh rate to provide a smooth and tear-free experience while the latter will speed up the latest frame, delivering low latency, no tearing, and no cap. There's also a third mode known as Smooth Sync which will blur distracting screen tears with a dithering filter.

2 of 9

Intel Xe-HPG Based Discrete Alchemist GPU Configurations:

GPU Variant Graphics Card Variant GPU Die Execution Units Shading Units (Cores) Memory Capacity Memory Speed Memory Bus TGP Xe-HPG 512EU ARC A780? Arc ACM-G10 512 EUs 4096 Up To 32/16 GB GDDR6 18 / 16 / 14 Gbps 256-bit ~225W (Desktops)

120-150W (Laptops) Xe-HPG 384EU ARC A580? Arc ACM-G10 384 EUs 3072 Up To 12 GB GDDR6 16 / 14 Gbps 192-bit 150-200W (Desktops)

80-120W (Laptops) Xe-HPG 256EU ARC A550? Arc ACM-G10 256 EUs 2048 Up To 8 GB GDDR6 16 / 14 Gbps 128-bit 60-80W (Laptops) Xe-HPG 128EU ARC A380? Arc ACM-G11 128 EUs 1024 Up To 6 GB GDDR6 16 / 14 Gbps 96-bit ~75W (Desktops) Xe-HPG 128EU ARC A350? Arc ACM-G11 128 EUs 1024 Up To 4 GB GDDR6 16 / 14 Gbps 64-bit 35-50W (Laptops) Xe-HPG 96EU ARC A330? Arc ACM-G11 86 EUs 768 Up To 4 GB GDDR6 16 / 14 Gbps 64-bit ~35W (Laptops)

Intel Arc Alchemist 'ACM-G10' GPU Specifications - The Top GPU

The top Arc Alchemist GPU is going to be the ACM-G10. It is said expected to measure 407mm2 which makes it larger than both NVIDIA's GA014 and AMD's Navi 22 chips. The ACM-G10-powered GPUs are going to compete against NVIDIA's GeForce RTX 3070(Ti) and AMD Radeon RX 6700 XT.

NVIDIA packs in tensor cores and much bigger RT/FP32 cores in its chips while AMD RDNA 2 chips pack a single ray accelerator unit per CU and Infinity Cache. Intel will also have dedicated hardware onboard its Alchemist GPUs for Raytracing & AI-assisted super-sampling tech. The full die features 32 Xe Cores, 512 EUs, 4096 ALUs, a 256-bit bus interface, & up to 16 GB GDDR6 memory featuring clock speeds between 16-18 Gbps from Samsung.

The Xe-HPG Alchemist ACM-G10 chip is suggested to feature a graphics clock of up to 2.1 GHz while the maximum clock rate will sit around 2.4 GHz. We have already spotted a flagship configuration with DG2-512 GPU running at 2.4 GHz, delivering nearly 20 TFLOPs of FP32 horsepower so we might very well end up with 2.5 GHz clocks in the final revision.

The TDP target for these chips seems to start at 120W for laptops and go all the way up to 225W for desktop parts. In either case, we can expect the final model to rock an 8+6 pin connector config, The reference model is also going to look very much like the drone marketing shot Intel put out during the ARC branding reveal.

Intel ARC ACM-G10 vs NVIDIA GA104 & AMD Navi 22 GPUs

Graphics Card Name Intel ARC A770 NVIDIA GeForce RTX 3070 Ti AMD Radeon RX 6700 XT GPU Name ACM-G10 NVIDIA GA104 AMD Navi 22 Architecture Xe-HPG Ampere RDNA 2 Process Node TSMC 6nm Samsung 8nm TSMC 7nm Die Size 406mm2 392mm2 335mm2 Transistors 21.7B 17.4B 17.2B Transistor Density 53.4M Transistors/mm2 44.4M Transistors/mm2 51.2M Transistors/mm2 FP32 Cores 32 Xe Cores 48 SM Units 40 Compute Units FP32 Units 4096 6144 2560 Max Clock 2100 MHz 1770 MHz 2581 MHz FP32 TFLOPs 17.2 TFLOPs 21.75 TFLOPs 13.21 TFLOPs Memory Bus 256-bit 256-bit 192-bit Memory Capacity 16 GB GDDR6 8 GB GDDR6X 12 GB GDDR6 Launch Q3 2022 Q2 2021 Q1 2021

Intel Arc Alchemist 'ACM-G11' GPU Specifications - The Small GPU

The Intel ACM-G11 is going to be the smaller Arc GPU, aiming at entry-level and mainstream PC platforms. The GPU is said to measure around 156mm2. This is also much smaller than the 200mm2 TU117 die that the chip will be competing against. The GA107 die size isn't known yet but it is likely to be around 160-180mm2. It is a bigger chip compared to the recently released AMD Navi 24 which measures only 107mm2.

There are two configs that feature the full-fat SKU with 1024 cores, a 96-bit, and a 64-bit variant with 6 GB and 4 GB memory capacity, respectively. The cut-down variant will come with 96 EUs or 768 cores and a 4 GB GDDR6 memory featured across a 64-bit bus interface. The chip is expected to feature a clock speed of around 2.2 - 2.5 GHz and have a sub 75 Watt power consumption which means we will be looking at connector-less graphics cards for the entry-level segment.

This GPU will be very similar to the DG1 GPU-based discrete SDV board however Alchemist will have a more improved architecture design and definitely more performance uplift over the first-gen Xe GPU architecture. This lineup is definitely going to be aimed at the entry-level desktop discrete market based on the specifications.

Intel ARC ACM-G11 vs NVIDIA GA106 & AMD Navi 24 GPUs

Graphics Card Name NVIDIA GeForce RTX 2050 AMD Radeon RX 6500 XT Intel ARC A380 NVIDIA GeForce RTX 3050 GPU Name NVIDIA GA107 AMD Navi 24 ACM-G11 NVIDIA GA106 Architecture Ampere RDNA 2 Xe-HPG Ampere Process Node Samsung 8nm TSMC 6nm TSMC 6nm Samsung 8nm Die Size TBC 107mm2 157mm2 276mm2 FP32 Cores 16 SM Units 16 Compute Units 8 Xe Cores 24 SM Units FP32 Units 2048 1024 1024 3072 Memory Bus 64-bit 64-bit 96-bit 128-bit Memory Capacity 4 GB GDDR6 4 GB GDDR6 6 GB GDDR6 8 GB GDDR6 TDP 30-45W ~75W ~75W ~75W Launch Q1 2022 Q2 2022 Q2 2022 Q1 2022

Intel Arc A-Series Desktop Graphics Lineup

The Intel Arc A7 and Arc A5 graphics cards will be the only desktop families to make use of the top ACM-G10 ""Alchemist"" GPU die. There are three graphics cards featured in the desktop family that utilize this design including the Arc A770, Arc A750, and the Arc A580. Intel has officially confirmed that the Arc A770 & Arc A750 will be available on the same day and their prices will start at $329 & $289 US, respectively.

Intel Arc A770 Graphics Card - 32 Xe Cores, 16 GB Memory, 2.1 GHz

The Intel Arc Alchemist lineup will include the flagship Arc A770 which will feature the full ACM-G10 GPU with 32 Xe-Cores and a 256-bit bus interface. The Intel Arc A770 will feature both 16 GB and 8 GB flavors across a 256-bit bus interface and a TDP of 225W. The clock speeds for the card will be rated at 2.1 GHz for the GPU (Graphics Clock) and 17.5 Gbps for the GDDR6 memory, offering up to 560 GB/s of bandwidth.

It is expected to be positioned in the same performance category as the RTX 3060 but will offer slightly better performance. We have seen several benchmarks of the Arc A770 here and here. The graphics card will be starting at $329 US pricing for the 8 GB variant while the Limited Edition with 16 GB memory will be priced at $349 US which is a very small premium for twice the memory cap. The graphics card is said to offer up to 42% better performance per dollar versus the NVIDIA RTX 3060 (overclocked variant).

2 of 9

Intel Arc A750 Graphics Card - 28 Xe Cores, 8 GB Memory, 2.05 GHz

The second part is the Intel Arc A750 which will also be equipped with an ACM-G10 GPU but house 28 Xe Cores (3584 ALUs), 28 ray tracing units 8 GB GDDR6 memory running across a 256 -bit bus interface, and a TDP target of 225W, same as the Arc A770. The card will feature a 2050 MHz GPU & 16 Gbps memory clock rate for an effective 512 GB/s of bandwidth.

This GPU will aim for the GeForce RTX 3060 series mobility options. Intel has shown the card to be an average 5% faster than the RTX 3060 across 48 modern titles. You can read more about the perf figures here. Intel also states that the Arc A750 offers up to 53 percent higher performance per dollar compared to the same overclocked RTX 3060 or 11% higher than the Arc A770 which is very impressive. That bodes well for the card considering neither NVIDIA nor AMD has plans to launch mainstream and budget cards based on their next-generation GPU architectures for a couple of more months.

Intel states their reference design will be part of their IBC or ""Intel Branded Card"" offerings which utilize a reference PCB & cooler designed by Intel themselves & parts sourced from their partners and assembled in Malaysia. These Limited Edition products will be available on launch directly from retailers and E-tailers. The graphics cards will be launched in key market regions.

2 of 9

The reference models such as the Arc A770 and Arc A750 Limited Edition will feature a beautiful cooler and some of the main highlights include:

Die-cast aluminum frame

Thermal solution with a vapor chamber and extended heat pipes

Screwless shroud design

High-performance axial fans with 15 blades

Chamfered edges

Full backplate with matte accents

90 fully controllable diffused RGB LEDs

Stealth Black I/O bracket

4 Display Outs

Both the Intel Arc A770 and Arc A750 graphics cards will come in Limited Edition flavors and also custom designs which will be available globally. The Arc A770 will be as high as the Alchemist line will go and if you were looking for more enthusiast variants, then you'd have to wait for the next-generation 'Battlemage' lineup. The graphics cards will be bundled with a range of games & apps that alone amount to around $500 US in value:

Intel Arc 5 'Advanced' Gaming Graphics Card Lineup

The Intel Arc 5 lineup is expected to include just one variant, for now, the Arc A550. The graphics card is expected to feature 24 Xe-Cores (3072 ALUs) and will also feature 8 GB of GDDR6 memory across either a 256-bit wide bus interface at the same 16 Gbps clocks for 512 Gbps of bandwidth.

The graphics card is expected to compete against the RTX 3050 and will be aiming at the $200-$299 US segment with a TDP of 175W. It is likely that this variant will be one of the best sellers if it can be priced under the $250 US bracket and close to $200 US since that will put it close to the RX 6500 XT while offering better performance, & a finer feature set like AV1, XeSS, better raytracing capabilities to name a few.

Intel Arc 3 'Enhanced' Gaming Graphics Card Lineup

As for the entry-level lineup, Intel is expected to have two offerings, the Arc A380, and Arc A310. The models are likely to feature 8 and 4 Xe-Cores with the top variant rocking 6 GB GDDR6 (96-bit) memory and the entry-level model featuring 4 GB GDDR6 memory (64-bit). The entry-level lineup will compete against NVIDIA's GeForce GTX 1650 and GTX 1050(Ti) offerings. In addition, to the gaming variants, Intel will also have two Pro variants, the Arc Pro A50 and Arc Pro A40. The first could utilize the ACM-G10 GPU while the latter could utilize the ACM-G11 GPU.

Pricing of the Intel Arc A380 is already confirmed at $129-$139 US while the Arc A310 will enter the sub-$100 US market segment.

Intel Arc A-Series Desktop Graphics Card Lineup 'Official':

Graphics Card Variant GPU Die Shading Units (Cores) XMX Units GPU Clock (Graphics) Memory Capacity Memory Speed Memory Bus Bandwidth TGP Price Arc A770 Arc ACM-G10 4096 (32 Xe-Cores) 512 2.10 GHz 16 GB GDDR6 17.5 Gbps 256-bit 560 GB/s 225W $349 Arc A770 Arc ACM-G10 4096 (32 Xe-Cores) 512 2.10 GHz 8 GB GDDR6 16 Gbps 256-bit 512 GB/s 225W $329 US Arc A750 Arc ACM-G10 3584 (28 Xe-Cores) 448 2.05 GHz 8 GB GDDR6 16 Gbps 256-bit 512 GB/s 225W $249 US Arc A580 Arc ACM-G10 3072 (24 Xe-Cores) 384 1.70 GHz 8 GB GDDR6 16 Gbps 256-bit 512 GB/s 175W $249 US Arc A380 Arc ACM-G11 1024 (8 Xe-Cores) 128 2.00 GHz 6 GB GDDR6 15.5 Gbps 96-bit 186 GB/s 75W $139 US Arc A310 Arc ACM-G11 512 (4 Xe-Cores)) 64 TBD 4 GB GDDR6 16 Gbps 64-bit TBD 75W $59-$99 US

Intel Arc A-Series Entry-Level Desktop Graphics Performance

So far, Intel has showcased the official performance numbers of two graphics cards, the Arc A750 and the Arc A380. The Intel Arc A380 seems to be competing against the AMD Radeon RX 6400 as it trades blows with it while the Arc A750 offers up to 17% better performance than the NVIDIA RTX 3060 graphics card.

Intel has started to share performance numbers and information regarding its high-end Arc Alchemist GPUs too. The first of these designs is the Intel Arc A750 Limited Edition which was also teased back at IEM 2022. The performance benchmarks shared by Intel include five games which include F1 2021, Cyberpunk 2077, Control, Borderlands 3, and Fortnite. All of these games were tested at 1440p resolution using the high preset and the Arc A750 graphics card was compared against NVIDIA's GeForce RTX 3060 which it beat by delivering up to 17% performance.

Intel Arc A750 Limited Edition Performance Benchmarks in Games:

Intel Arc A750 Limited Edition Performance Demo In Cyberpunk 2077:

As you can see in the disclaimers below, both graphics cards were tested on the same system configurations comprising an Intel Core i9-12900K CPU and the latest Windows 11 version. In terms of drivers, the RTX 3060 used the 516.40 version while the Arc A750 used an engineering driver. You can also see a more detailed performance breakdown (FPS) in the slide below:

Intel Arc A750 Limited Edition Performance Disclaimers & Configurations Used:

All of the testing in the official benchmarks was done using an Intel Core i5 12600k with 32 GB of 3200 MHz DDR4 RAM and Windows 11 OS and a 4TB NVME SSD. Only the GPUs, ie the GTX 1650, RX 6400, and Intel Arc A380 were swapped between them. Testing was conducted almost a month back so it's worth noting that driver performance would almost certainly have increased during this time:

As we can see, the Intel Arc A380 trades blows with the AMD RX 6400 and (less occasionally) with the NVIDIA GTX 1650. It actually beats the RX 6400 in Total War: Troy, Naraka Bladepoint, The Witcher 3, and F1 2021. Considering this is the official documentation, it's actually pretty cool that Intel did not present a one-sided story about its upcoming GPU. Here is also where the story gets really interesting. FineWine™ is a term that AMD fans and readers of this site would be very familiar with and was a popular term to describe AMD's ongoing post-launch driver development back in the days when it used to be cash-strapped and was the underdog.



Compute workloads are once again a mixed bag when it comes to Intel Arc A380. It beats out both the GTX 1650 and RX 6400 handily in HandBrake and is slightly worse than the GTX 1650 in DaVinci Resolve.

Intel Arc A-Series Mobile Graphics Lineup

The Mobility lineup was the first to launch in the consumer segment with five new discrete chips within three different tiers. The Intel Arc 7 and Arc 5 lineup will utilize the ACM-G10 GPU while the Arc 3 lineup will utilize the ACM-G11 GPU. All of these GPUs are equipped with the same feature set which includes support for XeSS, DirectX XII Ultimate, XMX acceleration, Xe Media Engine, and PCIe Express 4.0 along with a host of other features.

Intel Arc 7 'High-Performance' Gaming GPU Lineup

The Intel Arc 7 lineup is going to utilize the flagship ACM-G10 GPU and will feature two variants, the Arc A770M and the Arc A730M. The top-end variant for mobility platforms, the Arc A770M, will be equipped with the full ACM-G10 configuration, utilizing 32 Xe-Cores for 4096 ALUs, 32 ray tracing units, a graphics clock of 1650 MHz, up to 16 GB GDDR6 memory that operates across a 256-bit wide bus interface and a TDP target of 120-150W. This is comparable to the GeForce RTX 3070 Ti Max-Q variant.

The second part is the Intel Arc A730M which will also be equipped with an ACM-G10 GPU but house 24 Xe Cores (3072 ALUs), 24 ray tracing units, a graphics clock of 1100 MHz, 12 GB GDDR6 memory running across a 192-bit bus interface and a TDP target of 80-120W. This GPU will aim for the GeForce RTX 3060 series mobility options.

Intel Arc 5 'Advanced' Gaming GPU Lineup

The Intel Arc 5 lineup will only feature one variant for now that makes use of the ACM-G10 GPU. It will feature 16 Xe Cores (2048 ALUs), 16 Ray tracing units, a 900 MHz graphics clock, 8 GB GDDR6 memory running across a 128-bit bus interface, and a TDP range of 60-80W. This chip should aim for the RTX 3060 Max-Q graphics chip.

Intel Arc 3 'Enhanced' Gaming GPU Lineup

Lastly, we have the Intel Arc 3 lineup which is the entry-level and power-optimized family making use of the ACM-G11 GPU. The lineup features the Arc A370M which utilizes the full GPU config & 8 Xe Cores (1024 ALUs), 8 ray tracing units, 1550 MHz graphics clock, 4 GB of 64-bit GDDR6 memory, and a TDP range of 35-50W. This chip would be tackling the GeForce RTX 3050 series.

The second option is the Intel Arc A350M which features 6 Xe cores (768 ALUs), 6 ray tracing units, 1150 MHz graphics engine clock, a 4 GB 64-bit bus interface, and a TDP range of 25-35W which is going to aim the entry-level MX500 series options from NVIDIA.

Intel Arc A-Series Mobility GPU Lineup:

Graphics Card Variant GPU Variant GPU Die Execution Units Shading Units (Cores) Memory Capacity Memory Speed Memory Bus TGP Arc A770M Xe-HPG 512EU Arc ACM-G10 512 EUs 4096 16 GB GDDR6 16 Gbps 256-bit 120-150W Arc A730M Xe-HPG 384EU Arc ACM-G10 384 EUs 3072 12 GB GDDR6 14 Gbps 192-bit 80-120W Arc A550M Xe-HPG 256EU Arc ACM-G10 256 EUs 2048 8 GB GDDR6 14 Gbps 128-bit 60-80W Arc A370M Xe-HPG 128EU Arc ACM-G11 128 EUs 1024 4 GB GDDR6 14 Gbps 64-bit 35-50W Arc A350M Xe-HPG 96EU Arc ACM-G11 96 EUs 768 4 GB GDDR6 14 Gbps 64-bit 25-35W

Intel Arc A-Series Entry-Level Mobility GPU Performance

Intel has been tight-lipped about the performance of its Arc Alchemist graphics but they are now starting to share some performance metrics of their entry-level parts. We also know through our own sources where these GPUs will land. The ACM-G10 is expected to be an NVIDIA GA104 & AMD Navi 22 competitor while the ACM-G11 is expected to compete against NVIDIA GA106 / GA107 and AMD Navi 24 GPUs.

The flagship model should end up with around 18.5 TFLOPs FP32 compute which is 40% more than the RX 6700 XT but 9% lower than the NVIDIA RTX 3070. In terms of performance positioning, the top 512 EU variant is said to compete against the RTX 3070 / RTX 3070 Ti, the 384 EU variant is said to compete against the RTX 3060 / RTX 3060 Ti on desktops. On the laptop side, the 512 EU might be just as fast as the RTX 3080, 384 EU variant around RTX 3070 level and the 256 EU will end up against the RTX 3060.

Performance for the entry-level ACM-G11 GPU is expected to land between the GeForce GTX 1650 and GTX 1650 SUPER but with raytracing capabilities. This performance level, if priced correctly, will be highly competitive against similar solutions from NVIDIA and AMD.

Intel has shown its entry-level Arc A370M GPU offering a smooth 60 FPS+ gaming experience at 1080p across a variety of games versus the integrated Intel Iris Xe graphics. Then in another slide, they show competitive titles can deliver over 90 FPS at 1080p when running on the Arc A370M series.

Intel also highlights the content acceleration features integrated within Arc GPUs with the A370M providing a 2.4x boost over the integrated Iris Xe GPU. Intel hasn't shared any performance figures versus the competition yet.

2 of 9

Intel Arc Alchemist GPU Gaming Features

Intel knows that making a GPU is just one part of the whole graphics ecosystem and they are also creating a wide portfolio of features that will go into power their Arc GPU lineup. Raja Koduri and Lisa Pearce have highlighted that drivers play a crucial role in graphics development & they are collaborating with a list of developers and studios to optimize their GPUs for current and next-gen AAA games and creative applications.

2 of 9

Intel's DG2 ARC Alchemist will offer the first true gaming drivers and that is its own initiative. NVIDIA and AMD have worked for years to optimize their current suite of gaming drivers and to get Intel's first discrete gaming GPUs on the same level as the competition is certainly a big deal. A range of driver-specific optimizations including Resizable BAR support is also headed to Linux for Intel's Arc Alchemist GPUs.

Technologies that will be incorporated by Intel Arc GPUs include:

XeSS (Xe Super Sampling) AI-Assisted Super Sampling Technology

XeGTAO (Ground-Truth Ambient Occlusion)

Xe DeepLink Technology

XeXMX with Xe-Cores

Hardware-Accelerated Raytracing

Intel GameDev Boost with 1oneAPI Tool Kit

Resizable-Bar Support for Desktops & Laptops

Intel has shown several games that will utilize XeSS in their recent demos such as 505 Game's Death Stranding, IO Interactive's Hitman 3, and Exor Studio's The Riftbreaker, all of which are fairly new AAA titles. Intel showcased both games running on an undisclosed Xe-HPG ARC Alchemist GPU. Both games were compared on 1080p resolution and 4K XeSS upscaling. Although the videos are of 1080p quality, you can still see that 4K XeSS really helps enhance the visual quality in both titles.

Intel ARC Alchemist 4K XeSS Super Resolution Demo In Hitman 3:

2 of 9

Intel ARC Alchemist 4K XeSS Super Resolution Demo In Riftbreakers:

2 of 9

The upscaled images are both sharp, and less blurry and show the textures on various objects in more detail. We have a very in-depth interview with the principal engineer of XeSS here which talks about how the company plans on expanding the technology in their future updates. You can also see an internal 4K XeSS demo here along with further XeSS tech details here.

Intel Arc Alchemist XeSS Technology (GDC 2022 Demo)

Intel XeSS is a super-sampling technique that leverages Machine Learning to reconstruct a low-resolution frame into a high-resolution frame, running at a fraction of the cost of rendering at a higher resolution such as 4K. The core principle of XeSS is to take advantage of ML through the integrated XMX AI acceleration hardware that is featured on the Xe-Cores for Arc Alchemist GPUs. XeSS will be fully compliant with DirectX 12 and uses the Intel Vector Shading language-based NN (Neural Networking) running on Intel's Arc SIMD architecture.

Compared to native resolution (4K), XeSS 4K with XMX takes less than half the cost to render a scene. The technology is also DP4a compliant which means it can run on GPUs without AI or ML acceleration engines such as XMX but offer similar performance and image quality.

In terms of image quality, Intel XeSS will eliminate all kinds of ghosting with minimal artifacts (such as shimmering) when compared to other upscaling methods such as TAAU. It also comes with its own built-in sharpening engine and will be replacing TAA. Intel has stated that XeSS can achieve much higher scaling ratios without compromising quality than Temporal Supersampling or Spatial upscaling.

Intel also shared a brand new XeSS Rens demo which was running on an Intel Arc Alchemist GPU that was running at a fixed frequency. The demo was run on 1440p with raytracing and 4K with raytracing enabled. The demo was run at each resolution on 5 different XeSS presets that range from Ultra Performance, Performance, Balanced, Quality, and Ultra Quality. The Ultra performance mode offers up to 2.53x performance boost over native while Ultra Quality offers a 27% boost in performance over native at 4K resolution.

Intel Arc Alchemist Raytracing Technology (GDC 2022 Demo)

Next up, Intel talked about its raytracing approach and how they are making it better than AMD's and NVIDIA's approach. Intel will be bypassing SIMD divergency for hit shaders, and textures and using a set of HW sorting for rays and threads to maximize the uptime of each lane. This would allow Intel to essentially automatically accelerate raytracing on hardware.

In a slide showcasing performance metrics on a pre-production Intel Arc Alchemist silicon, the GPU offers 0.775x performance in RayQuery (relative) vs DXR1.0. Intel states that this is a bigger perf hit than competitor 1 (NVIDIA) while competitor 2 (AMD) takes an even bigger hit. Intel also offers their own conclusion and fixes to why this performance hit is seen on their GPUs.

In addition to XeSS support, Intel also showed a brief demo of raytracing running in Metro Exodus on its own ARC Alchemist GPUs. Another key technology Intel talked about is XeGTAO which is the brand new Gound-Truth Ambient Occlusion method, an advanced form of screen-space ambient occlusion, that delivers greater accuracy for higher image quality.

Intel ARC Alchemist Raytracing Demo In Metro Exodus:

2 of 9

Intel XeSS Is Backwards Compatible With DG1 'Xe-LP' & 11th Gen CPUs

Intel has also confirmed that the XeSS technology will be backward compatible with both Xe-LP-based DG1 GPUs & iGPUs on the 11th Gen Tiger Lake GPUs.

Intel also wants to leverage the workstation and content creation market with its Xe-HPG GPUs in applications such as 3DSMax where they can give NVIDIA's Quadro and AMD Radeon PRO graphics cards some tough competition. It is specifically stated that Intel's ARC GPUs can offer great graphics performance within content creation and development applications.

Intel also emphasized the driver release and how it plans to release them on regular basis and new releases every time a major title is launched. The company has gone on a major hiring spree for its graphics division, acquiring renowned names from the industry over the last couple of weeks. Since we mentioned drivers, Intel will also have integrated overclocking tools within their latest driver suite available when Arc Alchemist GPUs hit the shelves.

Intel ARC Alchemist Internal XeGTAO Demo:

2 of 9

Intel also announced that devs will have access to their XeSS technology through the DevMesh program and anyone from indie to AAA developers can submit a form from the official Intel DevMesh site. Intel is touting up to 2x FPS with their XeSS Super Resolution technology so it will be great to have more options for gamers & the tech also will be workable on both NVIDIA and AMD GPUs.

Moving away from GPUs for a bit, Intel also discussed how they can leverage their hybrid design introduced in 12th Gen Alder Lake CPUs within game engines. Intel and IO Interactive have been optimizing both the GPU and CPU sides of things. It is stated that developers can leverage back-ground tasks such as AI acceleration, Character Animation, Physics, Collisions, audio-processing, and more, leaving the performance cores with their leading single-threaded performance to be available for the more demanding tasks.

Intel DeepLink Demo Using ARC Alchemist & Iris Xe GPUs:

2 of 9

The last most interesting thing shared by Intel was their DeepLink technology which will help Xe-HPG ARC Alchemist GPUs work alongside Iris Xe to boost performance in creation applications. A demo showcasing a standalone ARC Alchemist GPU and another system with DeepLink where the same ARC Alchemist GPU is working alongside an Iris Xe GPU integrated on Intel's CPUs is shown. The DeepLink system ended up with 40% faster transcoding in Handbrake as it was able to utilize more performance out of the Iris Xe chip.

There Intel Arc 3 series is available starting now in various laptop designs while the Arc 5 and Arc 7 GPUs will be hitting mobile segment in early Summer so around May or June. Expect more info on these parts in the coming months.

Intel Arc Alchemist General Performance Expectations

Intel has been tight-lipped about the performance of its Arc Alchemist graphics. It is likely that the company will be releasing more benchmarks as they get super close to launching. But despite that, we know through some leaks where these GPUs will land. The DG2-512 is expected to be an NVIDIA GA104 & AMD Navi 22 competitor while the DG2-128 is expected to compete against NVIDIA GA106 / GA107 and AMD Navi 24 GPUs.

The flagship model should end up with around 18.5 TFLOPs FP32 compute which is 40% more than the RX 6700 XT but 9% lower than the NVIDIA RTX 3070. In terms of performance positioning, the top 512 EU variant is said to compete against the RTX 3070 / RTX 3070 Ti, the 384 EU variant is said to compete against the RTX 3060 / RTX 3060 Ti on desktops. On the laptop side, the 512 EU might be just as fast as the RTX 3080, the 384 EU variant around RTX 3070 level and the 256 EU will end up against the RTX 3060.

Performance for the entry-level DG2-128 GPU is expected to land between the GeForce GTX 1650 and GTX 1650 SUPER but with raytracing capabilities. Based on initial leaks, the DG-128 has shown up to be around the same tier as GeForce RTX 3050 Ti while the DG2-512 has shown up on par with NVIDIA's GeForce RTX 3070 Ti. This performance level, if priced correctly, will be highly competitive against similar solutions from NVIDIA and AMD.

Intel Arc Alchemist GPU Price & Availability

So that brings us to the next segment of Intel Arc Alchemist GPUs, and that is pricing & availability. One big advantage that Intel could have over AMD and NVIDIA is that with these cards, they might enter the sub-$250 US market which has not seen a worth-it product for some time. The recent AMD Radeon RX 6500 XT for $199 US has ended up as a failure in multiple perspectives while the RTX 3050 from NVIDIA for $249 US is better on the features/performance side but pricing is again going to be questionable.

Now Intel would also be bound by the same chip procurement issues that other companies are facing by relying on TSMC's 6nm process node but the 6nm node itself isn't that much in demand as compared to the 7nm process. So getting those wafers mostly is all about how much dollars you can flex at TSMC and Intel has really wide pockets. With that in mind, they could potentially have a bigger supply than AMD and one that can even challenge NVIDIA if they manage to price it right around the same level or lower. Lower will be a huge win for Intel but that remains to be seen. As one of Raja's strategies, the top part may actually end up with an MSRP close to $399 US while the entry-level GPUs will end up with a top-bin price of $99-$249 US.

But availability is the more concerning thing. This is Intel's first major discrete GPU launch for both desktop PCs and laptops. Due to driver and software delays, Intel launched its first Arc GPUs in Q2 2022 (a delay from its original Q1 2022 release window) and only in the Chinese market segment. The mobility lineup has only started making its way in the US and EU markets while the desktop cards, which have only received the entry-level Arc A380, are so far China-exclusive. The rest of the lineup is expected to launch by the end of Summer and the company hopes to bring more added optimizations through its drivers for current-generation titles based on the DirectX 12 and Vulkan APIs.

The graphics cards will be available in both reference 'Limited Edition', 'Standard', and custom models with GUNNIR prepping both Arc A380 and high-end variants in non-reference designs. Other manufacturers are also expected to offer their designs once we get closer to the proper discrete graphics card launch of Arc GPUs.

Intel Arc GPU Roadmap & Future Products

Each generation of ARC GPU will be named after fictional character classes from various games. The first is Alchemist and is the naming scheme attached to the first generation of Xe-HPG GPUs. According to Intel, the Alchemist name was derived from various fantasy games, including Final Fantasy XIV & Dungeons and Dragons. In those games, the Alchemist is able to craft powerful potions from basic herbs, elements, and other crafting materials.

The Alchemist will be the start of Intel's ARC graphics journey as the company also revealed the codenames for its next-generation Xe-HPG lineups to be Battlemage, Celestial, and Druid. These characters were also embedded in the presentation slide during Architecture Day 2021. The site reports that the Battlemage name has been derived from the Elder Scrolls world, Celestial comes from several fantasies including the recent Marvel Eternals movie while Druid has been a common character in the fantasy RPG/RTS universe. As you can tell, these are all fantasy and mythological characters which sound cool, and it's good to see Intel is thinking out of the box & going with more gaming-inspired names while their competitors use GPU naming conventions based on Scientists and Stars.

We have also seen rumors of the 5th Gen Arc GPU codename which is expected to be called 'Elasti' and expected for a 2026 release.

Currently, these characters serve as an icon for each of their respective ARC GPU generation but Intel is asking the community for input on what else could be done with them. Intel hints that they may offer ARC-branded goodies such as T-Shirts with these characters and that sounds like a cool idea. One suggestion could be to feature these characters in future technology demos such as the recent XeSS showcase. With that said, you do get to see some really high-res images that you could use as wallpaper on the desktop and mobile devices to showcase your support for Intel's ARC GPU family.

2 of 9

Intel ARC Gaming GPU Lineup

GPU Family Intel Xe-HPG Intel Xe-HPG Intel Xe2-HPG Intel Xe3-HPG Intel Xe Next Intel Xe Next Next GPU Products ARC Alchemist GPUs ARC Alchemist+ GPUs ARC Battlemage GPUs ARC Celestial GPUs ARC Druid GPUs ARC E*** GPUs GPU Segment Mainstream Gaming (Discrete) Mainstream Gaming (Discrete) Mainstream / High-End Gaming (Discrete) Mainstream / High-End Gaming (Discrete) Mainstream / High-End Gaming (Discrete) Mainstream / High-End Gaming (Discrete) GPU Gen Gen 12 Gen 12 Gen 13? Gen 14? Gen 15? Gen 16? Process Node TSMC 6nm TSMC 6nm TSMC 4nm? TSMC 3nm? TBA TBA Specs / Design 512 EUs / 1 Tile / 1 GPU 512 EUs / 1 Tile / 1 GPU 1024 EUs / 1 Tile / 1 GPU TBA TBA TBA Memory Subsystem GDDR6 GDDR6 GDDR6(X)? TBA TBA TBA Launch 2022 2023? 2024? 2026 2026+ 2026+

Overall, Arc Alchemist marks the start of a new era for Intel and its graphics team, bringing the next-gen GPUs for gamers, content creators, and power users across the globe. We can't wait to see their GPUs in action this quarter!","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/intel-core-i9-13900k/,"Intel Core i9-13900K, The 13th Gen Raptor Lake Flagship CPU, Specs, Price, Performance & Availability – Everything We Know So Far","Product Info Intel Core i9-13900K 2H 2022 Manufacturer Intel Type CPU Platforms Desktop PC Expected Price ~$599 US Expected Release Date 2H 2022

Intel Core i9-13900K will be the flagship chip of the 13th Gen Raptor Lake Desktop CPU family that will feature support on the LGA 1700/1800 socket platform. Just like its predecessor, Alder Lake, the Raptor Lake chip will adopt a similar hybrid architecture design, composed of P-cores and E-cores but with more cores, higher clocks, and a larger cache for faster performance.

Intel Core i9-13900K CPU: The 13th Gen Raptor Lake Desktop Flagship With 24 Cores & 5.8 GHz Clock Speeds

[Updated- 20/10/22]

While we have already detailed what Intel's 13th Gen Raptor Lake and Z790 platform brings to the table over here, I believe that the fastest chip in the lineup deserves its own roundup. Intel's Raptor Lake isn't a massive architectural upgrade but a refinement of the existing Alder Lake design that'll entice gamers and content creators with more of virtually everything. The Core i9-13900K being the flagship of this lineup will have to prove that it's the real deal by not only showcasing a decent CPU performance gain over the Core i9-12900K but also against AMD's Ryzen 7000 flagship chip based on the Zen 4 core.

Intel 13th Gen Raptor Lake Desktop CPUs Expected Features:

Up To 24 Cores & 32 Threads

Brand New Raptor Cove CPU Cores (Higher P-Core IPC)

Based on 10nm ESF 'Intel 7' process node

Supported on existing LGA 1700 motherboards

Dual-Channel DDR5-5600 Memory Support

20 PCIe Gen 5 Lanes

Enhanced Overclocking Features

125W PL1 TDP (Flagship SKUs)

Intel hasn't officially confirmed the Core i9-13900K CPU part yet but there are multiple leaks that confirm its existence and also the fact that the chip will get an even faster 'Special Edition' variant with even higher clock speeds. So with that said, let's get on with the specifications.

Intel Raptor Lake vs AMD Raphael Desktop CPUs Comparison 'Confirmed'

CPU Family AMD Raphael (RPL-X) Intel Raptor Lake (RPL-S) Process Node TSMC 5nm Intel 7 Architecture Zen 4 (Chiplet) Raptor Cove (P-Core)

Gracemont (E-Core) Flagship SKU Ryzen 9 7950X Core i9-13900K Cores / Threads Up To 16/32 Up To 24/32 Total L3 Cache 64 MB (+3D V-Cache) 36 MB Total L2 Cache 16 MB 32 MB Total Cache 80 MB 68 MB Max Clocks (1T) 5.85 GHz 5.8 GHz Memory Support DDR5 DDR5/DDR4 Memory Channels 2 Channel (2DPC) 2 Channel (2DPC) Memory Speeds DDR5-5200 DDR5-5600

DDR4-3200 Platform Support 600-Series (X670E/X670/B650/A620) 600-Series (Z690/H670/B650/H610)

700-Series (Z790/H770/B760) PCIe Gen 5.0 Both GPU & M.2 (Extreme chipsets only) Both GPU & M.2 (700-Series only but split) Integrated Graphics AMD RDNA 2 Intel Iris Xe Socket AM5 (LGA 1718) LGA 1700/1800 TDP (Max) 170W (TDP)

230W (PPT) 125W (PL1)

240W+ (PL2) Launch September 2022 October 2022

Intel Core i9-13900K 'Raptor Lake' CPU Specifications

In terms of specifications, the Intel Core i9-13900K CPU will offer a total of 24 cores and 32 threads. These are divided into an 8+16 configuration which includes 8 P-Cores based on the Raptor Cove and 16 E-Cores based on the Gracemont core architecture. All of these cores are fabricated on the 10nm ESF or 'Intel 7' process node. Given that the chip will feature more cores and cache using the same process node, the overall die size would be a bit bigger than Alder Lake's C0 desktop die.

As for cache, the Intel Core i9-13900 Raptor Lake CPU carries 16 MB of L2 cache for the P-Cores (2 MB per core) and 16 MB of L2 cache for the E-cores too (4MB per cluster of 4 cores). This gives us a total of 32 MB of L2 cache which combined with the L3 cache will offer us a total of 68 MB of cache which is rumored to be labeled as 'Game Cache'.

A leaked CPU-z screenshot showing an Intel Core i9-13900K Engineering Sample CPU. (Image Credits: Chiphell Forums)

The Core i9-13900K will carry some impressive clock speeds of 3.0 GHz base, 5.5 GHz (all-core) boost, and a massive 5.8 GHz single-core boost clock. The CPU will feature a based TDP of 125W (PL1) and PL2 TDP (or MTP - Maximum Turbo Power) of 253W. The actual figure is said to be around 350W at max which will be 100W higher than the Core i9-12900KS.

Just like Alder Lake, the Intel Raptor Lake CPUs including the Core i9-13900K won't feature any AVX-512 support since that has been removed from the current and future mainstream processors. The CPU will also offer improved DDR5 memory support while retaining DDR4 support too. The DDR5 memory will be natively supported with speeds of up to 5600 MT/s and one can expect over 8000 MT/s speeds once Raptor Lake comes to the market.

On the other hand, the CPU will get some enhanced overclocking features such as the following:

Added per-core OC TVB support

Added package OC TVB support

Added Efficient TVB support

Intel will also be launching its first 6 GHz CPU, the Core i9-13900KS, at CES 2023. This would make Raptor Lake the first x86 CPU family to offer a clock frequency that's going to breach the 6 GHz barrier. Knowing that AMD is going all-out with their own Zen 4-powered Ryzen 7000 chips in the clock department with 5.5 GHz+ being achieved across several threads and rumors of 5.6-5.8 GHz single-core clocks in the air, it looks like Intel will just unleash everything it is capable of with Raptor Lake.

Intel Core i9-13900KS CPU Specifications 'Preliminary':

CPU Name Intel Core i9-13900KS Intel Core i9-13900K Intel Core i9-12900KS Intel Core i9-12900K Process Node 10nm ESF 'Intel 7' 10nm ESF 'Intel 7' 10nm ESF 'Intel 7' 10nm ESF 'Intel 7' P-Core Architecture Raptor Cove Raptor Cove Golden Cove Golden Cove E-Core Architecture Gracemont Gracemont Gracemont Gracemont Hybrid Configuration 8+16 8+16 8+8 8+8 Cores / Threads (Max) 24/32 24/32 16/24 16/24 Base Clock TBD 3.0 GHz 3.4 GHz 3.2 GHz One-Core Boost ~6.0 GHz 5.8 GHz (1-2 Cores) 5.5 GHz 5.2 GHz All-Core Boost ~5.6 GHz 5.5 GHz (All-Cores) 5.2 GHz 5.0 GHz Memory Support (Native) DDR5-5600 DDR5-5600 DDR5-4800 DDR5-4800 L2 Cache 32 MB 32 MB 14 MB 14 MB L3 Cache 36 MB 36 MB 30 MB 30 MB TDP (PL1) 150W 125W 150W 125W TDP (PL2) 253W 253W 241W 241W Price (MSRP) ~$750 US ~$599 US $739 US $589 US Launch 2H 2022 2H 2022 2H 2021 2H 2021

Intel Core i9-13900K 'Raptor Lake' CPU Performance

Coming to the performance section, Intel has officially stated that the Raptor Lake CPUs bring up to a double-digit performance boost. They haven't stated if this is single-core or multi-core but based on recent leaks, we can tell that the performance bump mostly comes in the multi-threaded section thanks to the increased core count but single-core performance also gets a decent bump thanks to the increased clocks and cache.

Intel's Core i9-13900K Raptor Lake ES1 CPU is mostly on par with the Intel Core i9-12900K with a 4.0 GHz clock speed but the ES3 CPU ends up 7% faster in single and 28% faster in multi-thread tests. It also delivers a 34% higher single-threaded and 21% higher multi-threaded performance versus the AMD Ryzen 9 5950X. Now AMD is expected to gain an additional >15% single-threaded IPC uplift and an overall >35% multi-threaded uplift which comes through a combination of architectural & clock improvements, gen-over-gen with Zen 4 Ryzen 7000 CPUs so it will be a really close battle in between the two flagships.

Intel Raptor Lake Core i9-13900K CPU-z ES (MT) Benchmarks Multi-Thread 0 4000 8000 12000 16000 20000 24000 0 4000 8000 12000 16000 20000 24000 Intel Core i9-13900K (ES3) 18k AMD Ryzen 9 5950X 13k Intel Core i9-13900K (ES1) 12.4k Intel Core i9-12900K 11.7k

Intel Raptor Lake Core i9-13900K CPU-z ES (ST) Benchmarks Single-Thread 0 200 400 600 800 1000 1200 0 200 400 600 800 1000 1200 Intel Core i9-13900K (ES3) 880 Intel Core i9-12900K 834 AMD Ryzen 9 5950X 658 Intel Core i9-13900K (ES1) 611

In terms of gaming performance, the Intel Core i9-13900K CPU has been said to be the better chip when it comes to running games. We have been told that the CPU will reclaim the gaming crown from AMD's Ryzen 7 5800X3D for a short amount of time before AMD fires back with its 3D V-Cache lineup which is expected to debut this year too.

Intel Core i9-13900K 'Raptor Lake' Price & Availability

Intel's pricing strategy starting its 12th Gen Alder Lake lineup has been very aggressive and that has definitely helped them sell enough units to start making a dent in AMD's Ryzen market share & its revenue. Segments such as the Core i5 and Core i7 are showing up in the 'Top 10 Sellers' on several NA & EU-based retailers but the top Core i9 parts are what enthusiasts settle for.

It is likely that Intel will retain the prices of its chips moving forward. Intel only bumped the pricing up by $50 US when they doubled the core counts from 8 on Core i9-11900K ($539 US SEP) to 16 on the Core i9-12900K ($589 US SEP). Since Raptor Lake isn't a doubling and is mostly a refinement of Alder Lake, we can expect the pricing to remain the same and at most, hit the $599 US mark. AMD's flagship is likely to cost around $700-$800 US which means that Intel may have a big edge in price to performance segment.

As for launch and availability, the Intel 13th Gen Raptor Lake Desktop CPUs are expected to launch alongside the 700-series chipset family on 20th October for a price of $599.00 US (RCP).","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/nvidia-geforce-rtx-4080/,"NVIDIA GeForce RTX 4080 Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info NVIDIA GeForce RTX 4080 2022 Manufacturer NVIDIA Type Graphics Card Platforms PC Expected Price $1199 US Expected Release Date 2022

NVIDIA GeForce RTX 4080 will be the next-generation gaming flagship, offering the latest graphics architecture based on Ada Lovelace GPUs. The graphics card will be replacing the RTX 3080, a very popular gaming graphics card on its own.

NVIDIA GeForce RTX 4080 Graphics Card - Purely Designed For Enthusiast Gamers

[Launched- 16/11/22]

While there's no denying the enthusiasm around the higher-end GeForce RTX 4090 series graphics cards that offer the best of the best gaming performance, the RTX 4080 series graphics cards are the tier that most high-end gamers will be getting considering it doesn't break your wallet and still offers a huge amount of gaming performance. It's simple, the RTX 4090 series will be aimed at users who want the best of the best without worrying about the amount of money they are spending while the RTX 4080 series is aimed at users who want the best gaming performance at the best possible price.

The previous GeForce RTX 3080 was touted to offer a huge improvement over the RTX 2080 and while that claim fell a little short, it looks like the RTX 4080 has the potential to exceed far beyond its predecessor due to several reasons which will be apparent in this roundup detailing its specs & performance figures.

We should expect similar things with the next-generation gaming powerhouse too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new Ada Lovelace or AD10* class GPUs that will be powering the next-gen GeForce RTX 40 series cards.

You can also read the expected specs, prices, and performance of other upcoming RTX 40 GPUs in the posts below:

NVIDIA's AD103 'Ada Lovelace' GPU - The Next-Gen Powerhouse

Starting with the GPU configuration, the NVIDIA GeForce RTX 4080 series graphics cards are said to utilize the AD103 GPU core. Think of AD103 as an optimized version of AD102 that sits between the AD102 and AD104 GPUs. The GPU is said to measure around 400mm2-450mm2 and will utilize the TSMC 4N process node which is an optimized version of TSMC's 5nm (N5) node designed for the green team.

The NVIDIA Ada Lovelace AD103 GPU is expected to feature up to 7 GPC (Graphics Processing Clusters). This is the same GPC count as the Ampere GA102 GPU and one additional GPC over the GA103 GPU. Each GPU will consist of 6 TPCs and 2 SMs which is the same configuration as the existing chip. Each SM (Streaming Multiprocessor) will house four sub-cores which is also the same as the GA102 GPU. What's changed is the FP32 & the INT32 core configuration. Each sub-core will include 128 FP32 units but combined FP32+INT32 units will go up to 192. This is because the FP32 units don't share the same sub-core as the IN32 units. The 128 FP32 cores are separate from the 64 INT32 cores.

So in total, each sub-core will consist of 32 FP32 plus 16 INT32 units for a total of 48 units. Each SM will have a total of 128 FP32 units plus 64 INT32 units for a total of 192 units. And since there are a total of 84 SM units (12 per GPC), we are looking at 10,752 FP32 Units and 5,376 INT32 units for a total of 18,432 cores. Each SM will also include two Wrap Schedules (32 thread/CLK) for 64 wraps per SM. This is a 50% increase on the cores (FP32+INT32) and a 33% increase in Wraps/Threads vs the GA102 GPU.

NVIDIA AD103 'Ada Lovelace' Gaming GPU Block Diagram:

NVIDIA Ada Lovelace 'AD103' GPU Specs 'Preliminary':

GPU Name AD103 GA102 GA103 TU102 GPC 7 (Per GPU) Same 1.16x 1.16x TPC 6 (Per GPC) Same 1.20x Same SM 2 (Per TPC) Same Same Same Sub-Core 4 (Per SM) Same Same Same FP32 128 (Per SM) Same Same 2x FP32+INT32 192 (Per SM) 1.5x 1.5x 1.5x Warps 64 (Per SM) 1.33x 1.33x 2x Threads 2048 (Per SM) 1.33x 1.33x 2x L1 Cache 192 KB (Per SM) 1.5x 1.5x 2x L2 Cache 64 MB (Per GPU) 10.6x 16x 10.6x ROPs 32 (Per GPC) 2x 2x 2x

Moving over to the cache, this is another segment where NVIDIA has given a big boost over the existing Ampere GPUs. The Ada Lovelace GPUs will pack 192 KB of L1 cache per SM, an increase of 50% over Ampere. That's a total of 2.5 MB of L1 cache on the top AD103 GPU. The L2 cache will be increased to 64 MB as mentioned in the leaks. This is a 10.6x increase over the Ampere GA102 GPU that hosts just 6 MB of L2 cache. The cache will be shared across the GPU.

Finally, we have the ROPs which are also increased to 32 per GPC, an increase of 2x over Ampere. You are looking at up to 112 ROPs. There are also going to be the latest 4th Generation Tensor and 3rd Generation RT (Raytracing) cores infused on the Ada Lovelace GPUs which will help boost DLSS & Raytracing performance to the next level. Overall, the Ada Lovelace AD103 GPU will offer (versus the GA103 GPU):

16.6% More GPCs (Versus Ampere)

40% More Cores (Versus Ampere)

50% More L1 Cache (Versus Ampere)

16x More L2 Cache (Versus Ampere)

16.6% More ROPs (Versus Ampere)

4th Gen Tensor & 3rd Gen RT Cores

NVIDIA AD103 'Ada Lovelace' Gaming GPU 'SM' Block Diagram:

NVIDIA GeForce RTX 4080

49 TFLOPS of peak single-precision (FP32) performance

98 TFLOPS of peak half-precision (FP16) performance

390 Tensor TFLOPS

780 Tensor TFLOPs with sparsity

113 RT-TFLOPs

At the heart of the NVIDIA GeForce RTX 4080 graphics card lies the Ada Lovelace AD103 GPU. The GPU measures 608,4mm2 and will utilize the TSMC 4N process node which is an optimized version of TSMC's 5nm (N5) node designed for the green team. The GPU features an insane 45.9 Billion transistors.

NVIDIA Ada GPUs - AD102, AD103, AD104 For The First Wave of Gaming Cards

NVIDIA is first introducing three brand new Ada GPUs which include the AD102, AD103 & AD104. The AD102 GPU is going to be featured on the GeForce RTX 4090, the AD103 is going to be used by the GeForce RTX 4080 16 GB graphics cards and the AD104 GPU is going to be featured on the GeForce RTX 4080 12 GB graphics cards.

The Ada GPUs are based on the TSMC 4N process node which is a custom process designed exclusively for NVIDIA. It is essentially an optimized version of the N5 (5nm) process, offering drastic increases in transistors, cores, and frequency. The top AD103 GPU packs 16% more cores and also offers 45.9 Billion transistors while offering over 2x the performance per watt.

NVIDIA Ada AD103 GPU

The full AD103 GPU is made up of 7 graphics processing clusters with 12 SM units on each cluster. That makes up 84 SM units for a total of 10752 cores, 76 RT cores, 304Tensor Cores, 320 Texture Units, and a 256-bit bus interface in a 45.9 billion transistor package measuring 378.6mm2.

NVIDIA GeForce RTX 40 Series Graphics Card Lineup (Rumored):

Graphics Card GPU PCB Variant SM Units / Cores Memory / Bus Memory Clock / Bandwidth TBP Power Connectors Launch NVIDIA Titan RTX ADA AD102-400? TBD 144 / 18176? 48 GB / 384-bit 24 Gbps / 1.15 TB/s ~800W 2x 16-pin TBD NVIDIA GeForce RTX 4090 Ti AD102-400? TBD 144 / 18176? 24 GB / 384-bit 24 Gbps / 1.15 TB/s ~600W 1x 16-pin TBD NVIDIA GeForce RTX 4090 AD102-300 PG136 128 / 16384 24 GB / 384-bit 21 Gbps / 1.00 TB/s 450W 1x 16-pin Q4 2022 NVIDIA GeForce RTX 4080 AD103-301/300 PG139 SKU 360 76 / 9728 16 GB / 256-bit 23 Gbps / 716.8 GB/s 320W 1x 16-pin Q4 2022 NVIDIA GeForce RTX 4070 Ti AD104-400 PG141 SKU 331 60 / 7680 12 GB / 192-bit 21 Gbps / 504.0 GB/s 285W 1x 16-pin Q1 2023 NVIDIA GeForce RTX 4070 AD104-251/250 PG141-SKU 345/344/343 46 / 5888 12 GB / 192-bit 21 Gbps / 504.0 GB/s 200W 1x 16-pin / 8-Pin Q2 2023 NVIDIA GeForce RTX 4060 Ti AD106-350 PG190 SKU 361 34 / 4352 8 GB / 128-bit 18 Gbps / 288.0 GB/s 160-150W 1x 16-pin / 8-Pin Q2 2023 NVIDIA GeForce RTX 4060 AD107-400 PG173 SKU 371 24 / 3072 8 GB / 128-bit 18 Gbps / 288.0 GB/s 115-110W 1x 16-pin / 8-Pin Q2 2023 NVIDIA GeForce RTX 4050 AD107? TBD TBD 6 GB / 96-bit? TBD 100W 1x 16-pin / 8-Pin Q3 2023?

NVIDIA GeForce RTX 4080 Graphics Cards Specifications

The NVIDIA GeForce RTX 4080 will use 76 SMs of the 84 SMs for a total of 9728 CUDA cores. The GPU will come packed with 64 MB of L2 cache and a total of 112 ROPs which is simply insane. The clock speeds for the graphics card are rated at 2210 MHz base and 2510 MHz boost clocks and we have already seen over 3 GHz speeds with overclocking which you can read more about here.

As for memory specs, the GeForce RTX 4080 features 16 GB GDDR6X capacities that will be adjusted at 22.5 Gbps speeds across a 256-bit bus interface. This will provide up to 720 GB/s of bandwidth. This is still a tad bit slower than the 760 GB/s bandwidth offered by the RTX 3080 since it comes with a 320-bit interface but a lowly 10 GB capacity. To compensate for the lower bandwidth, NVIDIA could be integrating a next-gen memory compression suite to make up for the 256-bit interface.

NVIDIA GeForce RTX 4080 16 GB ""Official"" TBP - 320W

320W NVIDIA GeForce RTX 3080 12 GB ""Official"" TBP - 350W

As far as the power consumption is concerned, the TBP is rated at 320W. The card will be powered by a single 16-pin connector which delivers up to 600W of power. Custom models will be offering higher TBP targets.

NVIDIA GeForce RTX 4080 Graphics Cards Performance

As for the performance of these monster GPUs, NVIDIA shared the computational and gaming performance figures and it looks like the GeForce RTX 4080 will be sitting slightly ahead of the GeForce RTX 3090 Ti with around 50 TFLOPs of Compute power.

Just for comparison's sake:

NVIDIA GeForce RTX 4090: 83 TFLOPs (FP32) (2.5 GHz Boost clock)

83 TFLOPs (FP32) (2.5 GHz Boost clock) NVIDIA GeForce RTX 4080: 49 TFLOPs (FP32) (2.5 GHz Boost clock)

49 TFLOPs (FP32) (2.5 GHz Boost clock) NVIDIA GeForce RTX 3090 Ti: 49 TFLOPs (FP32) (1.86 GHz Boost clock)

49 TFLOPs (FP32) (1.86 GHz Boost clock) NVIDIA GeForce RTX 3090: 36 TFLOPs (FP32) (1.69 GHz Boost clock)

Based on a boost clock speed of 2.5 GHz, you get up to 49TFLOPs of compute performance and you can definitely squeeze out a lot more with an overclock as we had demonstrated with the RTX 4090. One should remember that compute performance doesn't necessarily indicate the overall gaming performance. Even so, it will be a huge upgrade for gaming PCs and an 8.5x increase over the current fastest console, the Xbox Series X.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RTX 4090 83 RTX 4080 49 RTX 3090 Ti 40 RX 6900 XTX 25 Xbox Series X 12.1 PlayStation 5 10.2

This will be a 2x compute performance uplift and a 2x gain in gaming performance as NVIDIA has demonstrated for each graphics card versus its predecessor and this is without even factoring in the RT and Tensor core performance which are expected to get major lifts too in their respective department. A 2-4x gain over the RTX 3090 & RTX 3090 Ti would be very disruptive.

Gamers should expect 4K gaming to be buttery smooth on these graphics cards and with DLSS, we might even see playable 60 FPS at 8K resolution which is something that NVIDIA has been trying to achieve with its RTX 3090 series BFGPUs for a while now.

NVIDIA GeForce RTX 4080 Graphics Cards Price & Availability

The NVIDIA GeForce RTX 4080 16 GB graphics card will be available starting tomorrow for a price of $1199 US. The card will be available in both Founders Edition and custom graphics card flavors at launch.

2 of 9

NVIDIA GeForce RTX 40 Series Official Specs:

Graphics Card Name NVIDIA GeForce RTX 4090 NVIDIA GeForce RTX 4080 NVIDIA GeForce RTX 4070 Ti NVIDIA GeForce RTX 4070 NVIDIA GeForce RTX 4060 Ti NVIDIA GeForce RTX 4060 GPU Name Ada Lovelace AD102-300 Ada Lovelace AD103-300 Ada Lovelace AD104-400 Ada Lovelace AD104-250 Ada Lovelace AD106-350 Ada Lovelace AD107-400 Process Node TSMC 4N TSMC 4N TSMC 4N TSMC 4N TSMC 4N TSMC 4N Die Size 608mm2 378.6mm2 294.5mm2 294.5mm2 190.0mm2 146.0mm2 Transistors 76 Billion 45.9 Billion 35.8 Billion 35.8 Billion 22.9 Billion TBD CUDA Cores 16384 9728 7680 5888 4352 3072 TMUs / ROPs 512 / 176 320 / 112 240 / 80 184 / 64 136 / 48 TBD Tensor / RT Cores 512 / 128 304 / 76 240 / 60 184 / 46 136 / 34 TBD L2 Cache 72 MB 64 MB 48 MB 36 MB 32 MB 24 MB Base Clock 2230 MHz 2210 MHz 2310 MHz 1920 MHz 2310 MHz 1830 MHz Boost Clock 2520 MHz 2510 MHz 2610 MHz 2475 MHz 2535 MHz 2460 MHz FP32 Compute 83 TFLOPs 49 TFLOPs 40 TFLOPs 29 TFLOPs 22 TFLOPs 15 TFLOPs RT TFLOPs 191 TFLOPs 113 TFLOPs 82 TFLOPs 67 TFLOPs 51 TFLOPs 35 TFLOPs Tensor-TOPs 1321 TOPs 780 TOPs 641 TOPs 466 TOPs 353 TOPs 242 TOPs Memory Capacity 24 GB GDDR6X 16 GB GDDR6X 12 GB GDDR6X 12 GB GDDR6X 8-16 GB GDDR6 8 GB GDDR6 Memory Bus 384-bit 256-bit 192-bit 192-bit 128-bit 128-bit Memory Speed 21.0 Gbps 23.0 Gbps 21.0 Gbps 21.0 Gbps 18.0 Gbps 17.0 Gbps Bandwidth 1008 GB/s 736 GB/s 504 GB/s 504 GB/s 288 GB/s

(554 GB/s Effective) 272 GB/s

(453 GB/s Effective) TBP 450W 320W 285W 200W 160-165W 115W Price (MSRP / FE) $1599 US / 1949 EU $1199 US / 1469 EU $799 US $599 US $399-$499 US $299 US Price (Current) $1599 US / 1859 EU $1199 US / 1399 EU $799 US $599 US $399-$499 US $299 US Launch (Availability) 12th October 2022 16th November 2022 5th January 2023 13th April 2023 24th May / July 2023 29th June 2023","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/nvidia-geforce-rtx-4090/,"NVIDIA GeForce RTX 4090 Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info NVIDIA GeForce RTX 4090 2022 Manufacturer NVIDIA Type Graphics Card Platforms PC Expected Price $1599 US Expected Release Date 2022

NVIDIA GeForce RTX 4090 graphics card is going to be the next-gen flagship for the green team, ushering in performance levels never before seen in the PC gaming segment, and here's everything from specs, price, and performance that you need to know.

NVIDIA GeForce RTX 4090 - The Next-Generation BFGPU For The Ultimate Gamer

[Launched- 11/10/22]

The NVIDIA GeForce RTX 3090 series proved that the green team can go to extreme lengths to secure their lead in the PC graphics segment. Labeled as 'BFGPU', a new breed of enthusiast & ultimate graphics card, these provide the best performance possible with the best possible PC gaming features in a package that's next to none.

NVIDIA's direction with the BFGPU was to design a graphics card not just for the ultimate gamer but also for professional content creators too who also want to have the best graphics performance at hand to power the next generation of AAA gaming titles with superb visuals and insane fluidity. It's not just the FPS that matters these days, it's visuals, and a smoother frame rate too and this is exactly what the GeForce RTX 30 series is made to excel at.

We should expect similar things with the next-generation flagship too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new Ada Lovelace or AD10* class GPUs that will be powering the next-gen GeForce RTX 40 series cards.

You can also read the expected specs, prices, and performance of other upcoming RTX 40 GPUs in the posts below:

NVIDIA's AD102 'Ada Lovelace' GPU - The Next-Gen Powerhouse

The NVIDIA Ada Lovelace AD102 GPU features up to 12 GPC (Graphics Processing Clusters). These are 5 more SMs compared to the Ampere GA102 GPUs. Each GPU will consist of 6 TPCs and 2 SMs which is the same configuration as the existing chip. Each SM (Streaming Multiprocessor) will house four sub-cores which is also the same as the GA102 GPU. What's changed is the FP32 & the INT32 core configuration. Each sub-core will include 64 FP32 units but combined FP32+INT32 units will go up to 128. This is because half of the FP32 units don't share the same sub-core as the IN32 units. The 64 FP32 cores are separate from the 128 INT32 cores.

So in total, each sub-core will consist of 16 FP32 plus 16 INT32 units for a total of 32 units. Each SM will have a total of 64 FP32 units plus 64 INT32 units for a total of 128 units. And since there are a total of 144 SM units (12 per GPC), we are looking at a total of 18,432 cores. Each SM will also include two Wrap Schedules (32 thread/CLK) for 64 wraps per SM & their own L0 i-cache. This is a 33% increase in Wraps/Threads vs the GA102 GPU. The Register file size is 16,384 across a 32-bit lane. Each SM also carries its own 128 KB of L1 data cache and shared memory so that's 18 MB of L1 cache.

Moving over to the cache, this is another segment where NVIDIA has given a big boost over the existing Ampere GPUs. The L2 cache will be increased to 96 MB as mentioned in the leaks. This is a 16x increase over the Ampere GPU that hosts just 6 MB of L2 cache. The cache will be shared across the GPU. The GPU will also feature up to 192 ROPs for the full-die.

There are also going to be the latest 4th Generation Tensor and 3rd Generation RT (Raytracing) cores infused on the Ada Lovelace GPUs which will help boost DLSS & Raytracing performance to the next level. Overall, the Ada Lovelace AD102 GPU will offer:

71% More GPCs (Versus Ampere)

71% More Cores (Versus Ampere)

50% More L1 Cache (Versus Ampere)

16x More L2 Cache (Versus Ampere)

71% More ROPs (Versus Ampere)

4th Gen Tensor & 3rd Gen RT Cores

The full die has not been featured on any GPU so far, not even the L40 which has 2 SMs disabled. It is likely that as yields progress, we will eventually see a gaming and workstation product using the full-fat AD102. Till then, the RTX 4090 is the top gaming graphics card while the RTX 6000 Ada is the top workstation solution.

NVIDIA AD102 'Ada Lovelace' Gaming GPU Block Diagram:

NVIDIA AD102 'Ada Lovelace' Gaming GPU 'SM' Block Diagram:

NVIDIA GeForce RTX 4090

82.6 TFLOPS of peak single-precision (FP32) performance

165.2 TFLOPS of peak half-precision (FP16) performance

660.6 Tensor TFLOPS

1321.2 Tensor TFLOPs with sparsity

191 RT-TFLOPs

At the heart of the NVIDIA GeForce RTX 4090 graphics card lies the Ada Lovelace AD102 GPU. The GPU measures 608,4mm2 and will utilize the TSMC 4N process node which is an optimized version of TSMC's 5nm (N5) node designed for the green team. The GPU features an insane 76.3 Billion transistors.

NVIDIA Ampere ""GeForce RTX 30"" GPUs Full Breakdown:

Graphics Card NVIDIA GeForce RTX 2070 SUPER NVIDIA GeForce RTX 3070 NVIDIA GeForce RTX 2080 NVIDIA GeForce RTX 3080 NVIDIA Titan RTX NVIDIA GeForce RTX 3090 GPU Codename TU106 GA104 TU104 GA102 TU102 GA102 GPU Architecture NVIDIA Turing NVIDIA Ampere NVIDIA Turing NVIDIA Ampere NVIDIA Turing NVIDIA Ampere GPCs 5 or 6 6 6 6 6 7 TPCs 20 23 23 34 36 41 SMs 40 46 46 68 72 82 CUDA Cores / SM 64 128 64 128 64 128 CUDA Cores / GPU 2560 5888 2944 8704 4608 10496 Tensor Cores / SM 8 (2nd Gen) 4 (3rd Gen) 8 (2nd Gen) 4 (3rd Gen) 8 (2nd Gen) 4 (3rd Gen) Tensor Cores / GPU 320 (2nd Gen) 184 (3rd Gen) 368 272 (3rd Gen) 576 (2nd Gen) 328 (3rd Gen) RT Cores 40 (1st Gen) 46 (2nd Gen) 46 (1st Gen) 68 (2nd Gen) 72 (1st Gen) 82 (2nd Gen) GPU Boost Clock (MHz) 1770 1725 1800 1710 1770 1695 Peak FP32 TFLOPS (non-Tensor) 9.1 20.3 10.6 29.8 16.3 35.6 Peak FP16 TFLOPS (non-Tensor) 18.1 20.3 21.2 29.8 32.6 35.6 Peak BF16 TFLOPS (non-Tensor) NA 20.3 NA 29.8 NA 35.6 Peak INT32 TOPS (non-Tensor) 9.1 10.2 10.6 14.9 16.3 17.8 Peak FP16 Tensor TFLOPS

with FP16 Accumulate 72.5 81.3/162.6 84.8 119/238 130.5 142/284 Peak FP16 Tensor TFLOPS

with FP32 Accumulate 36.3 40.6/81.3 42.4 59.5/119 65.2 71/142 Peak BF16 Tensor TFLOPS

with FP32 Accumulate NA 40.6/81.3 NA 59.5/119 NA 71/142 Peak TF32 Tensor TFLOPS NA 20.3/40.6 NA 29.8/59.5 NA 35.6/71 Peak INT8 Tensor TOPS 145 162.6/325.2 169.6 238/476 261 284/568 Peak INT4 Tensor TOPS 290 325.2/650.4 339.1 476/952 522 568/1136 Frame Buffer Memory Size and

Type 8 GB GDDR6 8 GB GDDR6 8 GB GDDR6 10 GB GDDR6X 24 GB GDDR6 24 GB GDDR6X Memory Interface 256-bit 256-bit 256-bit 320-bit 384-bit 384-bit Memory Clock (Data Rate) 14 Gbps 14 Gbps 14 Gbps 19 Gbps 14 Gbps 19.5 Gbps Memory Bandwidth 448 GB/sec 448 GB/sec 448 GB/sec 760 GB/sec 672 GB/sec 936 GB/sec ROPs 64 96 64 96 96 112 Pixel Fill-rate (Gigapixels/sec) 113.3 165.6 115.2 164.2 169.9 193 Texture Units 160 184 184 272 288 328 Texel Fill-rate (Gigatexels/sec) 283.2 317.4 331.2 465 509.8 566 L1 Data Cache/Shared Memory 3840 5888 4416 KB 8704 KB 6912 KB 10496 KB L2 Cache Size 4096 KB 4096 KB 4096 KB 5120 KB 6144 KB 6144 KB Register File Size 10240 KB 11776 KB 11776 KB 17408 KB 18432 KB 20992 KB TGP (Total Graphics Power) 215 Watts 220W 225W 320W 280W 350W Transistor Count 13.6 Billion 17.4 Billion 13.6 Billion 28.3 Billion 18.6 Billion 28.3 Billion Die Size 545 mm2 392.5 mm2 545 mm2 628.4 mm2 754mm2 628.4 mm2 Manufacturing Process TSMC 12 nm FFN

(FinFET NVIDIA) Samsung 8 nm 8N NVIDIA

Custom Process TSMC 12 nm FFN

(FinFET NVIDIA) Samsung 8 nm 8N NVIDIA

Custom Process TSMC 12 nm FFN

(FinFET NVIDIA) Samsung 8 nm 8N NVIDIA

Custom Process

NVIDIA Ada GPUs - AD102, AD103, AD104 For The First Wave of Gaming Cards

NVIDIA is first introducing three brand new Ada GPUs which include the AD102, AD103 & AD104. The AD102 GPU is going to be featured on the GeForce RTX 4090, the AD103 is going to be used by the GeForce RTX 4080 16 GB graphics cards and the AD104 GPU is going to be featured on the GeForce RTX 4080 12 GB graphics cards.

The Ada GPUs are based on the TSMC 4N process node which is a custom process designed exclusively for NVIDIA. It is essentially an optimized version of the N5 (5nm) process, offering drastic increases in transistors, cores, and frequency. The top AD102 GPU packs 70% more cores and also offers 76.3 Billion transistors while offering over 2x the performance per watt.

NVIDIA Ada AD102 GPU

The full AD102 GPU is made up of 12 graphics processing clusters with 12 SM units on each cluster. That makes up 144 SM units for a total of 18432 cores, 144 RT cores, 576 Tensor Cores, 576 Texture Units, and a 384-bit bus interface in a 76.3 billion transistor package measuring 608,5mm2.

NVIDIA GeForce RTX 4090 Graphics Cards Specifications

The NVIDIA GeForce RTX 4090 will use 128 SMs of the 144 SMs for a total of 16,384 CUDA cores. The GPU will come packed with 96 MB of L2 cache and a total of 384 ROPs which is simply insane but considering that the RTX 4090 is a cut-down design, it may feature slightly lower L2 and ROP counts. The clock speeds are not confirmed yet but considering that the TSMC 4N process is being used. The clock speeds are rated at up to 2.6 GHz and NVIDIA is claiming over 3 GHz speeds with overclocking which you can read more about here.

As for memory specs, the GeForce RTX 4090 will feature 24 GB GDDR6X capacities that will be clocked at 21 Gbps speeds across a 384-bit bus interface. This will provide up to 1 TB/s of bandwidth. This is the same bandwidth as the existing RTX 3090 Ti graphics card and as far as the power consumption is concerned, the TBP is rated at 450W. The card will be powered by a single 16-pin connector which delivers up to 600W of power. Custom models will be offering higher TBP targets.

NVIDIA Founders Edition Designed To Utilize Up To 600W of Power For Higher Overclocking

As for its brand new Founders Edition cards, the GeForce RTX 4090 24 GB and RTX 4080 16 GB, NVIDIA has produced a compact PCB similar to the ones we saw on the previous generation & designing a PCB like this helps improve airflow and cooling performance.

NVIDIA says that they have further optimized the Dual Axial Flow Through system, increasing fan sizes and fin volume by 10%, offering 20% higher air flow and upgrading to a 23-phase power supply (20+3 Phase for RTX 4090). Memory temperatures are reduced, and the new, substantially more powerful Ada GPUs are kept cool in ventilated cases, giving gamers excellent overclocking headroom. NVIDIA went through a rigorous testing procedure and is said to have evaluated as many as 50 fan designs before finalizing the one we are getting on the new cards. The cooler is used to dissipate heat from the heatsink assembly that comprises a vapor chamber, a big jump from the previous design too.

The NVIDIA GeForce RTX 4080 also uses the same cooler as the RTX 4090 Founders Edition and since it has a lower TDP, it should deliver even better thermal performance.

2 of 9

Each GeForce RTX 40 Series Founders Edition graphics card reduces cable clutter by leveraging the new standard GPU power input of next-gen ATX 3.0 power supplies, the PCIe Gen-5 16-pin Connector. This enables you to power GeForce RTX 40 Series graphics cards with just a single cable, improving the aesthetics of your build. If you are using a previous-gen power supply, an adapter cable is included in the box, allowing you to plug in three 8-pin power connectors, with an optional fourth connector for more overclocking headroom. ATX 3.0 power supplies will be available in October from ASUS, Cooler Master, FSP, Gigabyte, iBuyPower, MSI, and ThermalTake, with more models to come.

One advantage of the new 16-pin connector is that while the Founders Edition cards are designed at 450W & 320W, respectively, they can utilize the extra headroom provided through the new connector for extreme overclocking with the RTX 4090 going for that full 600W mark. The new power delivery also gives the RTX 40 series a 10x increase in response time to power transient management compared to the previous generation.

The new cards also feature DP 1.4a (4K 12-bit HDR @ 240Hz) and HDMI 2.1 (4K 120Hz HDR / 8K 60Hz HDR). All cards are compliant with the PCIe Gen 4 interface on existing motherboards and also feature full compliance with the Resizable-BAR technologies.

NVIDIA GeForce RTX 4090 Founders Edition PCB:

Next-Gen Micron GDDR6X Dies Run 10C Cooler Thanks To New Process Node

NVIDIA has also leveraged Micron's latest GDDR6X memory chips for its GeForce RTX 40 graphics cards which run 10C cooler, are more power efficient and since they are all 16Gb DRAM dies, they can be fused on one side of the PCB to be cooled better than dual-sided memory.

NVIDIA GeForce RTX 4090 Graphics Cards Performance

The NVIDIA GeForce RTX 4090 is the first gaming card to hit the 100 TFLOPs compute horsepower limit.

So we decided it was time to test how far we can push the NVIDIA GeForce RTX 4090 Founders Edition with some overclocking. To get to 100 TFLOPs, we first pushed the power limit and temp limit slider all the way to the max and upped the Core and Memory clocks by +275 and +1100 MHz, respectively. This wasn't enough as the card was being limited by its power design. That is when we landed our hands on MSI's latest Afterburner which allowed us to raise the core voltages. At 100%, we saw some performance regression so we had to stick with +55% which showed us some good results.

With the overclock applied on our NVIDIA GeForce RTX 4090 graphics card, we saw a maximum GPU core clock of 3150 MHz on the AD102 Ada GPU, a maximum power draw of 547W and our temps peaked at 69C. All of this was done on air and with no exotic liquid cooling, chillers or LN2 were used.

And behold, we saw the magical number of not 100 but almost 101 TFLOPs right in front of our eyes. To put things into perspective, this is a 22% compute boost over the stock RTX 4090 and a 2.5x compute performance boost over the RTX 3090 Ti. The AD102 GPU also ripped apart the data-center-focused Hopper H100 GPUs by offering over 50% better FP32 performance. Ada Lovelace is truly a game changer and we can definitely see it become a popular compute and AI graphics card when Quadro variants of the said chip launch as the RTX 6000 ADA and L60.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 40 80 120 160 200 240 0 40 80 120 160 200 240 RTX 4090 OC 101 RTX 4090 Stock 83 RTX 3090 Ti 40 RX 6900 XTX 25 Xbox Series X 12.1 PlayStation 5 10.2

This will be a 2x compute performance uplift for each graphics card versus its predecessor and this is without even factoring in the RT and Tensor core performance which are expected to get major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison. A 2-2.5x gain over the RTX 3090 & RTX 3090 Ti would be very disruptive and it makes sense why NVIDIA is going so hard with higher power limits on their cards.

Gamers should expect 4K gaming to be buttery smooth on these graphics cards and with DLSS, we might even see playable 60 FPS at 8K resolution which is something that NVIDIA has been trying to achieve with its RTX 3090 series BFGPUs for a while now.

NVIDIA GeForce RTX 4090 Graphics Cards Price & Availability

Now coming to the prices, the NVIDIA GeForce RTX 3090 Ti & RTX 3090 graphics cards are undoubtedly the most expensive single-chip GPUs to date. The NVIDIA GeForce RTX 4090 will come at a price of $1599 US for the Founders Edition variant and will be available on the 12th of October.

2 of 9

NVIDIA GeForce RTX 40 Series Official Specs:

Graphics Card Name NVIDIA GeForce RTX 4090 NVIDIA GeForce RTX 4080 NVIDIA GeForce RTX 4070 Ti NVIDIA GeForce RTX 4070 NVIDIA GeForce RTX 4060 Ti NVIDIA GeForce RTX 4060 GPU Name Ada Lovelace AD102-300 Ada Lovelace AD103-300 Ada Lovelace AD104-400 Ada Lovelace AD104-250 Ada Lovelace AD106-350 Ada Lovelace AD107-400 Process Node TSMC 4N TSMC 4N TSMC 4N TSMC 4N TSMC 4N TSMC 4N Die Size 608mm2 378.6mm2 294.5mm2 294.5mm2 190.0mm2 146.0mm2 Transistors 76 Billion 45.9 Billion 35.8 Billion 35.8 Billion 22.9 Billion TBD CUDA Cores 16384 9728 7680 5888 4352 3072 TMUs / ROPs 512 / 176 320 / 112 240 / 80 184 / 64 136 / 48 TBD Tensor / RT Cores 512 / 128 304 / 76 240 / 60 184 / 46 136 / 34 TBD L2 Cache 72 MB 64 MB 48 MB 36 MB 32 MB 24 MB Base Clock 2230 MHz 2210 MHz 2310 MHz 1920 MHz 2310 MHz 1830 MHz Boost Clock 2520 MHz 2510 MHz 2610 MHz 2475 MHz 2535 MHz 2460 MHz FP32 Compute 83 TFLOPs 49 TFLOPs 40 TFLOPs 29 TFLOPs 22 TFLOPs 15 TFLOPs RT TFLOPs 191 TFLOPs 113 TFLOPs 82 TFLOPs 67 TFLOPs 51 TFLOPs 35 TFLOPs Tensor-TOPs 1321 TOPs 780 TOPs 641 TOPs 466 TOPs 353 TOPs 242 TOPs Memory Capacity 24 GB GDDR6X 16 GB GDDR6X 12 GB GDDR6X 12 GB GDDR6X 8-16 GB GDDR6 8 GB GDDR6 Memory Bus 384-bit 256-bit 192-bit 192-bit 128-bit 128-bit Memory Speed 21.0 Gbps 23.0 Gbps 21.0 Gbps 21.0 Gbps 18.0 Gbps 17.0 Gbps Bandwidth 1008 GB/s 736 GB/s 504 GB/s 504 GB/s 288 GB/s

(554 GB/s Effective) 272 GB/s

(453 GB/s Effective) TBP 450W 320W 285W 200W 160-165W 115W Price (MSRP / FE) $1599 US / 1949 EU $1199 US / 1469 EU $799 US $599 US $399-$499 US $299 US Price (Current) $1599 US / 1859 EU $1199 US / 1399 EU $799 US $599 US $399-$499 US $299 US Launch (Availability) 12th October 2022 16th November 2022 5th January 2023 13th April 2023 24th May / July 2023 29th June 2023","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/intel-13th-gen-raptor-lake-cpus/,"Intel 13th Gen Raptor Lake Desktop CPUs Specs, Performance, Price, & Availability – Everything We Know So Far","Product Info Intel 13th Gen Raptor Lake CPUs 2H 2022 Manufacturer Intel Type CPUs Platforms Desktop PC Expected Price TBA Expected Release Date 2H 2022

Intel introduced its very first hybrid architecture client CPU platform, codenamed Alder Lake, late last year. The new platform brought with it much-needed improvements to performance and x86 efficiency, especially in the multi-threaded segment. The Alder Lake lineup is currently shipping in all segments on desktop and mobile platforms but the 12th Gen family will soon be succeeded by its 13th Gen successor known as Raptor Lake.

Intel 13th Gen Raptor Lake Desktop CPUs - Refining Alder Lake With More Cores, More Hybrid Goodness!

[Launched - 20/10/22]

On paper, Intel's 13th Gen Raptor Lake CPUs look to be an optimized version of the 12th Gen Alder Lake CPUs. They will be based on the same 10nm ESF 'Intel 7' process node, utilize the same P-Core & E-Core design, & will be supported on existing motherboards. But there's a lot that's changing with Raptor Lake and we are going to detail everything, from official details to rumored information that we know about Alder Lake so far and what you could expect from Intel's next desktop lineup which will be pitted right against AMD's next Ryzen CPU lineup for desktops too.

Like Alder Lake, Raptor Lake would utilize a completely hybrid architectural design. (Image Credits: Intel)

Intel 13th Gen Raptor Lake Desktop CPUs Features:

Up To 24 Cores & 32 Threads

Brand New Raptor Cove CPU Cores (Higher P-Core IPC)

Based on 10nm ESF 'Intel 7' process node

Up To 6.0 GHz clock speeds (expected)

Double The E-Cores on certain variants

Increased Cache for both P-Cores & E-Cores

Supported on existing LGA 1700 motherboards

New Z790, H770, and B760 motherboards

Up To 28 PCIe Lanes (PCH Gen 4 + Gen 3)

Up To 28 PCIe Lanes (CPU Gen 5 x16 + Gen 4 x12)

Dual-Channel DDR5-5600 Memory Support

20 PCIe Gen 5 Lanes

Enhanced Overclocking Features

125W PL1 TDP (Flagship SKUs)

AI PCIe M.2 Technology

Q4 2022 Launch

Intel 13th Gen 'Raptor Lake' CPUs Specifications

So starting with the specifications, Intel's 13th Gen Raptor Lake CPUs will utilize the hybrid core design, featuring a mix of Performance-Optimized 'P' and Efficiency-Optimized 'E' cores. For the new chips, Intel will be using a brand new P-Core known as Raptor Cove which will replace the Golden Cove cores featured on the Alder Lake CPUs. For The E-Core, Intel will retain the existing Gracemont core architecture but it will come with minor improvements.

The architecture has seen several optimizations and key refinements that have led to an increase from 16 cores and 24 threads to 24 cores and 32 threads. The new 10nm ESF (Intel 7) process retains Intel's clock leadership, pushing the chips up to 5.8 GHz (up to 6 GHz on the KS variant).

Intel’s Raptor Lake will be built using the company’s new E and P cores, you can read the architectural deep dive over here, and represent a significant evolution in the company’s power efficiency targets. It will be built on the Intel 7 process and scale from 9 watts to 125 watts. DDR5 and PCIe gen5 will be supported (first to market) and feature new technologies like the Intel Thread Director.

Raptor Lake will be fully scalable from Desktop (LGA1700) to ultra-mobile. Interestingly, however, while the platform has 8 P-cores and 16 E-cores, only the P-cores will support hyperthreading making for a total of 32 threads available. The integrated GPU will have 96 EUs of Xe architecture (good but nothing to write home about) but the thing that impressed us the most was the fact that Intel is claiming a 20% IPC uplift over Rocketlake.

Raptor Lake will feature up to 35 MB of noninclusive LL Cache and support DDR5-5200, LP5-5600 DDR4-3200, and LP4x-4266. It will also support two times the PCIe bandwidth thanks to its support of PCIe 5 and will be able to provide up to 16 lanes of PCIe Gen5 with up to 64 GB/s. The new design is fully modular and built like lego and should be completely scalable and flexible. The compute fabric interconnect has a bandwidth of 1000 GB/s while the IO fabric has a BW of 64 GB/s. The memory subsystem supports up to 204 GB/s but more importantly can scale memory frequency (and power) according to the need of the SoC.

Intel Core i9-13900K 24 Core Raptor Lake CPU Specs

The Intel Core i9-13900K is the flagship Raptor Lake CPU, featuring 24 cores and 32 threads in an 8 P-Core and 16 E-Core configuration. The CPU is configured at a base clock of 3.0 GHz, a single-core boost clock of 5.8 GHz (1-2) cores, and an all-core boost clock of 5.5 GHz (all 8 P-Cores). The CPU features 68 MB of combined cache and a 125W PL1 rating that goes up to 253W. The CPU can also consume up to 350W of power when using the ""Unlimited Power Mode"" which we detailed here.

Core i9-13900K 8+16 (24/32) - 3.0 / 5.8 GHz - 66 MB Cache, 125W (PL1) / 253W (PL2)

3.0 / 5.8 GHz - 66 MB Cache, 125W (PL1) / 253W (PL2) Core i9-12900K 8+8 (16/24) - 3.2 / 5.2 GHz - 30 MB Cache, 125W (PL1) / 241W (PL2)

2 of 9

Intel Core i7-13700K 16 Core Raptor Lake CPU Specs

The Intel Core i7-13700K CPU will be the fastest 13th-Gen Core i7 chip on offer within the Raptor Lake CPU lineup. The chip features a total of 16 cores and 24 threads. This configuration is made possible with 8 P-Cores based on the Raptor Cove architecture and 8 E-Cores based on the Grace Mont core architecture. The CPU comes with 30 MB of L3 cache and 24 MB of L2 cache for a total combined 54 MB cache. The chip was running at a base clock of 3.4 GHz and a boost clock of 5.40 GHz. The all-core boost is rated at 5.3 GHz for the P-Cores while the E-Cores feature a base clock of 3.4 GHz and a boost clock of 4.3 GHz.

Core i7-13700K 8+8 (16/24) - 3.4 / 5.3 GHz - 54 MB Cache, 125W (PL1) / 253W (PL2)

- 3.4 / 5.3 GHz - 54 MB Cache, 125W (PL1) / 253W (PL2) Core i7-12700K 8+4 (12/20) - 3.6 / 5.0 GHz, 25 MB Cache, 125W (PL1) / 190W (PL2)

2 of 9

Intel Core i5-13600K 14 Core Raptor Lake CPU Specs

The Intel Core i5-13600K features a total of 14 cores which include 6 P-Cores based on the Raptor Cove and 8 E-Cores based on current Gracemont cores. That's the same P-Core count as the Intel Core i5-12600K but the E-Core count has been doubled. So we are looking at a 40% core count bump and a 25% thread count bump vs the Alder Lake Core i5-12600K. The CPU comes with 24 MB of L3 and 20 MB of L2 cache for a combined total of 44 MB cache. Clock speeds are set at 3.5 GHz base, 5.2 GHz boost, and 5.1 GHz all-core boost while the E-Cores operate at 3.5 GHz base & 3.9 GHz boost clocks.

Core i5-13600K 6+8 (14/20) - 3.5 / 5.1 GHz - 44 MB Cache, 125W (PL1) /181W (PL2)

- 3.5 / 5.1 GHz - 44 MB Cache, 125W (PL1) /181W (PL2) Core i5-12600K 6+4 (10/16) - 3.6 / 4.9 GHz - 20 MB Cache, 125W (PL1) / 150W (PL2)

2 of 9

Intel 13th Gen Raptor Lake-S Desktop CPU Family:

CPU Name P-Core Count E-Core Count Total Core / Thread P-Core Base / Boost (Max) Cache (Total L2 + L3) TDP MSRP Predecessor MSRP (at Launch) Intel Core i9-13900KS 8 16 24 / 32 3.2 / 6.0 GHz 68 MB 125W (PL1)

253W (PL2) TBD $739 US Intel Core i9-13900K 8 16 24 / 32 3.0 / 5.8 GHz 68 MB 125W (PL1)

253W (PL2) $589.99 US $589 US Intel Core i9-13900KF 8 16 24 / 32 3.0 / 5.8 GHz 68 MB 125W (PL1)

253W (PL2) $564.99 US $564 US Intel Core i9-13900 8 16 24 / 32 2.0 / 5.6 GHz 68 MB 65W (PL1)

219W (PL2) $549.99 US $489 US Intel Core i9-13900T 8 16 24 / 32 1.1 / 5.3 GHz 68 MB 35W (PL1)

106W (PL2) $549.99 US $489 US Intel Core i9-13900F 8 16 24 / 32 2.0 / 5.6 GHz 68 MB 65W (PL1)

219W (PL2) $524.99 US $464 US Intel Core i7-13700K 8 8 16 / 24 3.4 / 5.4 GHz 54 MB 125W (PL1)

253W (PL2) $409.99 US $409 US Intel Core i7-13700KF 8 8 16 / 24 3.4 / 5.4 GHz 54 MB 125W (PL1)

253W (PL2) $384.99 US $384 US Intel Core i7-13790F 8 8 16 / 24 TBA / 5.2 GHz 57 MB 65W (PL1)

219W (PL2) TBD N/A Intel Core i7-13700 8 8 16 / 24 2.1 / 5.2 GHz 54 MB 65W (PL1)

219W (PL2) $384.99 US $339 US Intel Core i7-13700T 8 8 16 / 24 1.4 / 4.9 GHz 54 MB 35W (PL1)

106W (PL2) $384.99 US $339 US Intel Core i7-13700F 8 8 16 / 24 2.1 / 5.2 GHz 54 MB 65W (PL1)

219W (PL2) $359.99 US $314 US Intel Core i5-13600K 6 8 14 / 20 3.5 / 5.2 GHz 35.5 MB 125W (PL1)

181W (PL2) $319.99 US $289 US Intel Core i5-13600KF 6 8 14 / 20 3.5 / 5.2 GHz 35.5 MB 125W (PL1)

181W (PL2) $294.99 US $264 US Intel Core i5-13600 6 8 14 / 20 2.7 / 5.0 GHz 35.5 MB 65W (PL1)

154W (PL2) $255.99 US $223 US Intel Core i5-13600T 6 8 14 / 20 1.8 / 4.8 GHz 35.5 MB 35W (PL1)

92W (PL2) $255.99 US $223 US Intel Core i5-13500 6 8 14 / 20 2.5 / 4.8 GHz 35.5 MB 65W (PL1)

154W (PL2) $232.99 US $202 US Intel Core i5-13500T 6 8 14 / 20 1.6 / 4.6 GHz 35.5 MB 35W (PL1)

92W (PL2) $232.99 US $202 US Intel Core i5-13490F 6 4 10 / 16 TBA / 4.8 GHz 35.5 MB 65W (PL1)

148W (PL2) TBD $250 US Intel Core i5-13400 6 4 10 / 16 2.5 / 4.6 GHz 29.5 MB 65W (PL1)

148W (PL2) $221.99 US $192 US Intel Core i5-13400T 6 4 10 / 16 1.3 / 4.4 GHz 29.5 MB 35W (PL1)

89W (PL2) $221.99 US $192 US Intel Core i5-13400F 6 4 10 / 16 2.5 / 4.6 GHz 29.5 MB 65W (PL1)

148W (PL2) $196.99 US $167 US Intel Core i3-13100 4 0 4 / 8 3.4 / 4.5 GHz 17 MB 60W (PL1)

89W (PL2) $134.99 US $122 US Intel Core i3-13100T 4 0 4 / 8 2.5 / 4.2 GHz 17 MB 35W (PL1)

69W (PL2) $134.99 US $122 US Intel Core i3-13100F 4 0 4 / 8 3.4 / 4.5 GHz 17 MB 60W (PL1)

89W (PL2) $109.99 US $97 US

Intel 13th Gen 'Raptor Lake' CPUs Performance

Intel hasn't shared any detailed performance numbers of the 13th Gen Raptor Lake CPU family yet but based on what we know, we can expect around a 10-15% uplift in gaming performance and 15-25% gains in multi-threading performance. These are just estimates and the final CPU performance could be much better. Intel's main aim with Raptor Lake is to tackle the 3D V-Cache and the Zen 4 CPUs. AMD has already touted its Ryzen 7 5800X3D as the best gaming processor right now so we can expect Zen 4 and its 3D variants to take that lead further up. The Ryzen 5 7600X is said to beat the Core i9-12900K in gaming at just $299 US.

2 of 9

A demo showcasing the benefits of the extra cores was shown by Intel during Investors Day '22 which revealed how the E-Cores can offload the work in Blender and leave the 16 P-Core threads available for other tasks. The Raptor Lake chip used within the demo is an ES part running at lower clock speeds and at a base TDP of 125W and was able to outperform the Core i9-12900K (though we don't know if the Alder Lake chip was also running at base TDP of its max TDP). Nevertheless, it looks like those extra cores are going to deliver some nice uplift in performance overall. The recent rumors have highlighted clock speeds as high as 5.8 GHz for the top parts which will be insane to see on the desktop PC platform.

Intel Raptor Lake CPU ST Benchmark (Geekbench 5) Single-Core 0 500 1000 1500 2000 2500 3000 0 500 1000 1500 2000 2500 3000 Core i9-13900K 2.3k Core i9-13900 2.1k Core i7-13700K 2.1k Core i5-13600K 2k Core i9-12900K 1.9k Core i7-12700K 1.9k Core i5-12600K 1.9k Ryzen 9 5950X 1.7k Ryzen 7 5800X 1.7k Ryzen 9 5900X 1.7k Ryzen 5 5600X 1.6k

Intel Raptor Lake CPU MT Benchmark (Geekbench 5) Multi-Core 0 5000 10000 15000 20000 25000 30000 0 5000 10000 15000 20000 25000 30000 Core i9-13900K 26.5k Core i9-13900 20.1k Core i7-13700K 19.8k Core i9-12900K 17.3k Ryzen 9 5950X 16.5k Core i5-13600K 16.1k Core i7-12700K 14.1k Ryzen 9 5900X 14k Core i5-12600K 11.6k Ryzen 7 5800X 10.3k Ryzen 5 5600X 8.2k

Over the course, several benchmarks of Intel's Core i9-13900K and Core i9-13900 have leaked out, showing promising performance that's well ahead against AMD Ryzen 5000 and Intel 12th Gen CPU lineup in multi-threaded and delivers a good beating in single-threaded workloads too. The final performance is looking to be highly competitive when compared to existing parts and also shows good competition versus AMD's upcoming Ryzen 7000 Desktop CPUs.

Intel 13th Gen 'Raptor Lake' CPUs LGA 1700 Platform

Intel is sticking with its LGA 1700 platform for at least one more CPU lineup and that's Raptor Lake. Chipzilla confirmed that Raptor Lake CPUs will be compatible with the existing LGA 1700 motherboards based on the 600-series chipset. But like each generation, motherboard makers will be offering a brand new lineup of motherboards based on the 700-series chipset which will come with higher I/O lanes. In addition to that, Raptor Lake chips will be supporting DDR5-5600 speeds which is a nice bump over the native DDR5-5200 speeds that Alder Lake supports.

This offers a nice upgrade path to users who are currently running a mainstream Core i3 or Core i5 CPU and want to upgrade to a higher-end chip. They can simply replace their existing 12th Gen CPU with a higher-end Core i7 or Core i9 SKU which will increase the overall performance of their PC.

Intel PCH SKUs and revision datasheet. (Image Credits: Intel)

Intel Desktop Platform Chipset Comparison

Chipset Name Meteor Lake-S (MTL-S) PCH / 800 Series (Z890) Raptor Lake-S (RPL-S) PCH / 700 Series (Z790) Alder Lake-S (ADL-S) PCH / 600 Series (Z690) Rocket Lake-S (RKL-S) PCH / 500 Series (Z590) Comet Lake-S (CML-S) PCH / 400 Series (Z490) Coffee Lake S (CNL-H) PCH / 300 Series (Z390/H370, B360, Q370, H310) Coffee Lake S (KBL-R) PCH / Z370 Platform Process Node TBD 14nm 14nm 14nm 14nm 14nm 22nm Processor 22, 14 (TBD) 24,16C,12C,10C,6C,4C (TBD) 16C,12C,10C,6C,4C (Full corporate/consumer SKU stack at launch) 8C, 6C (Full corporate/consumer SKU stack at launch) 10C, 8C, 6C, 4C, 2C (Full corporate/consumer SKU stack at launch) 8C, 6C, 4C, 2C (Full corporate/consumer SKU stack at launch) 8C, 6C, 4C (6 Consumer SKUs at Launch) Memory Up To DDR5-5600+(Native) Up To DDR5-5600 (Native)

Up To DDR4-3200 (Native)? Up To DDR5-4800 (Native)

Up To DDR4-3200 (Native) Up To DDR4-3200 (Native) Up To DDR4-2933 (Native) Up To DDR4-2666 (Native) Up To DDR4-2666 (Native) Media, Display & Audio eDP / 4DDI (DP, HDMI) Display Capabilities eDP / 4DDI (DP, HDMI) Display Capabilities eDP / 4DDI (DP, HDMI) Display Capabilities DP 1.2 & HDMI 2.0, HBR3

HDCP 2.2 (HDMI 2.0a w/LSPCON)

12-bit AV1/HEVC & VP9 10-bit Enc/Dec, HDR, Rec.2020, DX12

Integrated Dual-Core Audio DSP With USB Audio offload

SoundWire Digital Audio Interface DP 1.2 & HDMI 1.4

HDCP 2.2 (HDMI 2.0a w/LSPCON)

HEVC & VP9 10-bit Enc/Dec, HDR, Rec.2020, DX12

Integrated Dual-Core Audio DSP

SoundWire Digital Audio Interface DP 1.2 & HDMI 1.4

HDCP 2.2 (HDMI 2.0a w/LSPCON)

HEVC & VP9 10-bit Enc/Dec, HDR, Rec.2020, DX12

Integrated Dual-Core Audio DSP

SoundWire Digital Audio Interface DP 1.2 & HDMI 1.4

HDCP 2.2 (HDMI 2.0a w/LSPCON)

HEVC & VP9 10-bit Enc/Dec, HDR, Rec.2020, DX12

Integrated Dual-Core Audio DSP I/O & Connectivity TBD Integrated USB 3.2 Gen 2x2 (20G)

Integrated Intel Wireless-AC (Wi-Fi6E/ 7 BT CNVio) with Gig+

Integrated SDXC 4.0 Controller

Thunderbolt 4.0 Integrated USB 3.2 Gen 2x2 (20G)

Integrated Intel Wireless-AC (Wi-Fi6E/ 7 BT CNVio) with Gig+

Integrated SDXC 4.0 Controller

Thunderbolt 4.0 Integrated USB 3.2 Gen 2x2 (20G)

Integrated Intel Wireless-AC (Wi-Fi6E/ BT CNVi)

Integrated SDXC 3.0 Controller

Thunderbolt 4.0 (Maple Ridge) Integrated USB 3.2 Gen 2

Integrated Intel Wireless-AC (Wi-Fi / BT CNVi)

Integrated SDXC 3.0 Controller

Thunderbolt 3.0 (Titan Ridge) w/ DP 1.4 Integrated USB 3.1 Gen 1 (5 Gbps)

Integrated Intel Wireless-AC (Wi-Fi / BT CNVi)

Integrated SDXC 3.0 Controller

Thunderbolt 3.0 (Titan Ridge) w/ DP 1.4 Integrated USB 3.1 Gen 1 (5 Gbps)

Thunderbolt 3.0 (Alpine Ridge) Storage PCIe 5.0 (CPU Lanes), 6x SATA 3.0 Next-Gen Intel Optane memory

PCIe 5.0 (CPU Lanes), 6x SATA 3.0 Next-Gen Intel Optane memory

PCIe 5.0, 6x SATA 3.0 Next-Gen Intel Optane memory

PCIe 4.0, 6x SATA 3.0 Next-Gen Intel Optane memory

PCIe 3.0, 6x SATA 3.0 Next Gen Intel Optane memory

PCIe 3.0, 6x SATA 3.0 Next Gen Intel Optane memory

PCIe 3.0, 6x SATA 3.0 Max PCH PCIe Lanes Up To 24 (Gen 4)

TBD (Gen 3) Up To 20 (Gen 4)

Up To 8 (Gen 3) Up To 12 (Gen 4)

Up To 16 (Gen 3) Up To 24 (Gen 3) Up To 24 (Gen 3) Up To 24 (Gen 3) Up To 24 (Gen 3) Max CPU PCIe Lanes Up To 20 (Gen 5)

Up To 4 (Gen 4) Up To 16 (Gen 5)

Up To 4 (Gen 4) Up To 16 (Gen 5)

Up To 4 (Gen 4) Up To 20 (Gen 4) Up To 16 (Gen 3) Up To 16 (Gen 3) Up To 16 (Gen 3) Max USB Ports TBD Up To 5 (USB 3.2 Gen 2x2)

Up To 10 (USB 3.2 Gen 2x1)

Up To 10 (USB 3.2 Gen 1x1)

Up To 14 (USB 2.0) Up To 4 (USB 3.2 Gen 2x2)

Up To 10 (USB 3.2 Gen 2x1)

Up To 10 (USB 3.2 Gen 1x1)

Up To 14 (USB 2.0) Up To 3 (USB 3.2 Gen 2x2)

Up To 10 (USB 3.2 Gen 2x1)

Up To 10 (USB 3.2 Gen 1x1)

Up To 14 (USB 2.0) Up To 10 (USB 3.2)

Up To 14 (USB 2.0) Up To 10 (USB 3.1)

Up To 14 (USB 2.0) Up To 10 (USB 3.0)

Up To 14 (USB 2.0) Security TBD N/A N/A N/A Intel SGX 1.0 Intel SGX 1.0 Intel SGX 1.0 Power Management TBD C10 & S0ix Support for Modern Standby C10 & S0ix Support for Modern Standby C10 & S0ix Support for Modern Standby C10 & S0ix Support for Modern Standby C10 & S0ix Support for Modern Standby C8 Support Launch 2024 2022 2021 2021 2019 2018 2017

The 13th Gen CPU will also feature enhanced overclocking capabilities. Alder Lake currently goes up to 5.5 GHz with the upcoming Core i9-12900KS SKU which is rated at a maximum power rating of up to 260W, the highest ever on the mainstream platform.

There's also a new AI M.2 module support that's supported by Raptor Lake CPUs and could have something to do with PCIe Gen 5 SSD support. The AI module could automatically detect a PCIe Gen 5 SSD and set the protocol of the M.2 slot to the newer standard though we have to learn more details about it. But as per the latest information we have, there doesn't seem to be any storage Gen 5 lanes coming directly from the CPU, and motherboard makers would have to split discrete GPU (x16 lanes) with M.2 storage ports to enable Gen 5 SSD support.

Intel 13th Gen 'Raptor Lake' CPUs Pricing

Intel's pricing strategy starting its 12th Gen Alder Lake lineup has been very aggressive and that has definitely helped them sell enough units to start making a dent in AMD's Ryzen market share. Segments such as the Core i5 and Core i7 are showing up in the 'Top 10 Sellers' on several NA & EU-based retailers.

Each segment has featured a disruptive price point and it is likely that Intel won't be adjusting or moving their prices up considering that they have a formidable opponent on the horizon in the form of the Ryzen 7000 series. As such, we can expect the 13th Gen Raptor Lake Desktop CPUs to adopt the same prices as Alder Lake. Considering that there's a $150-180 US gap between the top Core i9 and Core i7 SKUs, we can see Intel slot in two Core i9 SKUs, one with 16 cores & the other with 24 cores for its next-gen lineup.

Intel 13th Gen 'Raptor Lake' CPUs Launch & Availability

As for launch and availability, the Intel 13th Gen Raptor Lake Desktop CPUs are expected to launch alongside the 700-series chipset family on the 27th of September, 2022. The following is the latest embargo for 13th Gen CPUs:

Raptor Lake-S Processors and Intel® Z790 Chipset: Enthusiast Consumer K and KF SKUs only

Product Introduction Embargo Date: 27 Sep 2022 @ 09:20 am PT (Intel Innovation’22)

27 Sep 2022 @ 09:20 am PT (Intel Innovation’22) Sales Embargo Date: 20 Oct 2022 @ 06:00am PT m

The shelve launch is positioned for 20th October which will be around a month after the next-gen AMD Ryzen 7000 CPUs. Both AMD & Intel are known to push out their premium offerings first before moving into the mainstream/budget segment so expect Intel to introduce 'K' unlocked parts and Z790 boards before venturing into the non-K lineup.

Intel Mainstream CPU Generations Comparison:

Intel CPU Family Processor Process Processor Architecture Graphics Architecture Processors Cores/Threads (Max) TDPs Platform Chipset Platform Memory Support PCIe Support Launch Sandy Bridge (2nd Gen) 32nm Sandy Bridge HD3000 4/8 35-95W 6-Series LGA 1155 DDR3 PCIe Gen 2.0 2011 Ivy Bridge (3rd Gen) 22nm Ivy Bridge HD4000 4/8 35-77W 7-Series LGA 1155 DDR3 PCIe Gen 3.0 2012 Haswell (4th Gen) 22nm Haswell HD4600 4/8 35-84W 8-Series LGA 1150 DDR3 PCIe Gen 3.0 2013-2014 Broadwell (5th Gen) 14nm Broadwell Iris Pro 6200 4/8 65-65W 9-Series LGA 1150 DDR3 PCIe Gen 3.0 2015 Skylake (6th Gen) 14nm Skylake HD 500 Series 4/8 35-91W 100-Series LGA 1151 DDR4 PCIe Gen 3.0 2015 Kaby Lake (7th Gen) 14nm Skylake HD 600 Series 4/8 35-91W 200-Series LGA 1151 DDR4 PCIe Gen 3.0 2017 Coffee Lake (8th Gen) 14nm Skylake HD 600 Series 6/12 35-95W 300-Series LGA 1151 DDR4 PCIe Gen 3.0 2017 Coffee Lake (9th Gen) 14nm Skylake HD 600 Series 8/16 35-95W 300-Series LGA 1151 DDR4 PCIe Gen 3.0 2018 Comet Lake (10th Gen) 14nm Skylake HD 600 Series 10/20 35-125W 400-Series LGA 1200 DDR4 PCIe Gen 3.0 2020 Rocket Lake (11th Gen) 14nm Cypress Cove HD 700 Series 8/16 35-125W 500-Series LGA 1200 DDR4 PCIe Gen 4.0 2021 Alder Lake (12th Gen) Intel 7 Golden Cove (P-Core)

Gracemont (E-Core) HD 700 Series 16/24 35-125W 600 Series LGA 1700/1800 DDR5 / DDR4 PCIe Gen 5.0 2021 Raptor Lake (13th Gen) Intel 7 Raptor Cove (P-Core)

Gracemont (E-Core) HD 700 Series 24/32 35-125W 700-Series LGA 1700/1800 DDR5 / DDR4 PCIe Gen 5.0 2022 Raptor Lake Refresh (TBA) Intel 7 Raptor Cove (P-Core)

Gracemont (E-Core) HD 700 Series 24/32 35-125W 700-Series LGA 1700/1800 DDR5 / DDR4 PCIe Gen 5.0 2023 Meteor Lake Intel 4 Redwood Cove (P-Core)

Crestmont (E-Core) Xe1 (Alchemist) 22/28 35-65W 800 Series LGA 1851 DDR5 PCIe Gen 5.0 2024 Arrow Lake Intel 20A Lion Cove (P-Core)

Skymont (E-Core) Xe1 (Alchemist) 24/32 TBA 800 Series LGA 1851 DDR5 PCIe Gen 5.0 2024 Arrow Lake Refresh (TBA) Intel 20A Lion Cove (P-Core)

Skymont (E-Core) Xe1 (Alchemist) TBA TBA 800 Series LGA 1851 DDR5 PCIe Gen 5.0 2025 Lunar Lake Intel 18A TBD Xe2 (Battlemage) TBA TBA 900-Series? LGA 1851?? DDR5 PCIe Gen 5.0? 2025 Panther Lake (TBA) TBA TBD Xe3 (Celestial) TBD TBD 900-Series? LGA 1851? DDR5 PCIe Gen 6.0? 2026 Nova Lake (TBA) Intel 18A TBD TBA TBA TBA 1000-Series? TBA DDR5? PCIe Gen 6.0? 2026","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/pokemon-scarlet-and-violet-everything-you-need-to-know-guide/,Pokémon Scarlet and Violet – Everything You Need to Know About this Free-Roam Safari,"Product Info Pokémon Scarlet and Violet November 18, 2022 Platforms Nintendo Switch Publisher Nintendo Developer Game Freak Expected Price $59.99 Expected Release Date November 18, 2022

This has been a big year for fans of catching ‘em all, as Nintendo and Game Freak launched Pokémon Legends: Arceus in January, and now they’re preparing to drop the next core entry in the series, Pokémon Scarlet and Violet. It’s been three years since the last mainline game, Pokémon Sword and Shield, came out, so Poké hunger is at its peak.

Game Freak is promising some big changes for Pokémon Scarlet and Violet, including a full open world, non-linear progression, and co-op play. While there are some questions about whether Game Freak's dated tech is up to the job, this is undoubtedly their most ambitious effort yet. Here’s everything an aspiring trainer needs to know about Pokémon Scarlet and Violet…

Setting and Story

Pokémon Scarlet and Violet take place in the new Paldea region, which is said to be vaguely inspired by Spain and Portugal. The game has a somewhat Harry-Potter-esque setup, with the player visiting a Pokémon academy instead of just wandering off to make their way in the world. Here you’ll meet the usual cast of Pokémon RPG personalities, which may differ depending on whether you buy the Scarlet or Violet version of the game. These include Professors Sada or Turo, your friendly rival Nemona, and various other characters. As usual with Pokémon, don’t expect the most epic or emotionally complex story, but it seems like there should be some likable characters to hang out with.

Is this the open-world Pokémon I’ve been waiting for?

While we still have to wait to see how well Game Freak executes the concept, it seems the answer could be “yes.” Pokémon Scarlet and Violet will present a full open-world, with players able to explore as they see fit with few restrictions. Somewhat similar to Pokémon Legends: Arceus released earlier this year, collectible critters will actually appear in the overworld, rather than popping up randomly like in the past (although the behaviour they exhibit won’t be as complex).

For those who don’t want to just wander randomly, the game will essentially offer three campaigns to follow, which you can switch between as you desire. Victory Road is your traditional “collect the gym badges” challenge, although this time you can tackle them in whatever order you want. Meanwhile, Path of Legends will see you hunting down huge Titan Pokémon, and Starfield Street will see you do battle with Team Star (this game’s Team-Rocket-style bad guys).

Can I play with my friends?

Yes, and in a much less limited way than in the past. In addition to standard stuff, like trading and engaging in friendly battles, up to four players will be able to explore the world of Pokémon Scarlet and Violet together. It seems you’ll likely need an online connection and multiple copies of the game to team up, as there's been no mention of any sort of offline mode.

While you’re free to just mess around with buddies, the main co-op feature of Pokémon Scarlet and Violet are “Tera Raid Battles,” in which you and your fellow players take on powerful Terastallized Pokémon under a time limit (scroll on down for more info about the whole Terastallizing thing). Meanwhile, for the more adversarial folks out there, the competitive Battle Stadium also returns.

How have battles changed?

For the most part, Pokémon Scarlet and Violet’s battles will still be familiar turn-based affairs. That said, you will now encounter some Pokémon that have been “Terastallized,” giving them a shiny crystal-like shell and enhanced abilities. You can also Terastallize your own critters with a special orb. This orb only has a single change, allowing you to Terastallize just one of your party during a battle, but you can recharge it at any Pokémon center. In addition to simply giving them more power, you'll discover Terastallizing some Pokémon will temporarily change their type, giving you more versatility in battle.

The other big change to battling in Scarlet and Violet is that… you don’t have to if you don’t want to. You can set one of your Pokémon to fight wild Pokémon passively, allowing you to explore freely and collect XP without having to worry about constant battles. Similarly, battles with other trainers won’t be forced on you anymore – only you can initiate them.

What are some of the quirky extras I can play around with?

In addition to catching ‘em all, following the three main story paths, and goofing around with friends, there will be the usual variety of side activities to mess with. Pokémon Scarlet and Violet lets you assemble and eat picnics, because you can’t catch ‘em all on an empty stomach. There are also new options for customizing your character and a full photo mode to tinker with.

Will the game include the full Pokedex?

Unfortunately, no. Starting with Pokémon Sword and Shield, Game Freak stopped allowing players to import and play with all existing Pokémon varieties. The same will hold true for Pokémon Scarlet and Violet. The game features 400 catchable critters at launch, although there's a very good chance DLC will add more Pokémon down the line.

What are some of the new Pokémon coming to the game?

Of course, Pokémon Scarlet and Violet will have a variety new critters to collect. While the flow of new Pokémon has slowed in recent years, 20 have been revealed so far, with more to come. Most importantly, we have our new starters, the grass type Sprigatito, the fire type Fuecoco, and water type Quaxly (who quickly became the Internet's favorite, obviously).

There are also the new legendary Pokémon Koraidon and Miraidon, which will be important companions in your Scarlet and Violet journey as both of them can be used as vehicles, transforming into Poke-cycles and gliders to get around the map.

Other highlights include the chubby electric frog Bellibolt, the oddly-intimidating Farigiraf, and the bready dog Fidough. You can check out a gallery of announced Scarlet and Violet creatures, below.

2 of 9

You can check out the full Pokemon Scarlet and Violet Paldea Pokedex here.

Pricing, platform, release date, and limited edition

Pokémon Scarlet and Violet will arrive on Nintendo Switch on November 18 of this year. As is tradition, Scarlet and Violet will be offered as two slightly different games for $60 apiece. That said, Nintendo will also be offering the Pokémon Scarlet and Violet Double Pack for $120. No, you’re not missing anything, you don’t get any deal for buying the Double Pack – it’s simply a way to get both games if you absolutely have to experience every scrap of content. You can pre-order here.","Software, Mobile, Analysis, Pokémon Legends: Arceus, Exclusives, Web, Finance, Pokémon Scarlet and Violet, Hardware, Security, Interviews, Gaming, Deals"
https://wccftech.com/roundup/qualcomm-snapdragon-8-gen-2-specs-features-everything-else/,"Qualcomm Snapdragon 8 Gen 2 – Better Power Efficiency, New Rumored CPU Configuration and Everything Else You Should Know","Product Info Snapdragon 8 Gen 2 November 2022 Manufacturer Qualcomm Type Mobile chipset Platforms Android / Windows Expected Release Date November 2022

After the mess that was the Snapdragon 8 Gen 1, Qualcomm probably learned from its mistakes and setbacks, launching a significantly improved Snapdragon 8 Plus Gen 1 courtesy of an improved manufacturing process. These advancements will likely be seen in the upcoming Snapdragon 8 Gen 2, along with a potentially different CPU configuration than what Qualcomm has employed on previous flagship SoCs. Here is everything you need to know about the next-generation chipset.

Snapdragon 8 Gen 2 Will Not Shift to TSMC’s Cutting-Edge 3nm Technology but Can Switch to Samsung Again, Under the Right Circumstances

From what we know, TSMC will exclusively undertake Snapdragon 8 Gen 2 orders. For those that do not know, the Snapdragon 8 Plus Gen 1 is also mass produced by TSMC under its 4nm process, so looking at the improvements made, it makes complete sense for Qualcomm to stick with its Taiwanese supplier. Unfortunately, with Apple being TSMC’s most lucrative client, we do not expect the upcoming chipset to be made on the 3nm process since that is reserved for the M2 Pro and M2 Max.

Instead, TSMC will likely re-use its 4nm architecture to fulfill Snapdragon 8 Gen 2 orders, but Qualcomm will add a bunch of tweaking to ensure that it outperforms the Snapdragon 8 Plus Gen 1 while delivering better efficiency. One tipster has already commented that the initial samples of Qualcomm’s upcoming flagship silicon are showing better power-efficiency, beating the existing Snapdragon 8 Plus Gen 1, and are likely to outperform Samsung’s Exynos 2300. Looking at such positivity, we are inclined to say that Qualcomm should stick with TSMC for its latest launch.

Then again, Samsung has beaten TSMC in the race to mass-produce 3nm chips. The Korean manufacturer announced its 3nm GAA technology almost a month ago, with the first batch expected to be shipped to customers from July 25. Unfortunately, to our knowledge, no smartphone vendor has approached Samsung for its 3nm GAA chips, at least for now. As for Qualcomm, it could start giving orders to Samsung if TSMC starts facing mass production difficulties.

Samsung has been asked to provide 3nm GAA samples to Qualcomm on request to see if the next-generation node is worth considering for the Snapdragon 8 Gen 2. Other factors, such as costs, may also be considered, so if Samsung provides a better deal than TSMC, Qualcomm may take it. Regardless of which supplier it goes to, Qualcomm will consider its position carefully as it will not want a boatload of negative press on its upcoming Snapdragon 8 Gen 2 like what happened with the Snapdragon 8 Gen 1.

Potential Specifications and Expected Performance

For multiple generations, Qualcomm has stuck with a ‘1 + 3 + 4’ CPU cluster, including the Snapdragon 8 Plus Gen 1. The first single-core brings ultra-performance to the table, followed by three less powerful cores, and lastly, four cores focused on just efficiency. The Snapdragon 8 Gen 2 could take a different direction with a rumored ‘1 + 4 + 3’ configuration. This CPU cluster might sound strange to you, and that is because it is.

Apparently, instead of using three gold cores, Qualcomm intends to use four, likely to gain an advantage against the newly announced MediaTek Dimensity 9200, which has a ‘1 + 3 + 4’ configuration, and other SoCs. With that being said, the new CPU cluster will likely be as follows, and we have also added the frequencies of each core for good measure.

One Cortex-X3 core running at 3.40GHz

Four Cortex-A715 cores running at 2.80GHz

Three Cortex-A510 cores running at 2.00GHz

Snapdragon 8 Plus Gen 1 features

The new cores should enable the Snapdragon 8 Gen 2 to attain a 20 percent performance boost against the Snapdragon 8 Plus Gen 1, all the while maintaining the same power draw. In case you wanted to glimpse its single-core and multi-core performance, leaked Geekbench 5 scores of the Galaxy S23 Plus emerged, revealing notable gains in both tests.

The upcoming test handset obtained 1485 and 4844 points in single-core and multi-core benchmarks, respectively, so while it is slower than Apple’s A16 Bionic, Qualcomm is slowly pushing to close that performance gap. The Snapdragon 8 Gen 2 may also arrive in two variants, both with different CPU clock speeds for a different class of products.

Manufacturers who prefer their smartphones to tout a sleek form factor could use a slightly slower version of the Snapdragon 8 Gen 2, while gaming handsets could go all out with the best-in-class hardware. Alongside the unique CPU configuration, the Snapdragon 8 Gen 2 is expected to be paired with Qualcomm’s latest Snapdragon X70 5G modem, reaching new peak download speeds while consuming up to 60 percent less power.

Improved Video Streaming, and Quality Thanks to New Codec Support

The Snapdragon 8 Gen 2 could be the first from Qualcomm to get AV1 support, allowing for an improved streaming experience. This codec offers an exceptional upgrade for better video quality and at the same file size. If viewed at the same video quality, AV1 reduces the file size, freeing up valuable space, and is 30 percent more efficient than the H.265 codec, meaning your smartphone’s available resources will be freed up.

Snapdragon 8 Gen 2 - When Will Qualcomm Announce It?

Qualcomm has officially announced its annual Snapdragon Summit, with presentations starting on November 15 and concluding on November 17. Going with past launch schedules, the Snapdragon 8 Gen 2 will likely be announced on November 15, and if we are lucky, perhaps we will get a preview of Qualcomm’s Nuvia-based chipset, as the company is rumored to be working on a 12-core part, with eight performance cores and four power-efficiency ones.

Overall, we are raising our expectations for the Snapdragon 8 Gen 2, especially when the Snapdragon 8 Plus Gen 1 has proven to be a worthy A15 Bionic competitor since it beats Apple’s flagship phone SoC in a gaming test. Switching to TSMC for mass production has its perks, so we look forward to seeing what Qualcomm has in store for us.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/marvels-midnight-suns-everything-you-need-to-know-about-firaxis-games-tactical-role-playing-game/,Marvel’s Midnight Suns – Everything You Need To Know About Firaxis Games’ Tactical Role-Playing Game,"Among the many games based on the Marvel Comics Universe, Firaxis Games' Marvel's Midnight Suns is, without a doubt, one of the most surprising. Instead of playing it safe and showing some of the most popular super-heroes in familiar settings, the brilliant minds behind the XCOM series have taken advantage of an old comic series from the 90s to create an experience that will be quite unique and has the potential of becoming one of the best tactical games released in recent years.

Release Date, Platforms, Editions, Season Pass

Marvel's Midnight Suns will release on December 2nd, 2022, on PC via Steam and the Epic Games Store, PlayStation 5, and Xbox Series X|S after a series of delays. The game was originally scheduled for a March 2022 release but was eventually delayed to the second half of 2022 and then to October 7th to allow the developers to polish up the experience, add more story and cinematics, and make their tactical game the best it could be. This, unfortunately, was only the first delay, as Marvel's Midnight Suns was later delayed to December 2nd, 2022, for PC and current-generation consoles and to 2023 on PlayStation 4, Xbox One, and Nintendo Switch.

Alongside the $59.99,and €59.99 Standard Edition, which just includes a copy the game, Firaxis Games and 2K will release multiple special editions of Marvel's Midnight Suns. The first one, the Enhanced Edition, a PlayStation 5 and Xbox Series X|S exclusive edition that costs $69.99 in the United States and €69.99 in Europe, includes a copy of the game and the Enhanced Premium Pack, which include five premium skins - Captain America (Future Soldier), Captain Marvel (Mar-Vell), Magik (Phoenix 5), Nico Minoru (Sister Grimm), and Wolverine (X-Force). A Doctor Strange Defenders skin is also being offered as a pre-order bonus for this edition.

The Marvel's Midnight Suns Digital+ Edition, on the other hand, is a digital-exclusive edition that will release on PC as well as on PlayStation 5 and Xbox Series X|S. Launching for $79.99 and €79.99 in the United States and Europe, respectively, includes a copy of the base game and the Digital+ Premium pack featuring 11 premium skins - Captain America (Future Soldier), Captain Marvel (Mar-Vell), Magik (Phoenix 5), Nico Minoru (Sister Grimm), Wolverine (X-Force), Blade (Demon Hunter), Captain America (Captain of the Guard), Iron Man (Iron Knight), Nico Minoru (Shadow Witch), Ghost Rider (Spirit of Vengeance), Magik (New Mutant). A Doctor Strange Defenders skin is also being offered as a pre-order bonus for this edition.

The Marvel's Midnight Suns Legendary Edition is the edition that will include the most additional content. Launching for $99.99 in the United States and €99.99 in Europe, this edition includes a copy of the game, the Season Pass, which will grant access to four DLC packs focused on Deadpool, Venom, Morbius, and Storm, and the Legendary Premium Pack, which features 23 premium skins - Captain America (Future Soldier), Captain America (Captain of the Guard), Captain Marvel (Mar-Vell), Captain Marvel (Medieval Marvel), Magik (Phoenix 5), Magik (New Mutant), Nico Minoru (Sister Grimm), Nico Minoru (Shadow Witch), Wolverine (X-Force), Wolverine (Cowboy Logan), Blade (Demon Hunter), Blade (Blade 1602), Iron Man (Iron Knight), Iron Man (Bleeding Edge), Ghost Rider (Spirit of Vengeance), Ghost Rider (Death Knight), Doctor Strange (Strange Future Supreme), Scarlet Witch (Boss Witch), Scarlet Witch (Fallen Scarlet Witch), Spider-Man (Symbiote), Spider-Man (Demon), and 2 additional skins for an unannounced hero. A Doctor Strange Defenders skin is also being offered as a pre-order bonus for this edition.

Setting, Genre, Mechanics

Marvel's Midnight Suns sports a very interesting and unusual story based on the Midnight Sons comic book series, which ran from late 1993 to late 1994. Like in the original series, iconic superheroes like Iron Man, Spider-Man, Wolverine, and Captain America have to prevent the Earth from being destroyed by Lilith, the powerful Mother of Demons that has been summoned by Doctor Faustus. In the game, players will not take direct control of any of the established superheroes available in the game, as they will take the role of Hunter, a new superhero created just for the game. Joining him in his battle against evil, alongside the aforementioned Iron Man, Spider-Man, Wolverine, and Captain America, will be Blade, Captain Marvel, Deadpool, Doctor Strange, Ghost Rider, Magik, Morbius, Nico Minoru Scarlet Witch, Sistem Grimm, Storm, and Venom.

Marvel's Midnight Suns is a tactical role-playing game that, on the surface, doesn't look too different from the XCOM series Firaxis is known for. Appearances, however, are deceiving, as the game will be much more than a simple Marvel reskin of the latest entry in the X-COM series as it will also feature deck-building mechanics that allow players to unleash special attacks with each playable hero, buff their stats and more, adding a new layer of depth to an experience that already promised to have quite a bit of it without these new mechanics. These deck-building mechanics won't be the only feature that will differentiate Marvel's Midnight Suns from the X-COM franchise, as units' movement, for example, will not be locked to a grid, and they will not miss their attacks, two features that streamline the experience a bit without dumbing it down excessively for the master tacticians out there.

The role-playing game mechanics will also play a rather big role in Marvel's Midnight Suns. When not off fighting Lilith and her minions, players can explore the main base, the Abbey, and interact with the many superheroes in the game. Depending on the dialogue choices, players can also improve Hunter's relationship with all heroes, which will allow them to learn more about the setting and this epic war against evil. Also, being a proper RPG, Marvel's Midnight Suns will sport a rather lengthy campaign that will require players between 40 and 60 hours to complete.

Trailers

PC System Requirements

Being a tactical role-playing game, Marvel's Midnight Suns won't be a particularly demanding game, as even the recommended settings aren't particularly high.

MINIMUM: Requires a 64-bit processor and operating system OS: Windows 10 64-bit Processor: AMD Ryzen 3-2200G / Intel Core i5-4430 Memory: 8 GB RAM Graphics: AMD RX 470 / GeForce GTX 960 - 4GB DirectX: Version 12 Storage: 60 GB available space

","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/crisis-core-final-fantasy-vii-reunion-everything-you-need-to-know-about-zack-fairs-return/,Crisis Core: Final Fantasy VII – Reunion – Everything You Need to Know About Zack Fair’s Return,"Product Info Crisis Core: Final Fantasy VII – Reunion December 13th, 2022 Platforms PC (Steam), PlayStation 5, PlayStation 4, Xbox Series X, Xbox Series S, Xbox One, Nintendo Switch Publisher Square Enix Developer Square Enix Expected Price $49.99 Expected Release Date December 13th, 2022

With Final Fantasy VII Remake bringing a new generation of fans, it wasn't surprising to learn that Square Enix was working on a remake of what is one of the best products to come as part of the controversial Compilation of Final Fantasy VII project, which aimed to expand the world of the seventh main entry in the series with prequels and sequels. Thanks to Crisis Core: Final Fantasy VII – Reunion, newcomers will finally be able to understand why Zack Fair is one of the most loved characters of the Final Fantasy VII universe, while long-time fans will be able to experience the hunt for Genesis like they never did before.

Release Date, Platforms, Editions

Crisis Core: Final Fantasy VII – Reunion has been announced in June 2022 for PC, PlayStation 5, PlayStation 4, Xbox Series X, Xbox Series S, Xbox One, and Nintendo Switch during the 25th Anniversary Celebrations for the seventh main entry in the series with a generic Winter 2022 release window. The game's final worldwide release date, December 13th, was announced during the September 2022 Nintendo Direct when a brand new trailer provided another look at the updated visuals and gameplay.

The Crisis Core: Final Fantasy VII – Reunion regular edition, which will be available for $49.99 in the United States and €59.99 in Europe, is accompanied by a Digital Deluxe Edition, which will be available for $69.99 in the US and €79.99 in Europe, that will include a copy of the game, original mini soundtrack, and original art book. Pre-ordering either edition will also grant access to the SOLDIER Materia set that includes the Dark Fire, Dark Thunder, and Dark Blizzard materia that can inflict Poison and Silence status ailments alongside the respective elemental damage.

Two more Crisis Core: Final Fantasy VII – Reunion editions will also release on December 13th, but only in Japan. The Hero Edition, which has now been sold out, includes a copy of the game, The Art of Crisis Core: Final Fantasy VII art book, a script book, a mini soundtrack CD, a special cosmetic box with a Shin-Ra-inspired design, a Zack Fair's figure and Aerith's Letter, a mysterious letter that will give a glimpse into some of her memories with Zack.

The Collector's Edition will include the same goodies as the Hero's Edition, except for Zack's figure. The Collector's Edition can be pre-ordered from the Square Enix Japanese store for 14,000 yen, around $96.

Genre, Setting, Mechanics

Crisis Core: Final Fantasy VII – Reunion will be a faithful retelling of the original game's story. Set seven before the events of Final Fantasy VII, Crisis Core follows SOLDIER 2nd Class operative Zack Fair as he is sent together with 1st Class operative Angeal Hewley and the legendary Sephiroth to investigate the mysterious disappearance of another SOLDIER 1st Class member, Genesis. During the course of the adventure, Zack will get to meet many familiar faces like Cloud Strife and Aerith Gainsborough and eventually learn more about the dark side of the Shinra Corporation and how steep is the price of freedom in an intense and emotional ending. While the story will be the same as that of the original, there will be times when Final Fantasy VII Remake players will feel that something is off, according to Yoshinori Kitase.

Gameplay in Crisis Core: Final Fantasy VII – Reunion will also be almost identical to that of the original. Controlling Zack, players can explore different areas with a third-person perspective, interact with NPCs, collect items and fight all sorts of enemies in the game's real-time combat system that combines action and command-based elements. The new version of the game features plenty of combat improvements, such as an increased number of shortcuts that will give players quick access to the combat options unlocked by equipping Materia, such as magic, skills, and more. The Digital Mind Wave system, which grants special bonuses in combat depending on the aligned numbers, will also make a return but will be slightly less intrusive than in the original, giving players the choice of storing a special attack and unleashing it at any point during battle.

Crisis Core: Final Fantasy VII – Reunion will also feature plenty of other improvements outside of the gameplay ones. Visuals have been remastered with higher resolution and new character models, the UI has been redesigned to feel similar to that of Final Fantasy VII Remake, and the music has been rearranged. All these improvements are set to make Zack's story even more epic.

If you're looking for some hands-on impressions, check out Kai Powell's New York Comic-Con preview.

Trailers

The first Crisis Core: Final Fantasy VII – Reunion trailer was shared during the Final Fantasy VII 25th Anniversary celebration live stream, which provided the first look at the updated visuals and gameplay.

The announcement trailer has been followed by a second Crisis Core: Final Fantasy VII – Reunion trailer in September 2022, which confirmed the December 13th release date.

PC System Requirements

Being a step above a regular remaster but not exactly a full-blown remake, Crisis Core: Final Fantasy VII – Reunion will not be a particularly demanding game on PC.

MINIMUM:

Requires a 64-bit processor and operating system OS: Windows 10 / Windows 11 64-bit Processor: AMD A8-7600 / Intel Core i3-3210 Memory: 8 GB RAM Graphics: AMD Radeon RX 460 / NVIDIA GeForce GTX 750 Ti DirectX: Version 12 Storage: 30 GB available space Sound Card: DirectX Compatible Sound Card Additional Notes: 30 FPS @ 1280x720



RECOMMENDED:","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/the-callisto-protocol-everything-you-need-to-know-about-the-dead-space-inspired-horror-game/,The Callisto Protocol – Everything You Need to Know About the Dead Space-Inspired Horror Game,"Product Info The Callisto Protocol December 2, 2022 Platforms PlayStation 5, PlayStation 4, Xbox Series, Xbox One, and PC (Steam/Epic Games Store) Publisher KRAFTON Developer Striking Distance Studios Expected Price $69.99/$89.99/$249.99 Expected Release Date December 2, 2022

December is almost here, and so is The Callisto Protocol. The upcoming title from developer Striking Distance Studios and Glen Schofield (co-creator of the Dead Space series) is set to release in early December, so let’s have a quick rundown of what we know about the game and its features.

The game was originally announced back in December 2020 at The Game Awards, as were other titles. A red-band trailer released shortly thereafter gave more of an extended look at the game’s world and characters. Ever since then, we got a lot of information regarding the game's setting and gameplay mechanics, which we'll comb through with this article.

Pricing, release date, and platforms

The game will release on December 2nd, 2022, for PlayStation 5, PlayStation 4, Xbox Series, Xbox One, and PC via Steam and the Epic Games Store. Pre-orders are available now for The Callisto Protocol, and you can order one of three versions: the Day One Edition, the Deluxe Edition, and the Collector’s Edition (not available for PC). The Day One Edition has the game, the Retro Prisoner character skin, and two Retro Prisoner weapon skins for $59.99 on PC or $69.99 on consoles.

For an additional $20, The Callisto Protocol’s Deluxe Edition has the following features:

The Callisto Protocol main game

The Retro Prisoner character skin

two Retro Prisoner weapon skins

The game’s Season Pass

Meanwhile, the game’s Collector’s Edition (only available through GameStop) costs $249.99 and includes the following:

The Callisto Protocol main game

The Retro Prisoner character skin

two Retro Prisoner weapon skins

The game’s Season Pass

a statue of Jacob, the game’s main character

Steelbook Case

TCP Comic #0 Edition

an Outer Way Collectable Pin

a UJC Collectible Pin

48-hour Advanced Access to Story DLC (exclusive to PlayStation 5 and PlayStation 4)

The PC version is not eligible for the Collector’s Edition, so they’ll have to ignore it. Xbox Game Pass users are, unfortunately, going to have to purchase the game like everyone else. Striking Distance Studios has definitely thought about including it in the massively popular program, but the model doesn’t seem feasible for single-player games from independent studios in their eyes.

PC System Requirements

The PC version requirements are important for the game. To even run The Callisto Protocol, you need to meet these specifications:

A 64-bit processor and operating system

OS: Windows 10/11

Processor: Intel Core i5-7500 / AMD Ryzen 3 1200 4 Cores

Memory: 8 GB RAM

DirectX: Version 11

Meanwhile, the recommended requirements for The Callisto Protocol are as follows:

Requires a 64-bit processor and operating system

OS: Windows 10/11

Processor: AMD Athlon 5350 (6 Available Cores)

Memory: 8 GB RAM

DirectX: Version 12

PC Features

Next up, AMD’s Fidelity FX Super Resolution (or FSR for short) 2.0 was confirmed to be included in The Callisto Protocol, among other games like Hitman III, Grounded, Forspoken, and Microsoft Flight Simulator, to name a few.

On the topic of AMD, back at the start of August, The Callisto Protocol was revealed to be an official partner for AMD hardware. Essentially, it’s very likely that NVIDIA DLSS will not be in The Callisto Protocol at launch, at least. Whether it will be added later is currently unknown, but we’ll update if it does.

Finally, within the last few weeks, The Callisto Protocol’s PC version has had ray tracing confirmed for the game (as well as including some Unreal 5 elements), as well as a year’s worth of updates coming. This leads to just last week when a brand-new trailer debuted that discussed the secrets of Black Iron Prison.

Story and Setting

A few months ago, The Callisto Protocol was officially cut away from its original setting (inside the PlayerUnknown’s BattleGrounds universe), severing any and all connectivity to that game’s continuity. Black Iron Prison is now contained within its own universe, and protagonist Jacob Lee (played by Josh Duhamel) is on a mission to escape and survive.

While exploring, Jacob will encounter various deadly creatures that he’ll have to fight off or run away from. Black Iron also is home to various traps or cinematics that can immediately kill Jacob if the player isn’t paying attention, requiring the player to stay alert at all times. Throughout the prison, he’ll come across Dani Nakamura (played by Karen Fukuhara), leader of a resistance group, and Leon, the Captain of the Prison Guard, played by Sam Witwer.

A gameplay reveal followed soon thereafter at Sony’s June 2022 State Of Play, which showcased Jacob exploring Black Iron Prison, along with the game’s highly-detailed violence and gore. The game is going to follow in Dead Space's steps by showing visceral and brutal death scenes in which the protagonist can die due to environmental hazards or be executed by the game's monsters.

Gameplay Mechanics

September 2022 rolls around at this point, and by now, Striking Distance Studios finally explained some of the core intricacies of the combat system in The Callisto Protocol. It’s a mixture of ranged and melee combat powered by the GRP (or “Grip”) mechanic. Enemies need to be taken down efficiently and accurately in order to not get into too much trouble.

If left unchecked, enemies will begin to experience Mutations. These Mutations will make them far deadlier, more powerful, and generally harder to kill. If that seems unsettling, just imagine it when you’re dealing with a room full of Mutated creatures. Quick-time events in various cinematics will also be present, and missing any of them will result in death, as to be expected.

Trailers

The Callisto Protocol has seen many trailers released for it, all of which you can see below, along with a caption on when they were released.

Original announcement trailer at The Game Awards 2020.

Extended Red Band Trailer from late 2020.

First gameplay reveal from June 2022.

Summer Game Fest 2022 Trailer.

Summer Game Fest 2022 Next-Gen gameplay trailer.

Gamescom 2022 next-gen gameplay trailer.

The Callisto Protocol The Truth of Black Iron trailer.

We’ll continue to update as more information for The Callisto Protocol is released, including DLC content, trailers, and more. Stay tuned.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/star-ocean-the-divine-force-everything-you-need-to-know-about-tri-aces-jrpg/,Star Ocean: The Divine Force – Everything You Need to Know About tri-Ace’s JRPG,"Product Info Star Ocean: The Divine Force October 27th, 2022 Platforms PC (Steam), PlayStation 5, PlayStation 4, Xbox Series X, Xbox Series S, Xbox One Publisher Square Enix Developer tri-Ace Expected Price 59.99 Expected Release Date October 27th, 2022

The Star Ocean series may not be well-known as JRPG juggernauts like Final Fantasy and Dragon Quest, but it is still a popular franchise with an extremely loyal following that hasn't given up on it yet despite the release of some middling titles like Star Ocean: Integrity and Faithlessness.

With a much higher budget and an experience that feels close to the classic entries in the series, Star Ocean: The Divine Force is setting out to be a return to form for the series and a game that may surprise JRPG fans who never had the chance to experience the series at its finest.

Release Date, Platforms, Editions

Star Ocean: The Divine Force's announcement caught many by surprise, as no one knew that a new entry was in the works before the October 2021 PlayStation State of Play event where the game was officially announced for PlayStation consoles with a generic 2022 release date. On the same day, the game was also confirmed for PC, Xbox Series X, Xbox Series S, and Xbox One. Months later, Square Enix confirmed that the new entry in the series would debut worldwide on October 27th.

Unlike other JRPGs published by Square Enix, Star Ocean: The Divine Force will not receive a Collector's Edition. The game's Standard Edition will be released alongside a Digital Deluxe Edition that will include the full game, the Digital Deluxe Edition Original Soundtrack, the Radiant Hildegrim and Holy Sigrdrife armor and the Bunny the Lagomower Broock, tri-Emblum, Gold Bunny Statue, and Andvaranaut's Ring accessories. It hasn't yet been specified if these items are exclusive to the Deluxe Edition or if they can be obtained in-game.

The Standard Edition is priced at $59.99, while the Digital Deluxe Edition is listed at $74.99.

Genre, Setting, Mechanics

Like its predecessors, Star Ocean: The Divine Force will be a Japanese role-playing game with a varied cast of characters, multiple locations to explore, and lots of different enemies to defeat. The game takes features from previous Star Ocean titles to create a unique mix that both newcomers and veterans will love.

Star Ocean: The Divine Force is set in S.D. 583, between the events of the mobile game Star Ocean: Anamnesis and Star Ocean: Till the End of Time. In this age, the Pangalactic Federation, which always stood to protect order and peace in the galaxy, has changed for the worse, becoming an organization that forces planets to join its ranks by force. Raymond, captain of the merchant vessel Ydas, experiences the darkness that has engulfed the Federation first-hand when his ship is attacked by the Astoria, a Federation vessel that carries a member of the Kenny family, a name that fans of the first two entries in the series should know well. Following the attack, Raymond and his crewmates are forced to abandon their ship, landing with their escape pods on the underdeveloped fourth planet in the Aster System. Here, Raymond meets the crown princess of the Kingdom of Aucerius, Laeticia, a meeting that will change not only his life but that of the entire planet and the Pangalactic Federation.

Like Star Ocean: The Second Story, Star Ocean: The Divine Force features a dual protagonist system that lets players experience the story from either Raymond or Laeticia's points of view. It is not yet known how much the two stories will differ, but, looking at the second entry in the series, they will likely be almost the same, featuring slightly different events and endings.

Some notable changes will also spice up the series' typical gameplay. Taking a page from Star Ocean: Integrity and Faithlessness, combat will not occur in dedicated arenas, as both regular enemies and bosses will be fought right where they are encountered. Combat party size, however, has been reduced to four, but this will not limit combat options at all, thanks to the AP system that allows characters to unleash skills in quick succession. Playable characters Raymond, Laeticia, Elena, Albaird, Nina, Midas, Malkya, and Marielle will all come with unique combat styles, so players will have no trouble finding a character that best suits their playstyles. The action combat system will also feature mechanics seen in previous entries in the series, such as Blindsides, quick maneuvers that leave the enemy defenseless for a short while, opening to big damage.

Another major change featured in Star Ocean: The Divine Force over previous entries in the series is D.U.M.A, a companion robot that grants characters the ability to fly and glide for a short while on the field and perform advanced combat skills like the dashing attack called Vanguard Assault, which is also used to perform the aforementioned Blindsides. D.U.M.A. abilities can also be expanded during the course of the adventure to keep combat fresh and exciting.

Star Ocean: The Divine Force will also sport more returning features like Private Actions, special events that deepen the bonds between characters, and Item Creation, which lets players create and customize all sorts of items. A new minigame called Es'owa will also be included, although its mechanics have yet to be outlined.

Star Ocean: The Divine Force promises to be a return to form regarding music as well, as series composer Motoi Sakuraba returned to compose and arrange the game's soundtrack. L'Arc-en-Ciel, Vamps vocalist HYDE has also provided the game's theme song PANDORA.

Playable Demo

A playable Star Ocean: The Divine Force demo has been released on September 20th on PlayStation and Xbox consoles, allowing players to experience the first few hours of Raymond's story and the improved exploration and combat mechanics. The demo will not release on Steam.

PC System Requirements

MINIMUM: OS: Windows 10 / Windows 11 (64-bit) Processor: AMD Ryzen 5 1500X / Intel Core i7-7700 Memory: 16 GB RAM Graphics: AMD Radeon RX 580 / NVIDIA GeForce GTX 1060 (6 GB VRAM) DirectX: Version 11 Storage: 70 GB available space Additional Notes: 720p, Medium settings, 50+ frames per second



RECOMMENDED: OS: Windows 10 / Windows 11 (64-bit) Processor: AMD Ryzen 5 3600X／Intel Core i7-8700k Memory: 16 GB RAM Graphics: AMD Radeon RX 5700 XT / NVIDIA GeForce RTX 2070 (8 GB) DirectX: Version 11 Storage: 70 GB available space Additional Notes: 1080p, High Settings, 60 frames per second



Trailers

Star Ocean: The Divine Force's first trailer was shown during the October 2021 PlayStation State of Play event, providing an overview of the game's main characters, story, setting, and action combat.

Fans of the game had to wait a few months for the next trailer, which was shared in late June 2022. Their patience was rewarded with a release date announcement.

With Tokyo Game Show returning in full force in 2022, there was no way Square Enix would not take advantage of it to showcase Star Ocean: The Divine Force further, releasing an extended trailer that provided an in-depth look at the game's story, setting, and combat.

Fans who wanted to know more about the Star Ocean: The Divine Force story, characters, and gameplay mechanics were also treated to several Mission Report videos that go more in-depth than any regular trailer could.

Short character trailers have also been released to better acquaint players with Raymond, Laeticia, and their companions.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/call-of-duty-modern-warfare-2-everything-you-need-to-know-about-the-reboot-sequel/,Call of Duty: Modern Warfare 2 – Everything You Need to Know About the Reboot Sequel,"Product Info Call of Duty: Modern Warfare 2 October 28, 2022 Platforms PlayStation 5, PlayStation 4, Xbox Series, Xbox One, and PC (Steam/Battle.net) Publisher Activision Blizzard Developer Infinity Ward, Raven Software, Beenox, Treyarch, High Moon Studios, Sledgehammer Games, Activision Shanghai, Demonware, Toys for Bob Expected Price $69.99/$99.99 Expected Release Date October 28, 2022

Call of Duty is a series that’s seen classics like Modern Warfare and World At War or the Black Ops subseries of titles. They’re first-person shooters designed by Activision Blizzard, and the latest title, Call of Duty: Modern Warfare 2, is a continuation of the 2019 Modern Warfare, not a remaster of the 2011 classic on Xbox 360.

Call of Duty: Modern Warfare 2 is set to release in about three weeks, and with the new release, up until now, there’s been substantial amounts of information. Here’s what you need to know about Activision Blizzard’s next big Call of Duty venture.

Release date, pricing, and platforms

Activision Blizzard releases Modern Warfare 2 on October 28th, 2022, for PlayStation 5, PlayStation 4, Xbox Series, Xbox One, and PC via Battle.net and Steam. There will be cross-play between all these platforms.

Pre-orders for the game are open right now, and you can preorder either the base game (Cross-Gen Bundle on console) or the Vault Edition. The default (Cross-Gen Bundle) pre-order is priced at $69.99 and includes the following:

Call of Duty: Modern Warfare II (2022) base game (last-gen and current-gen versions)

Campaign access one week early

Final Judgement Bundle (includes Deathknell Operator skin and Bloodthirsty weapon blueprint for use in Call of Duty Vanguard and Call of Duty Warzone)

The Oni Operator Pack (PlayStation 4 and PlayStation 5 exclusively)

If you want to pre-order the Vault Edition (priced at $99.99), it includes:

Call of Duty: Modern Warfare II (2022) base game (last-gen and current-gen versions)

Campaign access one week early

the Final Judgement Bundle

The Oni Operator Pack (PlayStation 4 and PlayStation 5 exclusively)

Season 1’s Battle Pass + 50 Tier Skips

Ghost Legacy Pack DLC

Red Team 141 Operator Pack

FJX Cinder Weapon Vault

The pre-order details show that Activision Blizzard’s next Call of Duty game will have battle passes (like many games these days do), and grabbing the Vault Edition will let you skip 50 tiers. Whether that’s half of it or two-thirds isn’t clear yet, but we’ll know when the game launches.

Something interesting about this game’s release is that it marks a return to Steam for Call of Duty. For reference, Call of Duty’s relationship with Valve’s storefront has been on a hiatus since WWII back in 2017. Modern Warfare 2019 was completely absent from Steam, as were Black Ops 4, Black Ops: Cold War, and Vanguard.

New Game Modes and Changes

The latest installment in the Call of Duty series will introduce several new changes and modes that will spice things up. Modern Warfare 2 will bring new abilities, an overhauled vehicle system that allows players to lean out of vehicle windows or mantle onto a vehicle roof. Swimming mechanics have been added thanks to the addition of water physics, and it is also possible to dive into the prone position, mantle, and ledge hang.

The leveling and Gunsmith system has been revamped, allowing players to fine-tune specific attachments to suit their playstyles. Modern Warfare 2 will also bring several new game modes. Here's a list of the competitive game modes that will be available in the game:

Team Deathmatch : Two teams of 6 players face off against each other to get kills and reach a score of 75. This has to be done under a time limit that will end games if the score limit is not reached.

: Two teams of 6 players face off against each other to get kills and reach a score of 75. This has to be done under a time limit that will end games if the score limit is not reached. Domination : Players must capture and hold three objectives to earn points. While there's no time limit in this mode, it will continue until either team reaches 200 points.

: Players must capture and hold three objectives to earn points. While there's no time limit in this mode, it will continue until either team reaches 200 points. Invasion : 40 players face off against AI enemies in a 20v20 elimination match. This is a large-scale mode in which players and their opponents go in an all-out war.

: 40 players face off against AI enemies in a 20v20 elimination match. This is a large-scale mode in which players and their opponents go in an all-out war. Ground War : Huge teams of 32 players will have to battle for supremacy by capturing and holding objectives in this large-scale mode.

: Huge teams of 32 players will have to battle for supremacy by capturing and holding objectives in this large-scale mode. Prisoner Rescue : A hostage situation is the background set for this mode. One team of 6 players will have to locate hostages and extract them. The second team is tasked with eliminating the opposing force. However, it's also worth noting that there are no respawns in this mode, and only team revives will bring players back.

: A hostage situation is the background set for this mode. One team of 6 players will have to locate hostages and extract them. The second team is tasked with eliminating the opposing force. However, it's also worth noting that there are no respawns in this mode, and only team revives will bring players back. Knock Out : This game mode also has no respawns, much like Prisoner Rescue. In it, you can hold a package to earn points and win. Players face off in a 6v6 elimination match where scoring the most points wins the game.

: This game mode also has no respawns, much like Prisoner Rescue. In it, you can hold a package to earn points and win. Players face off in a 6v6 elimination match where scoring the most points wins the game. Hardpoint : In this mode, you have to defend a moving objective to earn points. In this 6v6 mode, you must play in round-based matches where the winner must reach a score limit.

: In this mode, you have to defend a moving objective to earn points. In this 6v6 mode, you must play in round-based matches where the winner must reach a score limit. Search and Destroy: There are no respawns in this mode. The game mode will see one team planting a bomb while the other defends the objective. Once the bomb is planted, it has to be defused before the explosion. This game mode offers short and quick rounds with an added spice of tactical gameplay.

There is a third-person mode, too, for those interested in that kind of gameplay. Furthermore, Call of Duty: Modern Warfare 2 even has co-op content, thanks to the Special Ops (for two players) and the post-launch Raids (for up to three players).

PC System Requirements and Features

To run Call of Duty: Modern Warfare 2 on your personal computer, you’ll need to meet or exceed the following specifications:

OS: Windows 10 64-bit

CPU: Intel Core i5-3570 or AMD Ryzen 5 1600X

RAM: 8GB

GPU: NVIDIA GeForce GTX 670 or AMD Radeon RX 470

VRAM: 2GB

Storage: 25GB minimum

The recommended specs are as follows:

OS: Windows 10 64-bit

CPU: Intel Core i7-4770K or AMD Ryzen 7 1800X

RAM: 16GB

GPU: NVIDIA GeForce GTX 670 or AMD Radeon RX 580

VRAM: 2GB

Storage: 25GB minimum

Regarding PC features, the developers confirmed Ultrawide (21:9) support, NVIDIA DLSS 2, AMD FSR 1.0, and Intel XeSS support. There will be over 500 customizable settings, though ray tracing may not be one of them, even though it was available in recent Call of Duty installments.

Last but not least, Call of Duty: Modern Warfare 2 for PC ships with the new version of the RICOCHET Anti-Cheat software and its kernel-level driver. Additionally, it's been confirmed that RTX 40 series users (namely the 4090) will have a very smooth experience as the game's campaign has been shown to run at over 100 FPS in Native 4K resolution.

Modern Warfare 2 Beta Changes and Rewards

Between Modern Warfare 2’s beta last month and now, changes were announced that were meant to balance a few things based on the data collected. The changes include tweaking the game’s audio balancing for other players’ footsteps, some unnamed weapon tuning, and other bug fixes needed.

On the topic of the beta, it’s garnered record-setting numbers for the series, with fifteen million pre-registrations, according to Activision. Players who participated in the beta will receive additional rewards on day one and the weekend after, which include the following for Week 1:

“Smashed It” animated emblem

“Buckle Up” charm

“Passed the Test” animated player card

“Operation First Blood” sticker

“Side Impact” weapon blueprint

Week 2’s rewards will be as follows.

“Collision” operator skin

“No Competition” vinyl

“Safety First” sticker

“Floor It” vehicle skin

“Frontal Impact” weapon blueprint

You’ll unlock these exclusive rewards through gameplay, but players who were not in the open beta will not have access to these cosmetics and blueprints. These rewards will also be available in Warzone 2.0 when that launches on November 16th, 2022 (Warzone 2.0 will be unavailable on Steam).

Call of Duty: Modern Warfare 2 Campaign and Multiplayer Access

If you look back at the pre-order benefits, Call of Duty: Modern Warfare 2 mentions that you’ll be able to play the single-player campaign (think “story mode” in other genres) a week early. Activision confirms that this will be a reality, and if you’ve pre-ordered the game, you’ll be able to download and run the campaign on October 20th, 2022. The rest of the game (multiplayer, Spec Ops mode, and more) will open up on the 28th, as originally stated.

The game’s campaign follows Task Force 141, made of new and returning characters (such as Price, Gaz, Ghost, Soap, Kate Laswell, and Farah Karim) as they face off against a new world terror with unknown but deep connections. The campaign begins when a missile strike from the US kills a foreign general. Task Force 141 is then called to contain the situation while fighting the terrorist group al-Qatala and the drug cartel Las Almas. Missions will take place in Asia, the Americas, and Europe, placing the player in various setpieces, including underwater combat, explosive assaults from high in the sky, and stealth missions.

As for the multiplayer, you’ll have to wait for the 28th to get your hands on it. Though it should be noted that the Campaign's early access is exclusive to digital storefronts, and physical copies will not get this feature, meaning if you’ve pre-ordered the game physically, you’ll have to wait like everyone else for Day One.

Trailers and gameplay footage

Activision Blizzard has launched a metric ton of trailers for Call of Duty Modern Warfare 2, and you can view many of them below.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/bayonetta-3-everything-you-need-to-know-guide/,Bayonetta 3 – Everything You Need to Know About this Bewitching Beat ‘em Up,"Product Info Bayonetta 3 October 28, 2022 Platforms Nintendo Switch Publisher Nintendo Developer Platinum Games Expected Price $59.99 Expected Release Date October 28, 2022

The Witching Hour is almost upon us, as after a rather long wait, Bayonetta 3 finally arrives on Nintendo Switch later this month. The Umbra Witch’s latest was announced all the way back in 2017, and for years very little about the game was shared, leading some to speculate it would end up as vaporware. Thankfully, that didn’t end up being the case.

This time around, Bayonetta is trying some new things, with different demon forms allowing her to change her appearance and moveset and the Demon Slave mechanic giving players the chance to control giant demons. The game’s story also promises to be its most multilayered yet. So, strap on your gun heels and scroll on down for all the key info you need to know about Bayonetta 3.

Story and setting

This time around, Bayonetta won’t be taking on the angels or demons of the past, but rather a new type of manmade weapons called Homunculi, with an evil force known as the Singularity seemingly being behind them. This Singularity threatens to destroy “the known worlds,” and it’s up to Bayonetta to stop them. The fight will take you to various locales around the world, including Japan, China, and other places beyond. As of now, that’s about all Nintendo and Platinum have shared officially.

Getting into more speculative territory, there is heavy fan suspicion that the Bayo you play as in Bayonetta 3 is actually a different version of the character. Specifically, many have posited that she’s actually Cereza, the kid version of Bayonetta seen in the first game, all grown up. While the exact identity of Bayonetta 3’s protagonist is unclear, Nintendo has confirmed that you’ll meet a “virtual coven of Bayonettas” over the course of the game, so the theory is actually fairly plausible. The game's most recent trailer confirms Bayonetta 3 is essentially the franchise's ""Into the Spider-Verse,"" as it kicks off with somebody who looks very much like the original Bayonetta dying and a variety of alternate Bayos from around the world. Some of the other Bayonettas look to hail from Japan, China, Egypt, and France, and all have radically different looks. You can check out the latest Bayonetta 3 trailer for yourself below.

Gameplay and mechanics

Bayonetta 3 is a stylish action game that carries forward many of the core mechanics from the first two entries in the series. Players can unleash combos by inputting the proper button sequences and enter slow-motion “Witch Time” by dodging attacks at just the right moment. The devastating (and gruesome) Torture Attacks that Bayo can unleash when she stuns an enemy also return.

The powerful Wicked Weave attacks, “Beast Within” animal transformations, and weapon system of past games have now been combined into the new streamlined “Demon Masquerade” system. As before, weapons come with their own unique movesets and Wicked Weave attacks are unleashed by completing combos, but this time around, each weapon also allows Bayo to transform into a new demon-inspired form for greater mobility in fights (Madama Butterfly, Gomorrah, and Phantasmaraneae forms have been revealed thus far).

Ultimately though, the biggest addition (literally) is the Demon Slave system, which allows you to summon various large kaiju-like demons to fight by your side. You have full control over these demons’ attacks, allowing you to continue combos with them. Watch out, though – Bayonetta herself is largely defenseless while a demon has been summoned, and if it absorbs too much damage you may lose control of the beastie.

Finally, Bayonetta also introduces Viola, an all-new playable character. Viola’s playstyle differs from Bayonetta’s in a few key ways – for instance, she enters witch time by blocking and parrying rather than dodging, and she can still move and attack independently while her Demon Slave (a big freaky cat named Cheshire) has been summoned.

Of course, as with past games in the series, Bayonetta won’t be all about combat. Battles will be interspersed with short exploratory sections and over-the-top action set pieces. You never quite know what a Bayonetta game might throw at you next. You can check out Wccftech's full hands-on impressions of Bayonetta 3's combat here.

Is Bayonetta 3 going to be too hard for me?

You don’t need to be too worried. While Platinum has a reputation for demanding games, and there’s certainly a lot of room for mastery for those who want to grab those Platinum medals, you don’t have to be a high-level player to get through the game with Silver and Gold medals in most battles.

Platinum seems to have made an effort to make Bayonetta 3 more approachable than past games. Players can change the game’s difficulty setting whenever they want, and a special accessory, the Immortal Marionette, lets players execute combos by mashing a single button. Of course, if you want a hard game, you can pump the difficulty up and revel in the punishment.

Am I going to be too embarrassed to play this game in front of my spouse/family/on the bus?

Sooooo… the Bayonetta series does have a reputation for being a bit horny. Okay, a lot horny. The sexiness is relatively playful and harmless, but it can be pretty shameless at times. The trailers and promo materials for Bayo 3 have been a bit less over-the-top, but that could just be Nintendo downplaying that aspect of the game.

That said, Platinum has included a new “Naïve Angel” mode in Bayonetta 3 that will censor some of Bayonetta 3’s nudity and more risqué scenes for those who want something less edgy or are playing in front of people who may not appreciate such things. I have a feeling even this mode won’t entirely eliminate the naughty stuff, so it’s really going to come down to your own personal comfort level.

Pricing, platform, release date, and limited edition

Bayonetta 3 launches on Nintendo Switch on October 28 of this year. The standard edition of the game will cost you $60 and can be pre-ordered here. The Bayonetta 3 “Trinity Masquerade Edition,” featuring a 200-page art book and reversible covers for each game in the series, has been offered for $90, but it seems to be sold out at all retailers at the moment.

Will this game ever be available on non-Nintendo platforms?

Unlikely. Bayonetta 2 has still never appeared on a non-Nintendo platform, and much like that game, Bayonetta 3 has been fully bankrolled by The Big N. Series creator Hideki Kamiya pretty much says you should just buy a Switch if you want to play. Ultimately, Bayonetta is essentially a Nintendo character at this point, so don’t expect her to cast her spell anywhere else.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Bayonetta 3, Interviews, Gaming, Deals"
https://wccftech.com/roundup/apple-iphone-15-ultra-rumors-features-specs-release-date/,"iPhone 15 Ultra: More Exclusive Features, Potentially Higher Price and More; Here’s Everything You Need to Know","Product Info iPhone 15 Ultra Q4, 2023 Manufacturer Apple Type Smartphone Platforms iOS Expected Price TBA Expected Release Date Q4, 2023

Apart from possibly choosing a different name for the iPhone 14 Pro Max successor next year, Apple could also add more exclusive upgrades to the iPhone 15 Ultra than what it incorporated in its premium models this year. In 2023, we could be greeted with a flagship that forgoes the moniker ‘Pro Max’ and replaces it with something that befits its potential stature. Here is everything you need to know about the iPhone 15 Ultra.

Apple Is Likely to Maintain the Same Design of the iPhone 14 Pro Max for the iPhone 15 Ultra

Given that Apple stuck with the notch for five iPhone generations while only reducing its size slightly on the iPhone 13, the Dynamic Island is likely to stay on the iPhone 15 Ultra and future models. In fact, the pill-shaped cutout that transforms during any intuitive function is reported to arrive for all iPhone 15 models in 2023. At least in this area, there would be less incentive for customers to pick up the pricier models unless Apple decides to give more functionality to the Dynamic Island on the iPhone 15 Pro and iPhone 15 Ultra.

Minor Changes to the Display

Every year, Apple brings improvements to the iPhone’s screen. This year, DisplayMate gave the iPhone 14 Pro Max display more performance awards than it delivered to the iPhone 13 Pro Max, and for those that do not know, the latter was the previous reigning leader of DisplayMate’s rankings for having the best smartphone display.

A mix of LTPO OLED screens from Samsung and LG could be made for the iPhone 15 Ultra, with Samsung taking a bulk of the orders as it has done on multiple occasions. Features like refresh rate switching from 1Hz to 120Hz and Always-on Display will most probably make a return.

Currently, we have not heard of any other advanced display technologies or components being prepped for the iPhone 15 Ultra, so we will update our readers if any future reports mention those advancements.

Cutting-Edge 3nm SoC for the iPhone 15 Ultra and More

Alongside the iPhone 15 Pro, the iPhone 15 Ultra could be the first from Apple to feature the company’s first 3nm SoC. TSMC is expected to be given orders, with mass production likely commencing in the second half of 2023. The chipset could be named the A17 Bionic and like the M3 for future Macs, it could be fabricated on TSMC’s second-generation 3nm architecture, bringing better power efficiency and performance to the table.

The disappointing news from this revelation is that the A17 Bionic may be exclusive to the iPhone 15 Pro and iPhone 15 Ultra, with the less expensive models getting treated to the A16 Bionic, according to one rumor. We have not received any word if the ‘Ultra’ variant will feature more RAM, but considering that all iPhone 14 models launched this year feature 6GB LPDDR5 RAM, we should be greeted with an 8GB RAM version next year.

After all, as Apple continues to add more features to iOS, iOS 17 will require more memory to work optimally, so one way to justify the iPhone 15 Ultra purchase is to give the flagship more memory. The only question is if Apple will adopt the LPDDR5X standard like some Android phone makers. While we contemplate on Apple’s choice of specifications, we should also remind our readers to patiently wait for the technology giant’s custom 5G modem since that plan has hit a temporary roadblock and will not debut with the iPhone 15 launch.

An earlier teardown of the iPhone 14 Pro and iPhone 14 Pro Max revealed that Apple’s entire lineup features Qualcomm’s Snapdragon X65 5G modem. This modem, along with a bunch of other components, is what allows all iPhone 14 models to communicate with some satellites, with users eventually using Apple’s Emergency SOS via satellite in November. For 2023, the iPhone 15 Ultra will probably use the Snapdragon X70 5G modem, and the addition of this component could bring more exclusive satellite communication features.

As for Apple’s in-house 5G modem, experts argue that we will not see it before 2025. Other specification details of next year’s flagship are currently unknown to us, so let us move on to the camera.

New Camera Features

Reasons for buying an iPhone are plentiful, and its diversified camera array is one of them. We believe the iPhone 15 Ultra will arrive with one feature no other model for that year will get, and it will be the first in the iPhone launch’s history; a periscope zoom lens. Some of you were clamoring for Apple to add extended zoom capabilities to the iPhone, and after generating more patience than you can muster, it may only take next year of waiting for you to see the feature in action.

Currently, the iPhone’s zoom capabilities are limited to 3x optical zoom in and 2x optical zoom out, with the remaining 6x optical zoom range and up to 15x digital zoom done using a software and hardware running in unison. With a periscope zoom lens, which Apple is said to have already secured a supplier for, we could get 5x optical zoom right off the bat, meaning Apple would have greater flexibility incorporating higher digital zoom level options.

If we are lucky, Apple could implement a 10x optical zoom. As for the main sensor, we could be looking at the same 48MP camera belonging to the iPhone 14 Pro and iPhone 14 Pro Max, with Apple bringing additional software magic to boost image quality. We will get to know more about these cameras and more as time goes on.

Potentially Increased Pricing Structure

The fact that Apple is rumored to bring more exclusive features to the iPhone 15 Pro and iPhone 15 Ultra to rake increased margins and command a higher average selling price (ASP) means that the top-end model is likely to cost more. Given that the A16 Bionic running in the iPhone 14 Pro and iPhone 14 Pro Max costs more than twice to make compared to the A15 Bionic, a 3nm A17 Bionic could be an expensive chip to procure and use.

Not just this, but the addition of a periscope zoom lens, paired with an uncertain economic future that also has Apple’s only chip supplier, TSMC, raising wafer prices by up to 6 percent, the iPhone 15 Ultra could see a $100 price hike. Of course, do not take our word for it since Apple was rumored on multiple occasions to do the same for the iPhone 14 Pro and iPhone 14 Pro Max, and every single report was proven wrong. This year’s ‘Pro’ models still cost $999 while touting more upgrades than last year’s iPhone 13 Pro and iPhone 13 Pro Max.

Since the new start has not started, significant changes in rumors and reports alike will be seen, and we may have a completely different outlook on the iPhone 15 Ultra, so let us keep our crossed for more updates and wait for other surprises that Apple has planned for 2023.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/sonic-frontiers-everything-you-need-to-know-about-sonics-open-world-adventure-game/,Sonic Frontiers – Everything You Need to Know About Sonic’s Open-World Adventure Game,"Product Info Sonic Frontiers November 8th, 2022 Platforms PlayStation 5, PlayStation 4, Xbox Series, Xbox One, Nintendo Switch, and PC Publisher SEGA Developer Sonic Team Expected Price $59.99 Expected Release Date November 8th, 2022

Sonic Frontiers is just over a month away and looks to be SEGA’s next big venture for the series. The game is a more open-world format rather than linear levels this time around and has been getting lots of news coverage from conventions and even here at Wccftech, so let’s break down what we know about the game.

Sonic Frontiers was originally announced at the end of 2021, back at The Game Awards 2021. Touted as having “open-zone freedom”, the game places you in sprawling large worlds as Sonic, waiting for you to explore. At that point, the team at Sega said that more was to come later, and it definitely has.

Release Date, Pricing, Platforms

Sonic Frontiers will be released on PlayStation 5, PlayStation 4, Xbox Series, Xbox One, Nintendo Switch, and PC via Steam and the Epic Games Store on November 8th, 2022 (Epic will release at a later date. Visiting the game’s website will allow you to pre-order for any one of those platforms except for Epic Games.

Pre-ordering the game comes in one of two versions. Players who pre-order the Standard Edition (priced at $59.99) will get access to:

the Sonic Frontiers base game

access to THE ADVENTURER’S TREASURE BOX, which includes Skill Points Red Seeds of Power Blue Seeds of Defense



Meanwhile, if you pre-order the Digital Deluxe Edition (priced at $69.99), you’ll receive:

Sonic Frontiers base game

Access to THE ADVENTURER’S TREASURE BOX, which includes Skill Points Red Seeds of Power Blue Seeds of Defense

The Explorer’s Treasure Box, which includes Amy’s Memory Tokens a Portal Gear Chaos Emerald Vault Keys Additional Gloves & Shoes for Sonic

Digital art book with a 25-track digital mini soundtrack

PC System Requirements

Steam and Epic Games Store buyers will want to pay attention here because Sonic Frontiers’ PC specifications are now public knowledge. If you want to even run the game at 720p Low Settings @ 30 FPS, you’ll need the following:

Requires a 64-bit processor and operating system

OS: Windows 10

Processor: Intel Core i5-3470 or AMD Ryzen 5 1400

Memory: 8 GB RAM

Graphics: NVIDIA GeForce GTX 660, 2 GB or AMD Radeon HD 7870, 2 GB

DirectX: Version 11

Storage: 30 GB available space

The recommended specs are as follows. It should be worth noting that these specs will give you 1080p High @ 60 FPS. It also requires a CPU that supports the AVX and SSE4 instruction set.

Requires a 64-bit processor and operating system

OS: Windows 10

Processor: Intel Core i5-6600 or AMD Ryzen 5 2600

Memory: 12 GB RAM

Graphics: NVIDIA GeForce GTX 1070, 8 GB or AMD Radeon RX Vega 56, 8 GB

DirectX: Version 11

Storage: 30 GB available space

Gameplay Mechanics

Sonic Frontiers’ open worlds have lots to do outside of sightseeing; you’ll be fighting off enemies, tackling large-scale bosses, and exploring the vast landscapes of locations like Ares Island. Some minigames can also be found within the game, like fishing spots.

Though, on the topic of release dates, SEGA decided not to delay the game, despite player feedback suggesting that they should. That notion doesn’t exactly bode well for the game.

Sometime later, the developers of Sonic Frontiers released new gameplay footage through IGN, which showcased a fair chunk of the game’s traversal and landscapes. A few months ago, the title also saw some gameplay details revealed. Outside of the sprawling worlds, you’ll be able to explore, you’ll have to solve puzzles to access more parts of the map, and combat actually serves a purpose. Killing enemies will grant Sonic XP, allowing him to unlock new moves and level up.

The game is going to be far longer than other Sonic titles, clocking in at around 20 to 30 hours to finish a playthrough and a hundred hours to find and unlock everything. Comparatively, you could theoretically beat a Sonic game in a few hours if you put enough effort into it. Sonic Frontiers will also include classic stages known as Cyberspace stages (datamined from another Sonic project, Sonic Origins), meant to play like levels from past games.

Ares Island was shown off in footage from last month, giving players a glimpse of what to expect when they purchase the game itself. Some minigames will be available to players, like a fishing minigame.

Setting

The Starfall Islands are home to an ancient civilization long abandoned. The Chaos Emeralds have disappeared, and Sonic, Tails, and Amy travel to the Islands to find out why. After being separated from Tails and Amy, Sonic finds himself in Cyber Space, which takes the form of Green Hill Zone. After escaping, he’s now alone on Kronos Island, his friends nowhere to be seen.

An AI calls to him soon after, and after cryptically guiding Sonic towards rescuing his friends, destroying the “Titans” (which will probably be elaborated on later), and then “tear down the walls between dimensions” From there, the game kicks off and allows you to explore Kronos Island as you see fit.

Sonic Frontiers’ story comes from a trailer at Gamescom Opening Night Live. The studio mentioned that the game wouldn’t be going into its traditional heroes vs. villain plotlines that form the vast majority of Sonic games’ storylines. Despite this, Dr. Eggman is still making an appearance in-game, though what role he plays exactly is largely unknown (if the Story trailer is anything to go off of).

Trailers and Gameplay Videos

Sonic Frontiers has gotten a bunch of trailers between its 2021 Game Awards announcement and now, and you can watch them below.

The Game Awards 2021 announcement trailer.

May 2022 gameplay teaser.

IGN Gameplay Reveal from June 2022.

GameXplain teaser from June 2022.

Nintendo Direct Mini trailer from late June 2022.

IGN Japan footage from August 2022.

September 2022 Overview trailer.

Gamescom 2022 fishing minigame footage.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/new-tales-from-the-borderlands-everything-you-need-to-know-guide-2/,New Tales from the Borderlands – Everything You Need to Know About this Fresh Sci-fi Story,"Product Info New Tales from the Borderlands October 21, 2022 Platforms PC, Xbox One, Xbox Series X/S, PlayStation 4, PlayStation 5, Nintendo Switch Publisher 2K Games Developer Gearbox Studio Quebec Expected Price $39.99 Expected Release Date October 21, 2022

While the core looter-shooter titles will always be the main focus of the Borderlands series, for some players with niche tastes, Tales from the Borderlands is actually the best of the franchise. Featuring some of the franchise’s most likable characters and sharpest humor, Telltale’s series has held up well, but most never expected to see another Tales from the Borderlands.

Well, surprise! Earlier this summer Gearbox announced New Tales from the Borderlands, a fresh story-driven adventure featuring a new cast of characters. So, how do these New Tales carry on the legacy of Telltale’s original series? How do they differ? Scroll on down for all the key info you need to know about New Tales from the Borderlands…

Who’s Making New Tales from the Borderlands?

The original Tales from the Borderlands was the work of Telltale Games, but they went bankrupt in the time since its release. Granted, Telltale has been reformed under new ownership, but they haven't been involved in creating this new game.

New Tales from the Borderlands has instead been created in-house by a new Canadian team at Gearbox Studios Quebec. That said, “key alumni” from the original Telltale-developed Tales from the Borderlands are helping out with the game’s narrative.

Is this still an episodic game?

Yes and no. New Tales from the Borderlands will still be structured as a series of episodes, but unlike Telltale series of old, you’ll get all the episodes at once when you purchase the title.

Story Details

New Tales from the Borderlands will feature a new cast of “loveable nobodies,” including the idealistic yet nervous scientist Anu, feisty frozen yogurt store owner Fran, and your typical Borderlands neurotic smartass protagonist Octavio. All three live on the war-torn Promethea, and when the planet is invaded yet again by weapons maker Tediore, they hatch a plan to get their hands on a vault key that could give them access to untold treasures. But perhaps the real treasure will be the friends they make along the way? We’ll just have to wait and see.

While New Tales from the Borderlands is not a direct sequel to Telltale’s original series, it does take place in the broader Borderlands universe, and thus a variety of familiar faces from the past will show up. It’s been confirmed that original Tales from the Borderlands co-protagonist Rhys will make a cameo, although it seems that game’s other main character, Fiona, may be sittings things out.

Gameplay and Mechanics

New Tales from the Borderlands will follow in its predecessor’s footsteps and focus mainly on story and player choice. It seems the latter is being pushed harder than before, with Gearbox promising every decision, big and small, will have an effect on the overall narrative…

“Every choice you make can and will affect the events that unfold in the story, often in unexpected ways, so you'll have to play through the whole game to see what event or what choice affected what ending you see or what event was triggered during the process.”

Between story choices, gameplay will still largely be handled via quick time events, although there will also be exploratory sequences where you’re allowed to walk around on foot and some minigames, including one that lets you do battle with various Borderlands figurines. It should also be noted that the game is running on Unreal Engine 4, using the same visual style as Borderlands 3, so expect a much more technically accomplished game than Telltale’s somewhat janky original. You can check out around 20 minutes of New Tales from the Borderlands gameplay, below.

PC Requirements

Minimum

OS: Windows 10

Processor: Intel Core i5-4690K or AMD Ryzen 3 1300X

Memory: 8 GB RAM

Graphics: Nvidia GeForce GTX 960 4GB or AMD Radeon RX 470 4GB

DirectX: Version 12

Storage: 30 GB available space

Recommended

OS: Windows 10

Processor: Intel Core i7-4770 or AMD Ryzen 5 2600

Memory: 8 GB RAM

Graphics: Nvidia GTX 1060 6GB or AMD Radeon RX 590 8GB

DirectX: Version 12

Storage: 30 GB available space

Pricing, platforms, release date

New Tales from the Borderlands is coming to pretty much everything under the sun, including PC (via both Steam and Epic Games Store), Xbox One, Xbox Series X/S, PS4, PS5, and Switch on October 21 of this year. The game will set you back $40. There is also a $50 Deluxe Edition, which includes the original Tales from the Borderlands series. Pre-orders are open now.","Software, Mobile, Analysis, Exclusives, Web, Finance, New Tales from the Borderlands, Security, Hardware, Interviews, Tales from the Borderlands, Gaming, Deals"
https://wccftech.com/roundup/god-of-war-ragnarok-everything-you-need-to-know-about-the-twilight-of-the-gods/,God of War Ragnarök – Everything You Need to Know About The Twilight of the Norse Gods,"Product Info God of War Ragnarök November 9th, 2022 Platforms PlayStation 5, PlayStation 4 Publisher Sony Interactive Entertainment Developer Santa Monica Studio Expected Price 69,99 (PlayStation 5), 59.99 (PlayStation 4) Expected Release Date November 9th, 2022

2018's God of War proved that even the most straightforward action series can evolve into something different without doing away with everything that made it stand out, and Santa Monica studios are ready to show how their new and improved formula will evolve even further in God of War Ragnarök. Preventing the Twilight of the Norse Gods from happening will not be an easy feat, but Kratos and his son Atreus are ready for the challenge.

Release Date, Platforms, Editions

While the game had been teased in some capacity ever since the secret ending that suggested Kratos and Atreus would have to fight more Norse Gods in the future, it was only during the September 2020 PlayStation 5 showcase that a fifth main God of War game was officially confirmed with a generic 2021 release window. The debut teaser focused on the coming of Ragnarök, which led many to believe God of War Ragnarök would be the game's official name. The game's official name was confirmed only a year later, during the September 2021 PlayStation Showcase event. By that time, Sony Santa Monica had confirmed a delay into 2022, mostly caused by Kratos actor Christopher Judge recovering from surgery.

It would take a few more months to get the official release date, as Sony Interactive Entertainment and Santa Monica Studios confirmed that God of War Ragnarök would release worldwide on PlayStation 5 and PlayStation 4 on November 9th, 2022, with a cinematic trailer released on July 6th, 2022.

The God of War Ragnarök Standard Edition, which will be available for $69.99 on PlayStation 5 and $59.99 on PlayStation 4, includes a copy of the game and the Kratos Risen Snow Armor and Atreus Risen Snow Tunic as pre-order bonuses. All PlayStation 4 copies can be upgraded to a digital PlayStation 5 copy for $10.

The God of War Ragnarök Digital Deluxe Edition, which will be available for $79.99 exclusively on PlayStation 5, comes with a copy of the game, the Kratos Darkdale Armor, the Atreus Darkale Attire, Darkdale Blades Handles for the Blades of Chaos, the Darkdale Exe Grip for the Leviathan Axe, the official God of War Ragnarök Digital Soundtrack, a Dark Horse Digital Mini Artbook, and a PSN avatar set.

The God of War Ragnarök Collector's Edition, which was available for $199.99 before selling out, included all the in-game bonuses featured in the Digital Deluxe Edition as well as a voucher code for the game on PlayStation 5 and PlayStation 4, a Steelbook Display Case, 2” Vanir Twins Carvings, a Dwarven Dice Set and a highly detailed 16"" replica of Thor's Mjölnir.

The ultimate gift for all series fans is the God of War Ragnarök Jotnar Edition, which was available for $259.99 before it became sold out. This edition of the game includes all the bonuses featured in the Digital Deluxe and Collector's Editions alongside a 7-inch vinyl record with music by game's composer Bear McCreary, the Falcon, Bear and Wolf Pin Set, the Legendary Draupnir ring, Brok's Dice Set and the Yggdrasil Cloth Map.

While not part of any special edition, Sony announced another God of War Ragnarök limited edition item, a DualSense controller with a very cool design. The controller will release on the same day the game does, on November 9th, 2022.

Genre, Setting, Mechanics

Taking place roughly three years after the previous game, God of War Ragnarök will see Kratos and his son Atreus traveling through all the Nine Realms of Norse mythology (unlike the 2018 game, which only included six of the Realms) at the end of Fimbulwinter (the final Winter lasting three years which precedes Ragnarök) to prevent the apocalyptic event from happening. Meeting up with Tyr, the Norse God of War who was previously thought dead, the Greek God and his son will also have to confront other deities, such as Thor, the God of Thunder who's out for revenge, as is Freya, the Vanir Goddess who previously helped Kratos and Atreus reach Jotunheim. Thor is upset due to the deaths of his sons Modi and Magni, while Freya turned against Kratos and Atreus after they were forced to kill her son Baldur. Of course, given the background story, the two will likely have to deal with Odin Allfather and Fenrir, too. We already know that the game will mark the finale of the Norse saga, as the developers did not want to drag on the story for another five years that would be required to make a third game.

On the surface, God of War Ragnarök will not play too differently from its third-person action-adventure predecessor, so players will have to traverse a variety of locations, solve puzzles and defeat all sorts of powerful enemies using the Leviathan Axe and Kratos' signature Blades of Chaos. However, the previous game's experience will be expanded with plenty of new mechanics, such as the ability to infuse with ice and fire elements the Leviathan Axe and the Blades of Chaos, respectively, multiple shield types with different properties, and jumping attacks. Puzzles and traversal will also be expanded considerably, as Kratos will have to use his weapons more to explore some of the new worlds, such as Svartalfheim. Among the new abilities of Kratos' weapons, there is the ability to freeze geysers, dismantle pots, and more. Atreus will also be more involved in puzzle-solving situations.

God of War Ragnarök will feature over 60 accessibility options that will make the game enjoyable for all types of players, as well as two different display modes on PlayStation 5, which will let players run the game at 4K resolution and 30 frames per second or dynamic 4K resolution and 60 frames per second.

Trailers

As mentioned above, God of War Ragnarök has been originally teased during the PlayStation 5 showcase event in September 2020. The teaser did not even confirm the game's title but suggested that it would be Ragnarök.

The first proper look at God of War Ragnarök came with the PlayStation Showcase 2021 trailer, which finally showed the game in action and confirmed its final name.

The God of War Ragnarök Father and Son cinematic trailer was very light on gameplay, but it still got fans excited, as it confirmed the game's November 9th release date.

Another new look at God of War Ragnarök has been provided by the September State of Play story trailer, which showed how high the stakes are in Kratos and Atreus' new adventure.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/scorn-everything-you-need-to-know/,Scorn – Everything You Need to Know About This Long-Overdue Atmospheric First-Person Horror Adventure,"Product Info Scorn October 14th, 2022 Platforms PC, Xbox Series S|X Publisher Kepler Interactive Developer Ebb Software Expected Price $39.99 Expected Release Date October 14th, 2022

Officially announced as a Kickstarter project in 2014, Scorn is being developed by Serbian developer Ebb Software and inspired by the works of visual artists Zdzisław Beksiński and H. R. Giger. Following the failed Kickstarter campaign, the atmospheric first-person horror adventure received private funding in 2015 before getting another Kickstarter campaign in 2017. This time around, the game reached its funding goal in September 2017, beginning its long journey towards release.

Pricing, platforms, release date

Scorn is coming to PC via Steam and the Epic Games Store, Xbox Series X|S, and day one on Xbox Game Pass on October 14th, 2022, having just been bumped up from the previous October 21st date.

On both PC and Xbox Series, the Standard Edition will sell for $39.99. However, there is currently a 10% pre-order discount that brings the price down to $35.99. There is also a Deluxe Edition priced at $49.99 ($45.99 with the aforementioned discount), coming with the official digital soundtrack of the game, composed by Aethek & Lustmord, and a 192-page digital artbook including a massive amount of exclusive artwork and research designs.

It is unclear whether the console exclusivity deal is timed or not; either way, a PlayStation 5 version of Scorn hasn't been confirmed just yet.

Setting

Set in a nightmarish universe of weird forms and bleak tapestry, Scorn was designed around the idea of “being thrown into the world”. According to the developer, players won’t be taking control of an already fleshed-out main character with a predetermined personality and history. Instead, it will be up to the player to give their own interpretation of the events, themes, and their role in this universe through exploration and interaction with the game world. The story and themes that the game tries to convey get their desired effect through experience rather than exposition.

Gameplay Mechanics

Scorn takes place in an open-ended, cohesive world with different interconnected zones you can explore in a non-linear way. Each zone is a maze-like area with various rooms and paths to discover. The environment itself is a character. Every location contains its own theme (story), puzzles, and characters that are an integral part of the setting. Players will progressively open up new areas of the game, acquiring different skill sets and various items.

Ebb Software also implemented full body awareness features so that the player would experience better immersion by being aware of the character’s body and movement. Interaction with the world is said to be realistic: objects are picked up with your hands (instead of just floating in midair), machines and instruments are operated by grabbing the controls, et cetera.

Scorn also completely foregoes any form of Heads-Up Display (HUD) for greater immersion into the world. As such, everything is implied and indicated through environmental design.

Another key aspect of the gameplay mechanics is the importance of inventory and ammo management. Ebb Software said it plays a big role in keeping the player in an even greater state of awareness throughout the whole game. Players will have to think about when to fight and when to take cover, and how their actions affect the world around them. Different play styles will be needed to advance.

The developers also offered an estimate of the game's length, which is expected to range between six and eight hours.

Technical Specifications

Down below, you'll find both the minimum and recommended PC system requirements. The game will also be released on Xbox Series X|S. On both platforms, Scorn will support Microsoft's DirectStorage API.

MINIMUM: Requires a 64-bit processor and operating system OS: Windows 10 Processor: QuadCore AMD Ryzen 3 3300X / Intel Core i5-8400 Memory: 8 GB RAM Graphics: NVIDIA GeForce GTX 1060 (3 GB) DirectX: Version 12 Storage: 50 GB available space Additional Notes: SSD (Solid State Drive).

RECOMMENDED: Requires a 64-bit processor and operating system OS: Windows 10/11 Processor: AMD Ryzen 5 3600／Intel Core i7-8700 Memory: 16 GB RAM Graphics: NVIDIA GeForce RTX 2070 (8 GB) DirectX: Version 12 Storage: 50 GB available space Additional Notes: SSD (Solid State Drive).



Trailers

Since the game's official announcement in 2014, various trailers have been released, including the Kickstarter trailer and the 2016 teaser trailer. Upon the announcement that Scorn would also be coming to Xbox Series, several new videos were shared. Last year, the game received a release date reveal trailer. The most recent trailer, featuring 8 minutes of gameplay from the prologue, was released earlier this month.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-x670e-x670-motherboards-asus-asrock-msi-gigabyte-biostar/,"AMD X670E & X670 Motherboards Roundup Ft. ASUS, ASRock, MSI, Gigabyte, Biostar","Product Info AMD AM5 Motherboards 15th September 2022 Manufacturer ASUS, MSI, Gigabyte, ASRock, Biostar Type Motherboards Platforms AMD AM5 For Ryzen 7000 CPUs Expected Price $200-$1000US+ Expected Release Date 15th September 2022

Today, we will be taking a deep dive and rounding up all the AMD X670E & X670 motherboards from ASUS, ASRock, MSI, Gigabyte & Biostar.

AMD X670E & X670 Motherboards Deep Dive, Featuring ASUS, ASRock, MSI, Gigabyte, Biostar

[Updated - 20/08/22]

AMD and its board partners which include ASUS, ASRock, MSI, Gigabyte, and Biostar put out some really detailed specifications of their upcoming X670E & X670 motherboards during the ""Meet The Experts"" Livestream. We thought that since we have a little over a month left in the launch, we should be providing you with a deeper dive into what every single board has on offer.

AMD AM5 Platform - A New Beginning

Before we talk motherboards, we have to talk about the platform itself. The AMD Ryzen 7000 CPUs will be migrating to a new home known as AM5, the successor to the long-lasting AM4 platform. It marks a fresh start for the AMD Ryzen Desktop family and as such, existing Ryzen CPUs starting with Ryzen 1000 & all the way up to Ryzen 5000 won't be supported by the new platform we will tell you why it is so.

The AM5 platform will first and foremost feature the brand new LGA 1718 socket. That's correct, AMD isn't going the PGA (Pin Grid Array) route anymore and now focusing on LGA (Land Grid Array), similar to what Intel uses on its existing desktop processors. The main reason to go LGA is due to the addition of enhanced and next-gen features such as PCIe Gen 5, DDR5, etc that we will get to see on the AM5 platform. The socket has a single latch & gone are the days of worrying about pins underneath your precious processors.

In terms of features, the AM5 platform will initially support AMD's Ryzen 7000 'Zen 4' Desktop CPUs and extend that support to future Ryzen CPUs and APUs. The platform offers DDR5-5200 (JEDEC) memory support, up to 28 PCIe lanes (Gen 5 standard), increased NVMe 4.0, and USB 3.2 I/O lanes & we have also heard chatter about native USB 4.0 support which will be a game-changer.

A new feature called EXPO (AMD Extended Profiles for overclocking) will allow enhanced DDR5 memory OC on the new platform, similar to Intel's XMP. It has been a rough road for AM4 to offer decent DDR4 OC capabilities but that has more or less been sorted out by now, we can only expect DDR5 to have a much better OC and compatibility experience compared to DDR4 on AM4 platforms. Furthermore, it looks like the platform will only be DDR5 compatible and we won't see DDR4 options as we do on Intel's existing platform. But with DDR5 prices and availability improving, that won't be that big of a deal for most high-end consumers for who AMD will be aiming first.

AMD X670 Series Platform

The AM5 compliant AMD 600-series motherboards are currently being prepped up by the board makers, The 600-series lineup will initially consist of three chipsets, the X670E, X670, B650E, and B650.

In terms of features, the X670E (Extreme) is designed for the higher-echelon of motherboards with unparalleled capabilities, and extreme overclocking, and will have PCIe 5.0 support for both GPU and storage.

The X670 motherboards will be very similar in offering enthusiast-level overclocking but PCIe Gen 5.0 support for storage and graphics will depend on manufacturers. It is likely that some board makers will go to the cost-effective route and enable PCIe 5.0 support only for the GPU while keeping storage limited to PCIe 4.0. Both X670 chipsets will come in a dual-PCH solution on the motherboard to allow for the increased I/O for the next-gen platform.

One of the highlighted features of the AMD AM5 600-series platform is SAS or Smart Access Storage. This technology will enable GPU decompression with supported Microsoft DirectStorage games. Although there aren't many of those out there yet but expect industry-wide support for this on newer platforms.

As for longevity, AMD hasn't promised anything but they have stated that they want to see the new AM5 socket last at least four to five years, similar to AM4. While there has been a lot of controversy regarding Ryzen support on the initial AM4 motherboards, I believe that AMD has learned and will not follow the same route with AM5.

2 of 9

AMD Chipset Features and Specifications:

Wccftech X670E/X670 B650E/B650 A620 X570 X399 Refresh X399 X470 X370 B450 B350 A320 X300 A300 CrossfireX/SLI 2-Way CFX 2-Way CFX N/A Triple CFX/2-Way SLI Quad SLI/CFX

(Max 6 GPU Support) Quad SLI/CFX

(Max 6 GPU Support) Triple CFX/2-Way SLI Triple CFX/2-Way SLI N/A N/A N/A N/A N/A CPU Lanes 24 Gen 5 (with Ryzen 7000 CPUs & above) 24 Gen 5 (with Ryzen 7000 CPUs & above) 24 Gen 4 (with Ryzen 7000 CPUs & above) N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A PCH Lanes 12 Gen 4

8 Gen 3 8 Gen 4

4 Gen 3 8 Gen 3 30 +16 (with Ryzen 7 CPU) 60 (With Threadripper CPU)

4 Lanes Reserved for PCH 60 (With Threadripper CPU)

4 Lanes Reserved for PCH 16 (with Ryzen 7 CPU) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) 16 (with Ryzen 7 CPU)

8 (with Bristol Ridge) PCIe Gen 2 Lanes N/A N/A N/A N/A 8 PCIe Lanes (reserved) 8 PCIe Lanes (reserved) 8 (plus x2 PCIe Gen3 when no x4 NVMe) 8 (plus x2 PCIe Gen3 when no x4 NVMe) 6 (plus x2 PCIe Gen3 when no x4 NVMe) 6 (plus x2 PCIe Gen3 when no x4 NVMe) 4 (plus x2 PCIe Gen3 when no x4 NVMe) 4 (plus x2 PCIe Gen3 when no x4 NVMe) 4 (plus x2 PCIe Gen3 when no x4 NVMe) USB 3.1/3.2 Gen2 2 1 0 8 2 2 2 2 2 2 1 0 0 USB 3.1/3.2 Gen1 12 6 2 12 (PCH + CPU) 13 (PCH+CPU) 13 (PCH+CPU) 10 10 6 6 6 4 4 USB 2.0 8 6 6 N/A 6 6 6 6 6 6 6 0 0 SATA 6Gb/s 8 4 4 8 8 8 6 6 4 4 4 2 2 SATA Express N/A N/A N/A 2 2 2 2 2 2 2 2 1 1 DDR5 DIMMs 4 4 4 N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A DDR4 DIMMs N/A N/A N/A 4 8 8 4 4 4 4 2 2 2 Overclocking

Support Yes Yes N/A Yes Yes Yes Yes Yes Yes Yes No Yes No XFR2 Enhanced Yes Yes N/A Yes Yes No Yes No Yes No No No No Precision Boost Overdrive Yes Yes N/A Yes Yes No Yes No Yes No No No No NVMe Yes (Gen 5.0) Yes (Gen 5.0) N/A Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Form Factor ATX/mATX/ITX ATX/mATX/ITX mATX/ITX ATX, MATX ATX, MATX ATX, MATX ATX, MITX ATX ATX, M-ATX ATX, M-ATX M-ATX, Mini-ITX Mini-ITX M-ATX, Mini-ITX

ASUS X670E & X670 Motherboards

Starting with ASUS, the company is planning to offer at least six motherboards within its ROG, ROG Strix, TUF Gaming, ProArt, and Prime families. The lineup comes with Dynamic OC Switcher which we detailed here. The motherboards that we are able to confirm so far include:

ASUS ROG Crosshair X670E Extreme

ASUS ROG Crosshair X670E HERO

ASUS ROG STRIX X670-E WIFI Gaming

ASUS PRIME X670E-PRO WiFi

ASUS TUF Gaming X670-PLUS WiFi

ASUS ProArt X670-Creator WiFi

So with the motherboards out of the way, let's take a look at the individual specs and features that each product has to offer.

ASUS ROG Crosshair X670E Extreme

ASUS's top X670E motherboard is the ROG Crosshair X670E Extreme. This motherboard is designed to be the ultimate ROG offering and comes with a powerful power delivery solution that comprises 22 (20+2) Teamed Power Stages rated at 110A, an Infineon ASP2205 PWM controller, & the Vishay SIC850 Power Stages. The Alloy Chokes are rated at 45A while the capacitors are rated at 10K hours with a maximum temperature threshold of up to 125C. The AM5 socket is powered by an 8-pin pair which should allow for over 1000W of power to the Ryzen CPU itself.

The motherboard features four DDR5 DIMM slots which will be able to support AMD's EXPO tech and up to 128 GB capacities. There are several handy features such as Power On/Off, Reset and even a FlexKey button underneath the DEBUG LED. As for the overall layout, the motherboard is just as beautiful as one should expect with black color heatsinks and cover over the VRM, PCH & M.2 slots while also providing an AniMe Matrix LED display over the PCH heatsink and I/O cover.

2 of 9

Expansion slots include two PCIe 5.0 x16 and a single PCIe 4.0 x4 slot. The board can house up to five M.2 devices with two Gen 5.0 x4 onboard the motherboard itself, one from the PCIe Gen 5.0 M.2 card (Gen 5.0 x4) and two M.2 slots (1x Gen 5 x4 & 1x Gen 4 x4) on the ROG Zen-Z.2 add-on DIMM. The board also offers a total of 6 SATA III ports. The motherboard has a right-angled ATX power connector and also comes with an additional 6-pin connector for USB Type-C 60W power delivery (which offers 27W without the connection). You'll find an ample amount of I/O features such as WiFi 6E, 10Gb / 2 Gb Ethernet LAN ports, USB 4.0 ports, and premium audio capabilities, just to name a few. Of course, the motherboard will come at a premium and we are talking over $600 US easily.

ASUS ROG Crosshair X670E HERO

The next ASUS ROG motherboard that has been confirmed so far is the Crosshair X670E HERO which is a tamer version of the Extreme and is likely to be priced in the $400-$500 US range. It comes with an 18+2 phase teamed VRM design and uses similar components as the Extreme. It also offers a high-end heatsink and design layout with a Polymo Lighting system embedded over the I/O shield. As for expansion slots, the board offers two PCIe Gen 5.0 x16 and a single PCIe 4.0 x2 slot. The motherboard is listed to support 5 M.2 slots which include two Gen 5.0 x4 (1 with PCIe 5.0 M.2 card), and three Gen 4.0 x4 slots. Storage options include 6 SATA III ports.

2 of 9

The motherboard comes with a single 2.5 GbE LAN port, two USB 4.0 ports, tons of USB 3.2 Gen 2 ports, WiFi 6E capabilities, and a high-end audio interface.

ASUS ROG STRIX X670-E WiFi Gaming

The ASUS ROG STRIX X670-E WiFi Gaming adopts a 16-phase power design and comes with a gaming aesthetic with black and grey color tones. The I/O cover has a small LCD that could be customized according to your preferences. The expansion slots include two PCIe 5.0 x16 and a single PCIe Gen 4.0 x16 slot. M.2 options should include three PCIe Gen 5.0 x4 slots & a single PCI-E Gen 4.0 x4 slot. The primary M.2 heatsink looks like it uses a heatpipe-based cooling solution. The storage options include four SATA III ports and there's a vast array of I/O available to users too.

ASUS PRIME X670E-PRO WiFI

ASUS's PRIME X670-E PRO WiFi also seems to be equipped with a 16-phase power delivery that is juiced up through a dual 8-pin connector configuration. We can see the PRIME series back with its unique white and black aesthetic in a futuristic layout. The board features three M.2 heatsinks that support a single PCIe Gen 5.0 x4 and three PCIe Gen 4.0 x4 SSDs. There are two PCIe Gen 5.0 x16 slots and a single PCIe Gen 4.0 x4 slot. There are also four SATA III ports on the motherboard.

ASUS TUF Gaming X670-PLUS WIFI

The ASUS TIF Gaming X670-PLUS WiFI seems to retain the 16-phase design but it is also the only motherboard from the bunch that has one exposed M.2 slot with no heatsink. It is likely that this one is a non-Gen 5.0 port. With that said, there are three PCIe Gen 4.0 x4 M.2 slots and a single PCIe Gen 5.0 x4 slot. PCIe expansion slots include two Gen 5 x16 and a single Gen 4 x4 slot. The TUF Gaming motherboards feature a grey and yellow-colored aesthetic and this board is no different.

ASUS ProArt X670-Creator WiFi

The ASUS ProArt X670-Creator WiFi motherboard features a 16-phase power delivery with a nice acrylic I/O cover, aluminum heatsinks, and an industrial design with its silver and grey aesthetics.

It comes with three PCIe 5.0 x16 slots (x8/x8/x4 electrical) and features two PCIe Gen 5.0 x4 and one PCIe Gen 4.0 x4 slot. The motherboard supports up to 4 SATA III storage devices and comes with a WiFi 6E interface. There's also a 6-pin connector for 60W USB Type-C charging.

2 of 9

ASUS X670E & X670 Motherboard Specs

Motherboard Name ROG Crosshair X670E Extreme ROG Crosshair X670E HERO ROG Crosshair X670E Gene ROG STRIX X670E-I Gaming WIFI ROG STRIX X670-E WIFI Gaming PRIME X670E-PRO WiFi TUF Gaming X670E-PLUS WiFi ProArt X670E-Creator WiFi Chipset X670E X670E X670E X670E X670E X670E X670E X670E Form Factor E-ATX ATX mATX mITX ATX ATX ATX ATX PCB Color Black Black Black Black Black Black Black Light Black Motherboard Color Black + Silver Black + Silver Black + Silver Black + Silver Black + Grey White + Black Black + Grey Silver + Gray VRM Design 20+2 Phase 18+2 Phase 16+2 Phase 10+2 Phase 16 Phase (TBD) 16 Phase (TBD) 16 Phase (TBD) 16 Phase (TBD) VRM Heatsink Yes Yes Yes Yes (Active Cooled) Yes Yes Yes Yes PWM Controller Infineon ASP2205 Infineon ASP2205 Infineon ASP2205 Infineon ASP2205 TBD TBD TBD TBD Power Stages 110A 110A 110A 110A TBD TBD TBD TBD Power Delivery (CPU) 8+8 Pin 8+8 Pin 8+8 Pin 8 Pin 8+8 Pin 8+8 Pin 8+8 Pin 8+8 Pin Memory DIMMs 4 DDR5 DIMM 4 DDR5 DIMM 2 DDR5 DIMM 2 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM Memory Support DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) Memory Capacity 128 GB (Max) 128 GB (Max) 64 GB (Max) 64 GB (Max) 128 GB (Max) 128 GB (Max) 128 GB (Max) 128 GB (Max) PCIe Gen 5.0 Slots 2 2 1 1 2 2 2 2 PCIe Gen 4.0 Slots 1 1 1 0 1 1 1 1 M.2 Gen 5.0 Slots 4 3 2 1 3 1 1 2 M.2 Gen 4.0/3.0 Slots 1 2 1 1 1 2/1 2/1 2 M.2 Heatsinks Yes (All) Yes (All) Yes (All) Yes (All) Yes (All) Yes (All) Yes (All) Yes (3 Heatsinks) SATA III Ports 6 6 4 2 4 4 4 4 WiFi Capabilities WiFi 6E WiFi 6E WiFi 6E WiFi 6E WiFi 6E WiFi 6E WiFi 6E WiFi 6E LAN Capabilities 10 GbE LAN

2.5 GbE LAN 2.5 GbE LAN 2.5 GbE LAN 2.5 GbE LAN 2.5 GbE LAN 2.5 GbE LAN 2.5 GbE LAN 10 GbE LAN

2.5 GbE LAN USB 4.0 Ports 2 2 2 2 0 0 0 2 USB 3.2 Ports 16 11 9 9 16 13 13 11 USB 3.1/3.0/2.0 Ports 4 6 6 7 6 6 6 7 RGB Sync Software ASUS Aura Sync ARGB Gen 2 ASUS Aura Sync ARGB Gen 2 ASUS Aura Sync ARGB Gen 2 ASUS Aura Sync ARGB Gen 2 ASUS Aura Sync ARGB Gen 2 ASUS Aura Sync ARGB Gen 2 ASUS Aura Sync ARGB Gen 2 ASUS Aura Sync ARGB Gen 2 Price $999 $699 $599 $469 $499 $349 $329 $499

MSI X670E & X670 Motherboards

MSI will be rolling out four brand new X670E Motherboards within its MEG, MPG, and PRO lineups. We recently revealed their flagship MEG X670E GODLIKE motherboards and the manufacturer has confirmed the specs and PCB we reported. All MSI X670 & B650 motherboards also come with the new ""Performance Switch"" feature that we detailed here. MSI's X670E motherboard lineup is as listed below:

MSI MEG X670E GODLIKE

MSI MEG X670E ACE

MSI MPG X670E Carbon

MSI PRO X670E-P WiFI

So with the motherboards out of the way, let's take a look at the individual specs and features that each product has to offer.

2 of 9

MSI MEG X670E GODLIKE Motherboard - The Flagship To Rule Them All!

Starting with the flagship, first, we have to talk about the size of this monster of a motherboard. The MSI MEG X670E GODLIKE will measure 305mm x 288mm. That's slightly smaller than the MEG Z690 GODLIKE but it will definitely be one of the biggest and baddest motherboards out there, one that every other manufacturer will be keeping a close eye on as they try to tackle it with their own X670E flagships.

Support For AMD Ryzen 7000 Desktop CPUs (AM5) Socket

24+2+1 Phase (105A) CPU VRM Design

Dual 8-Pin Power Connectors For CPU

Four DDR5 DIMM Slots (Up To 128 GB Capacities)

EXPO Support With DDR5-5600+ Memory Support

10 Layer & 2 Oz Copper PCB Design

Three x16 PCIe Gen 5 Slots (x16/x8/x8 Electrical)

Four M.2 Slots (1x Gen 5, 3x Gen 4)

M.2 Shield Frozr Heatsinks For M.2 Slots

Steel Reinforced PCIe and Memory Slots

Dual X670E ""Promontory"" PCH Dies

8 SATA III Ports, Dual USB 3.2 Type-C Gen 2 Ports (With 60W PD Charging0

Dual Front Panel USB 3.0 Headers

In terms of power delivery, the motherboard seems to feature at least 24+2+1 phases with 105A MOSFETs. Power to the CPU is provided through dual 8-pin connectors, a 24-pin ATX connector for the motherboard, one 6-pin power connector (at the bottom) for the PCIe lanes, and one 6-pin PD power connector (next to the 24-pin ATX connector) to deliver PD 60W charging for the front USB 3.2 Gen2x2 20Gbps Type C connector. You can also note the dual X670E PCH's taking up a good amount of room on the motherboard.

There are four DDR5 memory slots on the MSI MEG X670E GODLIKE motherboard that will support up to 128 GB capacities and while we don't know the speeds for them yet, the native JEDEC speeds for Ryzen 7000 ""Raphael"" CPUs are set at DDR5-5600 so we can expect over 6/7 Gbps transfer rates with EXPO support. The board is powered by dual 8-pin connectors located close to the DDR5 slots for easy cable management.

There are also placements for several OC-specific features on the board such as Power On/Off and reset switches at the bottom. Storage options include 8 SATA III ports while expansion slots include three PCIe Gen 5.0 x16 (x16/x8/x4 electrical) that run at either x16/x0/x4 or x8/x8/x4 modes.

There are at least four M.2 slots on the MSI MEG X670E GODLIKE motherboard which include a single PCIe Gen 5 x4 running off the Raphael CPU lanes, and three Gen 4 x4 slots running off the Promontory PCH. The motherboard will also ship with a brand new M.2 XPANDER-Z Gen 5 Dual add-in-card which supports up to two 25110 PCIe Gen 5.0 x4 SSDs.

There are also two USB 3.2 Gen 2 front panel headers (Type-C with 60W power deliver & 20Gb/s) on the motherboard too. MSI's top-tier X670E motherboards will come with a brand new M.2 SSD installation design as a part of its ""M.2 Shield Frozr"" technology and there will also be magnetic locks next to the M.2 ports. The magnetic locks will provide a connection to the RGB LEDs that are featured on the Shield Frozr heatsinks for M.2_2, M.2_3, and M.2_4 ports. There are also tons of fans (+ pump), RGB, and external headers on the motherboard.

MSI MEG X670E ACE Motherboard - Enthusiast-Tier Design With A Pinch of Gold!

The MSI MEG X670E ACE motherboard was one of the units that the 'MSI Insider team showcased during the webcast. Before talking more about it, let's list down its primary features:

Stacked fin-array heatsink with heat-pipe

22+2 phases / 90A power stages

Lightning Gen5 slot & M.2 support

Screwless M.2 Shield Frozr

M.2 Shield Frozr with magnetic design

Onboard 10G LAN with WIFI 6E

Front USB Type-C supports PD 60W

The MSI MEG X670E ACE motherboard features a very large heatsink with a finned design & it also comes with several M.2 Shield Frozr heatsinks. The most interesting is the one next to the DDR5 DIMM slots which have a tool-less installation design and can easily be removed and latched in to place with a special knob mechanism.

MSI MPG X670E Carbon WIFI Motherboard - An All-Rounder With High-End I/O

MSI has also given the X670E treatment to its next CARBON WIFI motherboard. This means we will be getting the same PCIe Gen 5 support for storage and graphics on this motherboard too. Listed features include:

Extended Heatsink with heat-pipe

18+2 phases / 90A power stages

Lightning Gen 5 slot & M.2 support

Screwless M.2 Shield Frozr

Onboard 2.5G LAN & WIFI 6E

USB Type-C supports up to DP 2.0

MSI PRO X670-P WIFI - Entry Into The X670 Segment With Quality Features!

Finally, we have the MSI PRO X670-P WIFI which combines stable functionality with high-quality assembly. Now one thing that MSI has told is that the X670E class motherboards will come with a 10-layer PCB design while the X670 motherboards will come with up to 8-layer PCBs. We know that the X670E class motherboards need those increased server-quality PCB layers to maintain the Gen 5.0 signal integrity for both discrete GPUs and storage. Since the X670 motherboard doesn't have to offer both dGPU and M.2 Gen 5 support, they can do away with 8-layers which is still a high-end PCB design. The main features of the motherboard include:

Extended Heatsink Design

14+2 phases / 80A SPS stages

Lightning Gen 5 M.2 support

1x Double-side M.2 Shield Frozr

Onboard 2.5G LAN & WIFI 6E

USB Type-C supports up to DP 2.0

MSI X670E & X670 Motherboard Specs

Motherboard Name MSI MEG X670E GODLIKE MSI MEG X670E ACE MSI MPG X670E Carbon MSI PRO X670E-P WiFi Chipset X670E X670E X670E X670E Form Factor E-ATX E-ATX ATX ATX PCB Color Black Black Black Black PCB Layers 10 Layer 10 Layer 8 Layer 8 Layer Motherboard Color Black + White + Gold Black + Gold Black Black + White VRM Design 24+2+1 (105A) 22+2+1 (90A) 18+2+1 (90A) 14+2+1 (80A) VRM Heatsink Wavy Fin / Cross heat-pipe / MOSFET backplate Stacked Fin Array / Direct Touch Heat Pipe / MOSFET Baseplate Extended Heatsink with Heatpipe Extended Heatsink PWM Controller TBD TBD TBD TBD Power Stages TBD TBD TBD TBD Power Delivery (CPU) 8+8 8+8 8+8 8+8 Memory DIMMs 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM Memory Support DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) Memory Capacity 128 GB (Max) 128 GB (Max) 128 GB (Max) 128 GB (Max) PCIe Gen 5.0 Slots 3 (x8/x4/x4) 3 (x8/x4/x4) 2 (x16/x8) 0 PCIe Gen 4.0/3.0 Slots 1 (x16) 0 1 (x16) 3 (x8/x4/x4) / 1 (x1) M.2 Gen 5.0 Slots 1 1 2 1 M.2 Gen 4.0 Slots 3 3 2 3 M.2 Heatsinks M.2 Shield Frozr Heatsinks M.2 Shield Frozr Heatsinks M.2 Shield Frozr Heatsinks M.2 Shield Frozr Heatsinks SATA III Ports 8 6 6 6 WiFi Capabilities WiFi 6E WiFi 6E WiFi 6E WiFi 6E LAN Capabilities 1 x 10 GbE (Marvell AQtion)

1 x 2.5 GbE (Intel I225V) 1 x 10 GbE (Marvell AQtion) 1 x 2.5 GbE (Realtek 8125B) 1 x 2.5 GbE (Realtek 8125B) USB 4.0 Ports 0 0 0 0 USB 3.2 Ports 15 17 13 13 USB 3.1/3.0/2.0 Ports 4 4 6 4 RGB Sync Software MSI Mystic Light MSI Mystic Light MSI Mystic Light MSI Mystic Light Price $1299 US $799 US $499 US $329 US

ASRock X670E & X670 Motherboards

Initially, ASRock will be launching five new X670E motherboards for the AMD Ryzen 7000 Desktop CPU family. Each motherboard will be placed within its own segment which includes the CARRARA Taichi, Standard Taichi, Phantom Gaming, Steel Legend, and Pro Series lineup. ASRock X670 & B650 motherboards support the latest Blazing OC Tuner software which we detailed here. Following are the motherboards to expect from ASRock:

ASRock X670E Taichi Carrara

ASRock X670E Taichi

ASRock X670E Steel Legend

ASRock X670E Pro RS

ASRock X670E PG Lightning

So with the motherboards out of the way, let's take a look at the individual specs and features that each product has to offer.

ASRock X670E Taichi Carrara

The ASRock X670E Taichi Carrara is a special edition motherboard, designed to celebrate the 20th Anniversary of ASRock, Taichi Carrara resembles the high strength as well as the esthetic of Carrara marble, they are also the key elements while developing this motherboard. The motherboard has a high-end 26-Phase SPS Dr.MOS power delivery and features four DDR5 DIMM slots supporting up to 128 GB capacities and overclocked (EXPO) profiles up to DDR5-6600+(OC). The CPU socket is powered by a dual 8-pin connector configuration.

2 of 9

Expansion slots include two PCIe Gen 5.0 x16 slots (x16/x8 electrical), a single PCIe Gen 5 x4, and three PCIe Gen 4 x4 M.2 slots, all of which are covered by large metallic heatsinks. There are also eight SATA III ports. I/O includes 5 USB 3.2 Gen 2 Type-A, 7 USB 3.2 Gen 1, and dual USB 4 ports. It also comes with WiFi 6E capabilities and a 2.5 GbE Ethernet LAN port.

Specification

Supports Ryzen 7000 series processors (AM5)

26 Phase SPS Dr.MOS Power Design

Supports DDR5 Memory (DDR5-6600+ OC)

1 PCIe 5.0 x16, 1 PCIe 5.0 x8

Graphics Output Options: HDMI

Realtek ALC4082 7.1 CH HD Audio Codec, ESS SABRE 9218 DAC, WIMA Audio Caps

8 SATA3, 1 Blazing M.2 (PCIe Gen5 x4), 2 Hyper M.2 (PCIe Gen4 x4), 1 Hyper M.2 (PCIe Gen4 x4 & SATA3)

2 Thunderbolt™ 4/USB4 Type-C, 1 Front USB 3.2 Gen2x2 Type-C

5 Rear USB 3.2 Gen2 Type A, 7 USB 3.2 Gen1 (3 Rear, 4 Front)

Killer E3100G 2.5G LAN, Killer AX1675X 802.11ax (WiFi 6E) + Bluetooth

Killer DoubleShot Pro

Lightning Gaming Ports

ASRock X670E Taichi

The ASRock X670E Taichi shares the same design as the Carrara offering. Both motherboards are equipped with many exciting features and new technology such as PCIe 5.0 & DDR5 capability, the insane IO capability including the support of Thunderbolt 4.0 has pushed the X670 platform even further into a high-end desktop category, and ASRock went all out on the VRM design too, with a total of 26 phases SPS Dr.MOS design on the X670E Taichi, it is the most powerful AM5 product ASRock can offer.

Besides the color difference, I expect the standard Taichi to cost a bit lower considering the other model is more of a collectible item.

2 of 9

Specification

Supports Ryzen 7000 series processors (AM5)

26 Phase SPS Dr.MOS Power Design

Supports DDR5 Memory (DDR5-6600+ OC)

1 PCIe 5.0 x16, 1 PCIe 5.0 x8

Graphics Output Options: HDMI

Realtek ALC4082 7.1 CH HD Audio Codec, ESS SABRE 9218 DAC, WIMA Audio Caps

8 SATA3, 1 Blazing M.2 (PCIe Gen5 x4), 2 Hyper M.2 (PCIe Gen4 x4), 1 Hyper M.2 (PCIe Gen4 x4 & SATA3)

2 USB4 Type-C, 1 Front USB 3.2 Gen2x2 Type-C

5 Rear USB 3.2 Gen2 Type A, 7 USB 3.2 Gen1 (3 Rear, 4 Front)

Killer E3100G 2.5G LAN, Killer AX1675X 802.11ax (WiFi 6E) + Bluetooth

Killer DoubleShot Pro

Lightning Gaming Ports

ASRock X670E Steel Legend

The ASRock X670E Steel Legend is supposed to be another strong mainstream offering with an 18 Phase SPS design and a range of features such as PCIe Gen 5.0 expansion slots, M.2 ports, and also several Gen 4 ports. The board features dual LAN capabilities with a 2.5 GbE and a 1 GbE Ethernet connection. The motherboard should end up around the $300-$350 US price range.

2 of 9

Specification

‧AMD X670 Chipset

‧18 Phase SPS Dr.MOS Power Design

‧Supports DDR5 Memory (DDR5-6600+ OC)

‧1 PCIe 5.0 x16, 1 PCIe 4.0 x4

‧Graphics Output Options: HDMI, DisplayPort

‧Realtek ALC1220 7.1 CH HD Audio Codec, Nahimic Audio

‧4 SATA3, 1 Blazing M.2 (PCIe Gen5 x4), 3 Hyper M.2 (PCIe Gen4 x4)

‧Front + Rear USB 3.2 Gen2x2 Type-C

‧1 Rear USB 3.2 Gen2 Type A, 10 USB 3.2 Gen1 (6 Rear, 4 Front)

‧Dragon 2.5Gbps LAN, Intel 1Gbps LAN, 802.11ax (WiFi 6E) + Bluetooth

ASRock X670E Pro RS

The ASRock X670E Pro RS seems to be an entry-level offering that should be priced around the $250-$300 US segment. It will come with a 16 Phase VRM and features a nice gunmetal silver & black aesthetic. The motherboard also offers PCIe Gen 5.0 expansion and M.2 slots. I/O includes WiFi 6E capabilities and a Dragon 2.5 GbE LAN port with tons of USB ports to work with.

2 of 9

Specification

‧AMD X670 Chipset

‧16 Phase SPS Dr.MOS Power Design

‧Supports DDR5 Memory

‧1 PCIe 5.0 x16, 2 PCIe 4.0 x1

‧Graphics Output Options: HDMI, DisplayPort

‧Realtek ALC897 7.1 CH HD Audio Codec, Nahimic Audio

‧6 SATA3, 1 Blazing M.2 (PCIe Gen5 x4)

‧3 Hyper M.2 (PCIe Gen4 x4), 1 M.2 (PCIe Gen3 x2/SATA)

‧Rear USB 3.2 Gen2x2 Type-C, Rear USB 3.2 Gen2 Type A+C

‧8 USB 3.2 Gen1 (4 Rear, 4 Front)

‧Dragon 2.5Gbps LAN

ASRock X670E PG Lightning

Lastly, we have the ASRock X670E PG Lightning which is one board that the manufacturer hasn't shown off much. The board is the most entry-level solution but still offers an 18 Phase VRM with an 8+4 pin CPU power connector configuration. It carries a single PCIe Gen 5.0 x16 and Gen 5.0 x4 M.2 slot and comes with the most basic I/O that would want on a motherboard. Since ASRock doesn't have the product page live yet, we can't tell the exact number of USB ports or I/O capabilities but it definitely lacks WiFi 6E.

2 of 9

ASRock X670E & X670 Motherboard Specs

Motherboard Name ASRock X670E Taichi Carrara ASRock X670E Taichi ASRock X670E Steel Legend ASRock X670E Pro RS ASRock X670E PG Lightning Chipset X670E X670E X670E X670E X670E Form Factor E-ATX E-ATX ATX ATX ATX PCB Color Black Black Black White (Camo) Black Grey (Texture) Black Grey (Texture) PCB Layers 8-Layer 8-Layer 8-Layer 8-Layer 8-Layer Motherboard Color White Black Black Gold White Black White Black All-Black VRM Design 26 Phase SPS Dr.MOS 26 Phase SPS Dr.MOS 18 Phase SPS Dr.MOS 16 Phase SPS Dr.MOS 18 Phase SPS Dr.MOS VRM Heatsink Yes Yes Yes Yes Yes PWM Controller TBD TBD TBD TBD TBD Power Stages TBD TBD TBD TBD TBD Power Delivery (CPU) 8+8 8+8 8+8 8+4 8+4 Memory DIMMs 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM Memory Support DDR5-5600 (JEDEC)

DDR5-6600+(EXPO) DDR5-5600 (JEDEC)

DDR5-6600+(EXPO) DDR5-5600 (JEDEC)

DDR5-6600+(EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) Memory Capacity 128 GB (Max) 128 GB (Max) 128 GB (Max) 128 GB (Max) 128 GB (Max) PCIe Gen 5.0 Slots 2 (x16/x8) 2 (x16/x8) 1 (x16) 1 (x16) 1 (x16) PCIe Gen 4.0 Slots 0 0 1 (x4) 2 (x4) 3 (x4) M.2 Gen 5.0 Slots 1 1 1 1 1 M.2 Gen 4.0 Slots 3 3 3 4 2 M.2 Heatsinks Yes Yes Yes (3) Yes (3) Yes (2) SATA III Ports 8 8 6 6 4 WiFi Capabilities WiFi 6E WiFi 6E WiFi 6E WiFi 6E N/A LAN Capabilities Killer E3100G 2.5G LAN Killer E3100G 2.5G LAN Dragon 2.5Gbps LAN

Intel 1Gbps LAN Dragon 2.5Gbps LAN Dragon 2.5Gbps LAN USB 4.0 Ports 2 2 2 N/A N/A USB 3.2 Ports 13 13 13 10 TBD USB 3.1/3.0/2.0 Ports 6 (Front Panel) 6 (Front Panel) 6 (Front Panel) 6 (Front Panel) 6 (Front Panel) RGB Sync Software Polychrome Sync Polychrome Sync Polychrome Sync Polychrome Sync Polychrome Sync Price $529 $499 $299 $279 $259

Gigabyte X670E & X670 Motherboards

Gigabyte has so far revealed a total of five motherboards, four within its AORUS lineup and one within its AERO lineup. The company has already detailed the prices of its motherboards during a previous event so let's take a look at the lineup itself which includes:

Gigabyte X670E AORUS Xtreme

Gigabyte X670E AORUS Master

Gigabyte X670 AORUS Pro AX

Gigabyte X670 AORUS Elite AX

Gigabyte X670E AERO D

2 of 9

So with the motherboards out of the way, let's take a look at the individual specs and features that each product has to offer.

Gigabyte X670E AORUS Xtreme Motherboard - Around $500 US Flagship Pricing

The Gigabyte X670E AORUS Xtreme will be the first AM5 flagship from the manufacturer, featuring the AM5 (LGA 1718) socket and an 18 Phase (105A) power delivery that will deliver juice to the AMD Ryzen 7000 Desktop CPUs. The motherboard features dual 8-pin connectors and a 24-pin ATX plug while next to the socket are four DDR5 DIMM slots that feature EXPO (Ryzen Extended Profiles For Overclocking) support and will support up to 128 GB capacities.

2 of 9

In terms of I/O, the motherboard is equipped with three PCIe x16 slots (1x Gen 5 x8, 2x Gen 4 x 4) and a total of four PCIe Gen 5.0 M.2 slots. The huge number of Gen 5 M.2 slots do cut the PCIe slot bandwidth to just x8 lanes but that still provides the same amount of bandwidth as a PCIe Gen 4.0 x16 interface.

The motherboard comes with 6 SATA III ports, large aluminum fin stacks covering the VRMs, and an all-heatsink shroud for the M.2 slots plus the PCH. There's also a Marvell AQC113C chip controller that is routed through a PCIe 4.0 interface for 10 GbE Ethernet LAN along with a huge variety of I/O on the backplate which includes Q-Flash Plus and Clear CMOS buttons. There are at least 10 USB Gen 2 ports plus HDMI/DP ports for the RDNA 2 iGPU.

The AORUS X670E Xtreme motherboard is said to target a price point lower than the current X570 AORUS Xtreme at around $500 US.

Gigabyte X670E AORUS Master Motherboard - The $360 US All-Rounder

Moving to the Gigabyte X670E AORUS Master, this is among Gigabyte's best-selling high-end series which offers a balance between pricing and enthusiast-class features. The VRM is laid out in a 16+2+2 (105A) power delivery that is powered by dual 8-pin connectors. The Aluminum Fin-Array stack covers the VRMs and just like the Xtreme, the motherboard comes in an E-ATX form factor.

2 of 9

In terms of I/O, the motherboard is equipped with three PCIe x16 slots (1x Gen 5 x16, 2x Gen 4 x 4) and a total of three PCIe Gen 5.0 M.2 slots. Storage options include six SATA III ports and aesthetics look great as ever with a more industrial approach this time around with a black and metal finish on the heatsinks.

There are 12 USB (10 Gen 2) ports on the back along with a 2.5 GbE Ethernet LAN connector. Unfortunately, the addition of a third Gen 5 M.2 port means that you won't get USB 4.0 on this motherboard. Pricing is said to be similar to the X570S AORUS Master at around $360 US & which should make this board a go-to option for several high-end Ryzen 7000 PC builders.

Gigabyte X670 AORUS PRO AX Motherboard - Entry-Level X670 Class At $300 US

The Gigabyte X670 AORUS PRO AX motherboard is the step-in to the X670 family and aims to be priced at around $300 US. The motherboard will feature a 16+2+2 (90A) power delivery powered by a dual 8-pin connector design. Unlike the other two high-end options which feature a fin-heatsink design, the PRO AX comes with a standard aluminum heatsink which still provides full coverage for cooling.

2 of 9

In terms of I/O, the motherboard is equipped with three PCIe x16 slots (1x Gen 4 x16, 1x Gen 4 x4, 1x Gen 3 x4) and a total of four PCIe M.2 slots of which one is Gen 5 compliant and the rest are Gen 4 slots.

You also get a similar array of I/O on the backplate with 6 USB Gen 2 ports and four USB 3.0 ports, a single 2.5 GbE LAN port, and dual USB Type-C ports (1x Gen 2x2, 1x Gen 2).

Gigabyte X670 AORUS Elite AX Motherboard - $250 US For Budget Users

Gigabyte goes one tier down on the AORUS lineup with its X670 Elite AX which uses a 16+2+2 phase design, a single Gen 5.0 NVMe slot, and a good bunch of features that one should expect from AMD Ryzen 7000 platforms such as WiFi 6E, 2.5GbE LAN and decent sized heatsinks on the VRM, PCHs & the M.2 slots.

Gigabyte X670(E) AERO D Motherboard - A Full-On Industrial Design Around $400

Lastly, there's the Gigabyte X670(E) AERO D motherboard which should come slightly above the $400 US mark. The motherboard has lots of similarities with the AORUS Master but trades a Gen 5 M.2 slot with the ASMedia ASM4242 USB4 host controller which provides two USB 4 ports on the rear I/O plate.

A rear shot of the motherboard shows the two AMD X670(E) chipsets located right beneath the circuitry for the DDR5 DIMMs. These are two independent chipsets rather than a single substrate featuring two PCH dies. Cooling is provided by the same PCH heatsink that has a chunky aluminum body.

Gigabyte X670(E) AERO D (Image Credits: TechPowerUP):

2 of 9

Gigabyte will also be offering a Tachyon series motherboard but that would be based on the B650(E) chipset and not the X670 series chipsets.

Gigabyte X670E & X670 Motherboard Specs

Motherboard Name Gigabyte X670E AORUS Xtreme Gigabyte X670E AORUS Master Gigabyte X670 AORUS PRO AX Gigabyte X670 AORUS Elite AX Gigabyte X670(E) AERO D Chipset X670E X670E X670 X670 X670(E) Form Factor E-ATX E-ATX ATX ATX ATX PCB Color Black Black Black Black Black Motherboard Color Black Black + Grey Black + Grey Black + Grey Silver VRM Design Direct 18 Phase (105A SPS) Twin 16 Phase (105A SPS) Twin 16 Phase (90A SPS) Twin 16 Phase (70A SPS) Twin 16 Phase (90A SPS) VRM Heatsink Fins-Array III (8mm Heatpipe) 12W/mK Therma Pad Fins-Array III (Enlarged Heatsink + 8mm Heatpipe) 12W/mK Therma Pad Full-Cover Heatsink (8mm Heatpiipe) 7W/mK Therma Pad Full-Cover Heatsink (8mm Heatpiipe) 5W/mK Therma Pad Full-Cover Heatsink (8mm Heatpiipe) 7W/mK Therma Pad PWM Controller Renesas RAA229628 Renesas RAA229620 Infineon XDPE192C3 Infineon XDPE192C3 Infineon XDPE192C3 Active OC Yes Yes Yes No Yes Power Delivery (CPU) 8+8 Pin 8+8 Pin 8+8 Pin 8+8 Pin 8+8 Pin Memory DIMMs 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM 4 DDR5 DIMM Memory Support DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) DDR5-5600 (JEDEC)

DDR5-**** (EXPO) Memory Capacity 128 GB (Max) 128 GB (Max) 128 GB (Max) 128 GB (Max) 128 GB (Max) PCIe Gen 5.0 Slots 1 (x16) 1 (x16) 0 0 1 (x16) PCIe Gen 4.0 / 3.0 Slots 1/1 (x4/x2) 1/1 (x4/x2) 2/1 (x16/x4/x2) 2/1 (x16/x4/x2) 1/1 (x4/x2) M.2 Gen 5.0 Slots 4 2 1 1 1 M.2 Gen 4.0 Slots 0 2 3 3 3 M.2 Heatsinks 1 4cm Height Heatsink

3 Enlarged Thermal Guard Heatsinks 1 4cm Height Heatsink

3 Enlarged Thermal Guard Heatsinks 1 4cm Height Heatsink

3 Enlarged Thermal Guard Heatsinks 4 Enlarged Thermal Guard Heatsinks 1 4cm Height Heatsink

3 Enlarged Thermal Guard Heatsinks SATA III Ports 6 6 6 4 6 WiFi Capabilities WiFi 6E (AX210) WiFi 6E (AX210) WiFi 6E (AX210) WiFi 6E (RZ616) TBD LAN Capabilities 10 GbE (Aquantia AQC113c) 2.5 GbE (Intel i225V) 2.5 GbE (Intel i225V) 2.5 GbE TBD USB 4.0 Ports (FP Header) 1 1 1 1 1 Total USB Ports 21 21 22 22 TBD RGB Sync Software RGB Fusion RGB Fusion RGB Fusion RGB Fusion RGB Fusion Price $699 $499 $399 $289 ~$300 US

Biostar X670E & X670 Motherboards

Biostar has so far only shown off one motherboard within its X670 portfolio and that's also their flagship design, the X670E Valkyrie. The board is an absolutely slick-looking design with an ATX form factor and black/gold/silver accents. The motherboard features a 22-phase VRM design with 105A Dr.MOS MOSFETs in an 8-layer PCB package with a 2oz Copper design. The CPU is powered by a pair of 8-pin power connectors. There are four DDR5 memory slots that support up to 128 GB capacities and surely some fast speeds with AMD's EXPO technology. Biostar lists the maximum at DDR5-6000+ (OC).

As for expansion slots, the Biostar Valkyrie comes with 2 PCIe Gen 5.0 x16 slots (x16/x8), a single PCIe Gen 4.0 x16 (x4) slot, two Gen 5 and two Gen 4 M.2 slots, and a total of 6 SATA III ports. Other features include 13 USB 3.2 (Gen 2x2 & Gen 2) ports, 4 USB 2.0 ports, a 2.5 GbE Ethernet LAN port powered by Intel's I225V controller, WiFi 6E capabilities, and an internal Thunderbolt header. The motherboard should retail in the $350-$500 US price range.

2 of 9

Biostar X670 & X670E Motherboard Specs

Motherboard Name Biostar X670E Valkryie Chipset X670E Form Factor ATX PCB Color Black PCB Layers 8-Layer Motherboard Color Black + Gold + Silver VRM Design 22 Phase (105A) VRM Heatsink Full-Coverage with Heatpipe Design PWM Controller TBD Power Stages TBD Power Delivery (CPU) 8+8 Memory DIMMs 4 DDR5 DIMM Memory Support DDR5-5600 (JEDEC)

DDR5-6000+ (EXPO) Memory Capacity 128 GB (Max) PCIe Gen 5.0 Slots 2 (x16/x8) PCIe Gen 4.0/3.0 Slots 1 (x4) M.2 Gen 5.0 Slots 2 M.2 Gen 4.0 Slots 2 M.2 Heatsinks Full Coverage Heatsinks SATA III Ports 6 WiFi Capabilities WiFi 6E LAN Capabilities 2.5GbE (Intel I225V) USB 4.0 Ports 0 USB 3.2 Ports 13 USB 3.1/3.0/2.0 Ports 4 RGB Sync Software Aurora Price TBD

Overall, the AMD 600-series motherboards from their partners look fantastic and should offer some great support on AMD's Ryzen 7000 Desktop CPUs which are launching on the 15th of September.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/gotham-knights-everything-you-need-to-know-on-batfamilys-game/,Gotham Knights – Everything You Need to Know on BatFamily’s Game,"Product Info Gotham Knights October 21st Platforms PC, PlayStation 5, Xbox Series S|X Publisher Warner Bros. Interactive Entertainment Developer Warner Bros. Montréal Expected Price 59.99 Expected Release Date October 21st

Gotham Knights is the first game set in Gotham City since 2015's Batman: Arkham Knight and the first game released by developer Warner Bros. Montréal since 2013's Batman: Arkham Origins.

However, it is not a sequel to the Batman: Arkham series, which takes place in a different version of the DC universe.

Pricing, platforms, release date

Gotham Knights was unveiled after years of rumors at 2020's DC FanDome event that occurred online due to the COVID-19 pandemic. The game was targeting a 2021 release date, but publisher Warner Bros. Games had to delay it to 2022 to deliver a better product.

A more precise launch date was announced in March 2022 to be on October 25th. However, a few weeks ago, fans learned that they would get to enter Gotham City four days earlier than planned, thanks to a rare instance of a release date being moved forward.

The original announcement of Gotham Knights included PlayStation 4 and Xbox One as platforms where the game would be available. However, these versions were subsequently canceled, leaving only PC and next-generation consoles such as PlayStation 5 and Xbox Series S|X.

Pre-orders are now available on all platforms, with all pre-orders getting the 233 Kustom BatCycle skin. The PC version is cheaper, priced at $59.99 for the Standard Edition and $79.99 for the Deluxe Edition, which includes the Visionary Pack's following items.

- Exclusive ‘’Knightwatch by Jim Lee’’ Transmog

- Beyond Suitstyle, inspired by Batman Beyond universe

- Salvage to build new Gear

- Boosted Gear

- Exclusive Emote

- 3 Exclusive Suit Colorways:

• Ultra Zur-En-Arrh

• Chroma Frost

• Tribute Asylum

Console customers can get each version with a $10 surplus, as is the case with most games.

There is also a Gotham Knights Collector's Edition, priced at $299.99 for consoles and $289.99 for PC. It includes the following items:

Collector Box

Gotham Knights Deluxe Edition Digital Download

Original Ledbook Packaging & 16-Page Mediabook

Augmented Reality Collectible Pin, Gotham City Map

Exclusive Knights Diorama inspired by Jim Lee & Certificate of Authenticity

In-game content such as Promethium New Guard Transmogs and Visionary Pack

Setting

As briefly mentioned earlier in this post, Gotham Knights is set in a different version of the DC universe compared to the Batman: Arkham games. The main reason for that is the developers wanted to be free of any constraints that would come up with being connected to that universe.

The premise is rather brutal, as Bruce Wayne himself is supposedly dead alongside long-time ally James Gordon, Gotham City's Police Commissioner. With the two bastions of lawfulness removed, Gotham City soon experiences a rampant rise in criminal activity, leaving Batman's protégées with only one option: step into the shoes of Bruce Wayne to try and save the city. Gotham Knights lets players choose between four of the most popular members of the so-called BatFamily: Robin (Tim Drake), Nightwing (Dick Grayson), Batgirl (Barbara Gordon), and Red Hood (Jason Todd).

They will have to deal with several classic villains, such as the Penguin, Mr. Freeze, Harley Quinn, Clayface, and chiefly the secretive and shadowy Court of Owls, which is the centerpiece of the narrative featured in the Batman: Gotham Knights comic book series that inspired the game.

As a side note, the upcoming Gotham Knights TV series in production at The CW does not have any ties with this game whatsoever.

Gameplay Mechanics

The game is an open world action RPG where players can independently level up each character and develop their unique abilities. Gotham Knights features auto-leveling so that enemies will always be leveled up alongside the player characters, and special foes will appear more often once the player characters' levels are high enough. Also, when you're playing as one character, even the others will level up to avoid them being left behind.

Each BatFamily member has access to a unique ultimate-like ability that can be unleashed after filling the corresponding meter. So far, we've only seen Batgirl's swarm of bats.

Additionally, they also all have different means of transportation, some far more outlandish than others. Nightwing hangs on to a Flying Trapeze glider; Batgirl uses a Cape glider; Robin teleports with the Justice League's satellite; Red Hood taps into the mystical powers gained after his resurrection through the Lazarus Pit to literally jump through the air.

Fans of the BatFamily will already know their signature styles and weapons, but here's a recap anyway:

Batgirl has her tonfa, is trained in kickboxing and capoeira, and has excellent hacking skills;

Nightwing is an acrobatic fighter who uses electrified escrima sticks alongside punches and kicks;

Robin wields a collapsible quarterstaff alongside various gadgets;

Red Hood employs firearms, although equipped with non-lethal weapons, and can throw attaching grenades that can be detonated with his pistols.

Gotham Knights supports two-player drop-in, drop-out co-op. The mode will be untethered, so each player will be free to explore in whatever direction they prefer instead of having to stick with the other teammate. Back in June, we also got confirmation that it will be possible to play as two Nightwings (or any other character double); additionally, the game features co-op takedowns, and the combat system as a whole has been designed to take advantage of the co-op feature.

As befitting a game set in Gotham City, the action will only take place at night, when the BatFamily goes out to solve crimes and stop villains. Upon returning to the Belfry home base, daytime will begin, and players will be free to manage their progression, conduct dialogues with their allies, and more.

Last but not least, the game's rendition of Gotham City is said to be far larger than in any other game before, including an underground of interconnected tunnels. There will be five boroughs to explore and to do so without spending too much time moving around, a fast travel mechanic named Fast Bat.

Technical Specifications

We don't know the official PC requirements for Gotham Knights yet. However, we know the game will support ray tracing on PC thanks to a collaboration with Intel. XeSS support is also likely but not confirmed for now.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/warhammer-40000-darktide-everything-you-need-to-know-about-fatsharks-new-game/,"Warhammer 40,000: Darktide – Everything You Need to Know About Fatshark’s New Game","Product Info Warhammer 40,000: Darktide November 30th, 2022 Platforms PC; Xbox Series S|X coming later Publisher Fatshark Developer Fatshark Expected Price $39.99 Expected Release Date November 30th, 2022

Warhammer 40,000: Darktide is a spiritual successor to the popular co-op Warhammer Vermintide games. The Swedish developer Fatshark is moving from the Warhammer fantasy setting to the sci-fi Warhammer 40K universe, which inherently requires several changes to the formula.

Warhammer 40,000: Darktide was first announced in July 2020.

Release date, platforms, pricing, editions

The game originally targeted a 2021 launch window, though Fatshark officially delayed it to Spring 2022 about a year after the announcement. Then, a smaller delay moved the release date of Warhammer 40,000: Darktide to September 13th, 2022. The third major delay nailed down November 30th as the final date.

The game will be first available on PC (Steam, Microsoft Store), with Xbox Series S|X coming later. Cross-play won't be available even between Steam and Microsoft Store users at launch, though the developers said they are exploring it.

The standard edition can be pre-ordered now for a price of $39.99, though it will also be available as part of the Game Pass subscription.

The Imperial Edition is priced at $59.99 and includes the following items:

Loyalist Pack : Purge heresy in style with these 4 unique class outfits, 8 weapon skin patterns, one set of headgear as well as an Ogryn body tattoo.

: Purge heresy in style with these 4 unique class outfits, 8 weapon skin patterns, one set of headgear as well as an Ogryn body tattoo. Mortis Veteran Portrait Frame : A cosmetic portrait frame used to pay tribute to the fallen defenders of Tertium Hive.

: A cosmetic portrait frame used to pay tribute to the fallen defenders of Tertium Hive. Caducades Backpack : A cosmetic backpack for human characters. Scavenged from the fallen troops of Cadia, this backpack has been repurposed to serve those still alive and fighting.

: A cosmetic backpack for human characters. Scavenged from the fallen troops of Cadia, this backpack has been repurposed to serve those still alive and fighting. 2500 Aquilas (premium currency)

Pre-ordering any version of the game provides the following bonus items:

The Atoman Star Weapon Trinket: A cosmetic weapon trinket awarded to those who answered in the hour of Atoma’s need.

A cosmetic weapon trinket awarded to those who answered in the hour of Atoma’s need. Vanguard of the Imperium Portrait Frame: A cosmetic portrait frame reserved for those first to enter the fray, and last to leave it.

Genre and setting

Warhammer 40,000: Darktide is an action game played in first-person view with a focus on cooperative gameplay, just like the Vermintide titles.

The game is set in Tertium, a hive city located within the Atoma Prime world. Atoma Prime lies at the center of the Moebian Domain, a vital fiefdom composed of several Imperial worlds that manufacture vast amounts of goods for the Imperium of Man. The Moebian Domain is however threatened at its borders by both Xenos (hostile alien races) and Daemons (forces of Chaos), colloquially called the Darktide. As such, many regiments of the Astra Militarum were raised on Atoma Prime to protect against these threats.

Eventually, though, Chaos forces sent by Nurgle, the Lord of Decay, managed to infiltrate Tertium with the so-called Admonition cult. Chaos also turned some of the aforementioned regiments, such as the decorated Moebian Sixth, to its side. A Lord Inquisitor is subsequently dispatched to Tertium, where he orders a handful of convicts - the player characters - to be used as agents of the Inquisition.

The story of Warhammer 40,000: Darktide has been written by renowned author Dan Abnett, whose credits span fictional universes as diverse as Marvel, DC, Doctor Who, Warhammer/ Warhammer 40,000, 2000 AD, and Tomb Raider. In the gaming space, he was a co-writer on Creative Assembly's Alien: Isolation.

Darktide also includes over 75K voiced lines to keep the party banter fresh depending on the situation, the party composition, the player character's rank within the Inquisition, and other factors.

Gameplay mechanics

As mentioned above, the moment-to-moment gameplay will largely resemble that of the Vermintide games. Players will face off against hordes of regular enemies, some Elite enemies, and a few Specials. However, there is one key difference: Warhammer 40,000: Darktide features much greater focus on ranged combat due to the setting. Whereas the two Vermintide titles were almost exclusively about melee combat, Darktide promises to be roughly even split.

Fatshark developers have called this Hybrid Combat. Players will have to learn how to use and when to switch to the most appropriate weapon type. The studio has loosely divided this into Far Combat (relegated to combat rifles), Close Combat (shotguns, submachine guns), and proper Melee Combat (in Warhammer 40,000: Darktide, power swords or a thunder hammer). Confirmed weapons also include a Ripper Gun and at least two different Lasguns. Most weapons will have secondary fire modes.

The mechanics in Warhammer 40,000: Darktide have been updated to account for the increasingly dynamic fights, introducing sprinting, vaulting, advanced recoil, and suppression fire. Additionally, given the importance of ranged combat, Fatshark added a regenerating shield called Toughness that lets players absorb a couple of ranged shots before they are stunned and then killed. Do note that this will only be available while sticking near the rest of the team.

The level design in this game is also different than that of the Vermintide games. Whereas missions and levels were tied together in those titles, Fatshark decided to create levels independently of missions in Warhammer 40,000: Darktide. As such, it will be possible for different missions to take place in the same area.

Another key differentiator from Vermintide is that the four classes (Veteran, Zealot, Ogryn, and Psyker) are not tied to specific heroes. Players will instead create their own characters through a specific character creator system. They'll start with choosing a backstory on how they became convicts: dereliction of duty, insubordination, misplaced faith, or sedition.

Appearance tweaking options include body type, face, eye color, hairstyle, facial hair, face tattoos, body tattoos, scars, height, and personality. Warhammer 40,000: Darktide will also allow for deeper visual customization, as players can mix and match their favorite cosmetic items in the following slots: headgear, upper body, lower body, and accessories. While the game itself is played in first-person view, the social hub where players take up contracts and missions is displayed in third-person camera so that the characters can be displayed in all their customized glory.

Unlike Vermintide, there are no class restrictions at play in this game, so you could pick four Psykers if you wanted to. They can be set up very differently anyway, as leveling up provides players with the choice of one between three perks. The rest of the character progression is a blend of randomized rewards, purchasing weapons through a shop (for in-game currency), or setting up a contract to unlock a weapon of choice. Crafting stations let players salvage unwanted items and use those materials for something more useful.

Warhammer 40,000: Darktide will have an evolving narrative with which Fatshark aims to keep the game as fresh as possible for returning fans. The developers also plan to make quick tweaks to regular missions every now and then, such as blackouts that make areas much darker suddenly requiring the use of flashlights.

The Aquilas Currency (Microtransactions)

Warhammer 40,000: Darktide does include microtransactions through the Aquilas premium currency. Most cosmetic items will be sold through the in-game store for real-world money, while others will be unlocked through in-game milestones such as progressing through the story.

Fatshark also said they are open to adding other types of purchasable content to the game in the future. They pointed to Weapon Packs being popular in Vermintide 2.

Trailers

Below is a collection of all the official Warhammer 40,000: Darktide trailers published by Fatshark.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-radeon-rx-7600-xt/,"AMD Radeon RX 7600 XT RDNA 3 “Navi 33” Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info AMD Radeon RX 7600 XT 2023 Manufacturer AMD Type Graphics Card Platforms Desktop PC Expected Price $300-$400 US Expected Release Date 2023

AMD Radeon RX 7600 XT graphics card based on the RDNA 3 ""Navi 33"" GPU will be aimed at the mainstream segment, offering great performance at a great value, and here's everything from specs, price, and performance that you need to know.

AMD Radeon RX 7600 XT RDNA 3 Graphics Card: Monolithic Navi For The Mainstream Gamers

[Updated- 11/09/22]

The AMD Radeon RX *600 segment has always been targeted at the mainstream and budget user. The last generation saw three products within this category, the RX 6650 XT, RX 6600 XT, & the RX 6600. The graphics cards were priced at $399. $379 and $329 US, respectively. So we can see that the prices are mostly within the $300-$400 US segment. The 6650 XT was launched in a bid to let users know that this segment is getting a price bump and it is likely that the same pricing will affect the upcoming RX 7600 series cards. With that said, this is a very heated market where AMD has to go against NVIDIA's next-gen RTX *060 series cards.

Some would consider the existing offerings great against NVIDIA's RTX 3060 series while others will consider them to be slightly more expensive for the features provided. NVIDIA did excel at RT titles and they also had the edge with DLSS which AMD managed to tackle with its AMD FSR 2.0 tech this year. NVIDIA also had the benefit of higher memory and bus sizes on its 3060 series cards whereas the 6600 series adopted a 128-bit bus, relying mostly on the Infinity Cache to eliminate the memory bandwidth bottlenecks.

With the upcoming AMD Radeon RX 7600 XT lineup, there's going to be a big change as users are likely to get the performance of a Navi 21 GPU at less than half the price.

With RDNA 2, AMD not just delivered a brand new GPU package to its gaming audience but a package that was uplifted with a wide variety of architectural and software innovations such as Infinity Cache tech, FSR, and Smart Access Memory. All of these features combined to give Radeon users a fluid and smooth gaming experience while enjoying all the benefits that modern-day games have to offer such as Ray Tracing, DirectX 12 Ultimate, and visual upscale technologies. AMD is also invested in its new FSR 2.1 tech which is already being integrated into games.

We should expect similar things with the next-generation RDNA 3 lineup too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new RDNA 3 GPU core that is expected to debut on the next-gen Radeon RX 7000 series graphics card lineup.

You can also read the expected specs, prices, and performance of other upcoming RDNA 3 GPUs in the posts below:

AMD Navi 33 ""Hotpink Bonefish"" - Mono Ahoy!

While the AMD Navi 31 & Navi 33 GPUs sit at the top with their chiplet designs, the Navi 33 GPU is expected to utilize a monolithic layout. The AMD RDNA 3 GPUs will be part of the 'GFX11' family and the Navi 33 GPU is internally codenamed ""Hotpink Bonefish"" whereas the RDNA 2, the Navi 23 GPU was internally known as 'Dimgrey Cavefish '. AMD has become quite fond of using fish names as its internal codenames for the gaming GPU lineup and that's expected to continue with the RDNA 3 lineup.

AMD confirmed that its RDNA 3 GPUs will be coming later this year with a huge performance uplift. The company's Senior Vice President of Engineering, Radeon Technologies Group, David Wang, said that the next-gen GPUs for Radeon RX 7000 series will offer over 50% performance per watt uplift vs the existing RDNA 2 GPUs. Some of the key features of the RDNA 3 GPUs highlighted by AMD will include:

5nm Process Node

Advanced Chiplet Packaging

Rearchitected Compute Unit

Optimized Graphics Pipeline

Next-Gen AMD Infinity Cache

>50% Perf/Watt vs RDNA 2

In the information published by AMD, the company highlighted a few key features of its RDNA 3 GPUs that will power the next generation of Radeon RX graphics cards. The RDNA 3 GPU will be based on a 5nm process node and utilize an advanced chiplet packaging that delivers increased performance per watt. Furthermore, the GPU will house a range of new technologies such as a brand new and rearchitected Compute Unit, an optimized graphics pipeline, and the next-gen of Infinity Cache.

AMD will be rearchitecting the compute units within RDNA 3 to deliver enhanced raytracing capabilities. Although there's no mention of what these capabilities are if we were to guess, we would say it's definitely talking about performance and a set of advanced features on the RDNA 3 GPU core for Radeon RX 7000 graphics cards.

AMD's RDNA 2 GPU-powered Radeon RX 6000 series were the first to feature raytracing capabilities on the red camp. They were a generation behind NVIDIA who introduced their first raytracing GPUs two years prior on the Turing graphics architecture and fine-tuned it further to deliver better performance in the second generation on Ampere. With RDNA 3 GPU-powered Radeon RX 7000 pitted for launch later this year, we can expect AMD to offer a similar jump in performance or even exceed Ampere's ray-tracing capabilities. But the real challenge ahead would be to rival NVIDIA's 3rd Gen RT (Raytracing) cores which are expected to debut on the Ada Lovelace-powered GeForce RTX 40 series.

Besides raytracing, AMD will also be adding an Optimized Graphics Pipeline for RDNA 3 GPUs will allow for even higher clock speeds than RDNA 2 GPUs. The AMD Radeon RX 6000 cards already run close to 3 GHz so, with an improved 5nm process node, we can expect AMD to breach past the 3 GHz clock limit. This is essential for AMD as their competitor isn't holding back either with RTX 40 series rumors also hinting at up to 3 GHz clock speeds utilizing the more efficient 4N (optimized 5nm process node).

In addition to these, AMD will also be leveraging advanced GPU capabilities of its RDNA 3 graphics architecture to deliver a richer software ecosystem such as support for AV1 and brand new WMMA Instructions which will allow AI-Learning through the assistance of dedicated hardware blocks. The company is expected to debut its next-gen FSR 3.0 technology with RDNA 3 GPUs which will tackle NVIDIA's AI-Assisted DLSS feature suite.

The GPUs will also be amongst the first to utilize the brand new PCIe Gen 5.0 protocol, allowing for up to 128 GB/s transfer rates. This will be a crucial step in enhancing the Smart Access Memory feature and also drive the way forward for SAS (Smart Access Storage) which is a brand new feature designed in compliance with Microsoft's Direct Storage API to deliver faster loading times and better texture streaming in-game. Display capabilities such as DP2.0 and HDMI 2.1 will also be present on the new graphics cards.

AMD RDNA GPU (Generational Comparison) Preliminary:

GPU Name Navi 10 Navi 21 Navi 31 GPU Process 7nm 7nm 5nm/6nm GPU Package Monolithic Monolithic MCD (Multi-Chiplet Die) Shader Engines 2 4 6 GPU WGPs 20 40 48 SPs Per WGP 128 128 256 Compute Units (Per Die) 40 80 192 Cores (Per Die) 2560 5120 12288 Cores (Total) 2560 5120 12288 Peak Clock 1905 MHz 2250 MHz ~3000 MHz FP32 Compute 9.7 23 ~75 Memory Bus 256-bit 256-bit 384-bit Memory Type GDDR6 GDDR6 GDDR6 Memory Capacity 8 GB 16 GB 24 GB Infinity Cache N/A 128 MB 96-192 MB Flagship SKU Radeon RX 5700 XT Radeon RX 6900 XTX Radeon RX 7900 XT TBP 225W 330W 350W Launch Q3 2019 Q4 2020 Q4 2022

AMD Radeon RX 7600 XT Graphics Card Specifications

The AMD Navi 33 GPU would be the third chip of the RDNA 3 lineup and utilize a monolithic design. We have heard that AMD will drop CU (Compute Units) in favor of WGP (Work Group Processors) on its next-gen RDNA 3 GPUs.

AMD Navi 33: 4096 Cores, 128-bit Bus, 32 MB Infinity Cache, 335mm2 GPU Die @6nm

4096 Cores, 128-bit Bus, 32 MB Infinity Cache, 335mm2 GPU Die @6nm AMD Navi 23: 2048 Cores, 128-bit Bus, 32 MB Infinity Cache, 237mm2 GPU Die @7nm

Each WGP will house dual CU (Compute Units) but with twice the SIMD32 clusters as opposed to just 2 on each CU within RDNA 2. The GPU will feature a single die. The die is very similar to the flagship Navi 21 GPU and is expected to utilize a 6nm process node for fabrication with a die size of 203mm2.

The Navi 33 GCD is expected to feature 2 Shader Engines and each Shader Engine has 2 Shader Arrays (2 per SE / 4 in total). This rounds up to 16 WGP's or 32 Compute Units for a total of 4096 cores which is higher than the Radeon RX 6800 ""Navi 21 XL"" GPU. The GPU will come packaged with 32 MB of Infinity Cache, the same amount as the Navi 23 GPU, and across a 128-bit wide bus. Just like the Navi 32 GPUs, the Navi 33 chips will be focused first on the mobile lineup with early graphics performance putting them ahead of the Intel Arc Alchemist lineup at less than half the cost & while pulling less power.

That Navi 33 GPU is said to launch in 2023 and will be pushed to laptops first which means that the desktop lineup will launch later. The GPU is also said to be compatible with existing Navi 23 PCBs & which would mean further cost reduction for AIBs and card manufacturers. AMD is expected to ship more Navi 33 GPUs to the mobile segment than the desktop market with various AMD Advantage designs that could be introduced around CES 2023.

AMD RDNA 3 Navi 3x GPU illustration show possible chip configurations. (Image Credits: @_wildc)

Now, all of this is going to result in a higher power draw and AMD seems to have confirmed this much that their next-generation graphics card lineup will feature higher power consumption but they will still be a more efficient option than what NVIDIA has to offer. The AMD Radeon RX 6650 XT already has a TBP of 176W which was a 16W increase over the RX 6600 XT. We expect the 7600 XT to set up around 180-200W TBP figure. The card is expected to retain its single 8-pin plug input for power and feature an updated dual (reference) fan design.

AMD Radeon RX 7600 XT Graphics Card Performance

As for the performance of the Navi 33 GPUs, we can only use theoretical numbers here since the launch is a bit far away but based on what we know from the expected theoretical compute numbers, the performance is going to see over a 2.3x gain over the existing cards. This is a major leap

AMD Radeon RX 7900 XT: ~75,00 TFLOPs (FP32) (Assuming 3.0 GHz clock)

~75,00 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 7800 XT: ~64.50 TFLOPs (FP32) (Assuming 3.0 GHz clock)

~64.50 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 7700 XT : ~46.08 TFLOPs (FP32) (Assuming 3.0 GHz clock)

: ~46.08 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 7600 XT: ~24.57 TFLOPs (FP32) (Assuming 3.0 GHz clock)

~24.57 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 6950 XT: 23.80 TFLOPs (FP32) (2324 MHz Boost Clock)

23.80 TFLOPs (FP32) (2324 MHz Boost Clock) AMD Radeon RX 6900 XT: 23.04 TFLOPs (FP32) (2250 MHz Boost clock)

23.04 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800 XT: 20.74 TFLOPs (FP32) (2250 MHz Boost clock)

20.74 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800: 16.17 TFLOPs (FP32) (2105 MHz Boost clock)

16.17 TFLOPs (FP32) (2105 MHz Boost clock) AMD Radeon RX 6750 XT: 13.31 TFLOPs (FP32) (2600 MHz Boost clock)

13.31 TFLOPs (FP32) (2600 MHz Boost clock) AMD Radeon RX 6700 XT: 13.21 TFLOPs (FP32) (2581 MHz Boost clock)

13.21 TFLOPs (FP32) (2581 MHz Boost clock) AMD Radeon RX 6700: 11.29 TFLOPs (FP32) (2450 MHz Boost clock)

11.29 TFLOPs (FP32) (2450 MHz Boost clock) AMD Radeon RX 6650 XT: 10.79 TFLOPs (FP32) (2635 MHz Boost clock)

10.79 TFLOPs (FP32) (2635 MHz Boost clock) AMD Radeon RX 6600 XT: 10.60 TFLOPs (FP32) (2589 MHz Boost clock)

10.60 TFLOPs (FP32) (2589 MHz Boost clock) AMD Radeon RX 6600: 8.928 TFLOPs (FP32) (2491 MHz Boost clock)

Based on a theoretical clock speed of 3.0 GHz, you get up to 65 TFLOPs of compute performance and the rumors are suggesting even higher boost clocks. But one should keep in mind that compute performance doesn't necessarily indicate the overall gaming performance but despite that, it will be a huge upgrade for gaming PCs and a 5.3x increase over the current fastest console, the Xbox Series X.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RX 7900 XT 75 RX 7800 XT 65 RX 7700 XT 46 RX 7600 XT 24.6 RX 6950 XT 23.8 RX 6900 XT 23 RX 6800 XT 20.7 RX 6800 16.2 RX 6750 XT 13.3 RX 6700 XT 13.2 Xbox Series X 11.2 RX 6700 10.8 RX 6650 XT 10.6 RX 6600 XT 10.2 PlayStation 5 8.9 RX 6600

This will be over a 2x compute performance uplift for each graphics card versus its predecessor and this is without even factoring in the brand new architectural features that are expected to bring major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison. The card being as fast as the RX 6950 XT would mean truly revolutionary performance uplifts for the mid-range segment.

Gamers should expect fluid 4K gaming to be buttery smooth on these graphics cards and with the FidelityFX suite offering next-gen FSR, SAS, and SAM support, we might even see playable 60 FPS at 1080p (RT) and 1440p resolutions.

AMD Navi 31 GPU SKUs ""Preliminary"" Specifications:

Graphics Card AMD Radeon RX 7900 XT AMD Radeon RX 7800 XT AMD Radeon RX 6900 XT AMD Radeon RX 6800 XT GPU Navi 31 XTX (RDNA 3) Navi 31 XT (RDNA 3) Navi 21 XTX (RDNA 2) Navi 21 XT (RDNA 2) Process Node 5nm+6nm 5nm+6nm 7nm 7nm Die Size ~308mm2 ~308mm2 520mm2 520mm2 Transistors TBD TBD 26.8 Billion 26.8 Billion Compute Units 48 WGPs 42 WGPs 80 72 Stream Processors 12288 10752 5120 4608 TMUs/ROPs TBD TBD 320 / 128 288 / 128 Game Clock TBD TBD 2015 MHz 2015 MHz Boost Clock ~3000 MHz ~3000 MHz 2250 MHz 2250 MHz FP32 TFLOPs ~75 TFLOPs ~65 TFLOPs 23.04 TFLOPs 20.74 TFLOPs Memory Size 24 GB GDDR6 + 96 MB Infinity Cache (+96 MB 3D Stack) 20 GB GDDR6 + 80 MB Infinity Cache (+80 MB 3D Stack) 16 GB GDDR6 +128 MB Infinity Cache 16 GB GDDR6 +128 MB Infinity Cache Memory Bus 384-bit 320-bit 256-bit 256-bit Memory Clock 24 Gbps? 24 Gbps? 16 Gbps 16 Gbps Bandwidth 1152 GB/s 960 GB/s 512 GB/s 512 GB/s TDP ~350W ~300W 300W 300W Price ~$999 US ~$649 US $999 US $649 US

AMD Radeon RX 7600 XT Graphics Card Price & Availability

The AMD Radeon RX 7000 series graphics cards will be focusing on the high-end variants first with the likes of the Navi 31, Navi 32, and Navi 33 GPUs. Previous rumors had mentioned Navi 33 to be followed by Navi 31 and then Navi 32 GPU-based graphics cards but the leaker had earlier pointed out that those plans were no longer applicable. The latest rumors point out to Navi 31 GPUs hitting the store shelves first, later this year. The Navi 32 and Navi 33 GPUs will be aiming a 2023 launch & Navi 33 is mostly mobile-focused so desktop variants might come a bit late after Navi 32 series.

This will be a similar timeframe as the AMD Ryzen 7000 'Zen 4' Desktop CPUs which will also be launching in Fall 2022. Furthermore, NVIDIA is also aiming for a Q4 2022 launch and that's not all, even Intel is planning a Q4 2022 launch for its very own 13th Gen Raptor Lake CPU family. So in total, we are looking at four major desktop PC launches later this fall which means it's going to be one heated Q4 this time around but consumers are in for a treat as they will have lots of tech to choose from for their next-gen gaming PC builds. AMD is highly liked to maintain pricing around the $400 US range for its Navi 33 GPUs.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/a-plague-tale-requiem-everything-you-need-to-know-about-hugo-and-amicias-return/,A Plague Tale: Requiem – Everything You Need to Know About Hugo and Amicia’s Return,"Product Info A Plague Tale: Requiem October 18th, 2022 Platforms PC, PlayStation 4, PlayStation 5, Xbox One, Xbox Series S|X, Nintendo Switch (cloud) Publisher Focus Home Interactive Developer Asobo Studio Expected Price $49.99/$59.99 Expected Release Date October 18th, 2022

A Plague Tale: Requiem is the direct sequel to 2019's breakout hit A Plague Tale: Innocence, which garnered widespread acclaim for French developer Asobo Studio, also responsible for the equally acclaimed Microsoft Flight Simulator.

The game was announced during Microsoft's E3 2021 press conference.

Pricing, platforms, release date

A Plague Tale: Requiem can already be pre-ordered for a price of $49.99 on PC and $59.99 on PlayStation 5 and Xbox Series S|X; Switch pre-orders are not yet available.

Pre-orders on all platforms include the Protector's Pack DLC:

Red Damsel Crossbow Skin

13 Cosmetics for Amicia

Bonus crafting materials

A Plague Tale: Requiem will be released on October 18th for PC (Steam), PlayStation 5, Xbox Series S|X, and Nintendo Switch (via cloud). The game will be available on day one for Game Pass subscribers.

Setting

Just like A Plague Tale: Innocence, its sequel is set in the 14th century's medieval France. The developers have ensured the setting's authenticity by working with Roxane Chilà, a doctor in medieval history from the local Bordeaux-Montaigne university.

The story will begin roughly six months after the events witnessed in the first game, at the beginning of Summer. The De Rune sibling protagonists Hugo and Amicia, accompanied by Hugo and Amicia's mother, Beatrice, and their friend Lucas, a young alchemist, set off from Aquitaine to Provence intending to find a cure for Hugo's blood disease (which allows him to control rat swarms). The disease is dormant at the start of the game but suddenly manifests again in Hugo alongside recurrent dreams of a mysterious island in the South.

This change of location was also chosen by Asobo to create a stark contrast between the tragic events of the plot and the lush, vibrant places found in Southern France.

Gameplay Mechanics

Genre-wise, A Plague Tale: Requiem can be easily classified as a third-person action/adventure game. In this sequel, Amicia, having become more experienced due to the events from Innocence, will be far more resourceful. Players can now freely decide whether to strike from the shadows or openly face foes such as French Inquisition soldiers because Amicia will not die after suffering a single hit this time around unless you've turned on the Hard mode difficulty. Additionally, she can return to stealth after being discovered, which should make for a smoother experience.

Amicia carries a new crossbow weapon that can even deal with armored enemies, though bolt ammunition will be relatively scarce. The developers also added the Tar material, which increases the radius of burning fire (useful for puzzles) and can also ignite enemies when you throw the flammable Ignifer mixture. Crossbow bolts, rocks (thrown with the sling and now infinite in number), and throwing pots can be tweaked with alchemical mixtures to create a total of over 20 combinations.

For his part, Hugo also finds his rat powers enhanced, as players will now be able to directly control the hordes. A new Echo ability lets him outline enemies through walls, as we've seen in many other games before.

From a technological standpoint, Asobo Studio revealed that A Plague Tale: Requiem features hordes of hundreds of thousands of rats, up from the roughly five thousand that could be displayed in the previous title. Partly to accommodate all these rats, the sequel's levels are said to be much larger, which should allow for increased tactical options during combat and improved exploration.

PC Features

NVIDIA confirmed that A Plague Tale: Requiem will include support for RTX technologies like ray tracing and NVIDIA DLSS.

PC requirements haven't been revealed yet, but we will update this page once they are publicly available.

Trailers

The world premiere reveal trailer for A Plague Tale: Requiem dropped at E3 2021.

The gameplay reveal trailer was released in December 2021 at The Game Awards.

Another trailer was released for the Xbox & Bethesda E3 2022 Showcase.

Last but not least, we got the gameplay overview trailer in the second half of August.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-radeon-rx-7700-xt/,"AMD Radeon RX 7700 XT RDNA 3 “Navi 32” Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info AMD Radeon RX 7700 XT 2023 Manufacturer AMD Type Graphics Card Platforms Desktop PC Expected Price ~$500 US Expected Release Date 2023

AMD Radeon RX 7700 XT graphics card based on the RDNA 3 ""Navi 31"" GPU is going to be a high-end gaming solution, ushering in performance levels never before seen in the PC gaming segment, and here's everything from specs, price, and performance that you need to know.

AMD Radeon RX 7700 XT RDNA 3 Graphics Card: MCM For The Mainstream Gaming Audience

[Updated- 04/09/22]

The AMD Radeon RX 6000 RDNA 2 graphics cards proved that the red team can offer performance on par and even exceed that of the competing GeForce RTX lineup. AMD tried to be competitive in the *700 series segment though the inflation and crypto prices led to some really high prices for a segment that was meant to be a top-seller amongst gamers under the $500 US brand. AMD might want to reignite the same level of competitiveness with its Navi 32 series and the respective GPUs under the RX 7700 banner.

AMD not just delivered a brand new GPU package to its gaming audience but a package that was uplifted with a wide variety of architectural and software innovations such as Infinity Cache tech, FSR, and Smart Access Memory. All of these features combined to give Radeon users a fluid and smooth gaming experience while enjoying all the benefits that modern-day games have to offer such as Ray Tracing, DirectX 12 Ultimate, and visual upscalers technologies.

We should expect similar things with the next-generation flagship too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new RDNA 3 GPU core that is expected to debut on the next-gen Radeon RX 7000 series graphics card lineup.

You can also read the expected specs, prices, and performance of other upcoming RDNA 3 GPUs in the posts below:

AMD Navi 32 'Wheat Nas' GPU - MCM At Competitive Prices

While the AMD Navi 31 sits at the top of the spectrum, the Navi 32 GPU will also be another MCM design that's aimed at the $500 US segment. The AMD RDNA 3 GPUs will be part of the 'GFX11' family and the Navi 32 GPU is internally codenamed 'Wheat Nas' whereas the RDNA 2, the Navi 22 GPU was internally known as 'Navy Flounder'. AMD has become quite fond of using fish names as its internal codenames for the gaming GPU lineup and that's expected to continue with the RDNA 3 lineup.

AMD confirmed that its RDNA 3 GPUs will be coming later this year with a huge performance uplift. The company's Senior Vice President of Engineering, Radeon Technologies Group, David Wang, said that the next-gen GPUs for Radeon RX 7000 series will offer over 50% performance per watt uplift vs the existing RDNA 2 GPUs. Some of the key features of the RDNA 3 GPUs highlighted by AMD will include:

5nm Process Node

Advanced Chiplet Packaging

Rearchitected Compute Unit

Optimized Graphics Pipeline

Next-Gen AMD Infinity Cache

>50% Perf/Watt vs RDNA 2

In the information published by AMD, the company highlighted a few key features of its RDNA 3 GPUs that will power the next generation of Radeon RX graphics cards. The RDNA 3 GPU will be based on a 5nm process node and utilize an advanced chiplet packaging that delivers increased performance per watt. Furthermore, the GPU will house a range of new technologies such as a brand new and rearchitected Compute Unit, an optimized graphics pipeline, and the next-gen of Infinity Cache.

AMD will be rearchitecting the compute units within RDNA 3 to deliver enhanced raytracing capabilities. Although there's no mention of what these capabilities are if we were to guess, we would say it's definitely talking about performance and a set of advanced features on the RDNA 3 GPU core for Radeon RX 7000 graphics cards.

AMD's RDNA 2 GPU-powered Radeon RX 6000 series were the first to feature raytracing capabilities on the red camp. They were a generation behind NVIDIA who introduced their first raytracing GPUs two years prior on the Turing graphics architecture and fine-tuned it further to deliver better performance in the second generation on Ampere. With RDNA 3 GPU-powered Radeon RX 7000 pitted for launch later this year, we can expect AMD to offer a similar jump in performance or even exceed Ampere's ray-tracing capabilities. But the real challenge ahead would be to rival NVIDIA's 3rd Gen RT (Raytracing) cores which are expected to debut on the Ada Lovelace-powered GeForce RTX 40 series.

Besides raytracing, AMD will also be adding an Optimized Graphics Pipeline for RDNA 3 GPUs will allow for even higher clock speeds than RDNA 2 GPUs. The AMD Radeon RX 6000 cards already run close to 3 GHz so, with an improved 5nm process node, we can expect AMD to breach past the 3 GHz clock limit. This is essential for AMD as their competitor isn't holding back either with RTX 40 series rumors also hinting at up to 3 GHz clock speeds utilizing the more efficient 4N (optimized 5nm process node).

In addition to these, AMD will also be leveraging advanced GPU capabilities of its RDNA 3 graphics architecture to deliver a richer software ecosystem such as support for AV1 and brand new WMMA Instructions which will allow AI-Learning through the assistance of dedicated hardware blocks. The company is expected to debut its next-gen FSR 3.0 technology with RDNA 3 GPUs which will tackle NVIDIA's AI-Assisted DLSS feature suite.

The GPUs will also be amongst the first to utilize the brand new PCIe Gen 5.0 protocol, allowing for up to 128 GB/s transfer rates. This will be a crucial step in enhancing the Smart Access Memory feature and also drive the way forward for SAS (Smart Access Storage) which is a brand new feature designed in compliance with Microsoft's Direct Storage API to deliver faster loading times and better texture streaming in-game. Display capabilities such as DP2.0 and HDMI 2.1 will also be present on the new graphics cards.

AMD RDNA GPU (Generational Comparison) Preliminary:

GPU Name Navi 10 Navi 21 Navi 31 GPU Process 7nm 7nm 5nm/6nm GPU Package Monolithic Monolithic MCD (Multi-Chiplet Die) Shader Engines 2 4 6 GPU WGPs 20 40 48 SPs Per WGP 128 128 256 Compute Units (Per Die) 40 80 192 Cores (Per Die) 2560 5120 12288 Cores (Total) 2560 5120 12288 Peak Clock 1905 MHz 2250 MHz ~3000 MHz FP32 Compute 9.7 23 ~75 Memory Bus 256-bit 256-bit 384-bit Memory Type GDDR6 GDDR6 GDDR6 Memory Capacity 8 GB 16 GB 24 GB Infinity Cache N/A 128 MB 96-192 MB Flagship SKU Radeon RX 5700 XT Radeon RX 6900 XTX Radeon RX 7900 XT TBP 225W 330W 350W Launch Q3 2019 Q4 2020 Q4 2022

AMD Radeon RX 7700 XT Graphics Card Specifications

The AMD Navi 32 GPU would be the second chip to feature an MCM design. We have heard that AMD will drop CU (Compute Units) in favor of WGP (Work Group Processors) on its next-gen RDNA 3 GPUs.

Each WGP will house dual CU (Compute Units) but with twice the SIMD32 clusters as opposed to just 2 on each CU within RDNA 2. Rumors are that AMD has the option to select between TSMC & Samsung for the 6nm die. The Radeon RX 7700 XT will be based on the full die configuration.

AMD Navi 32 (Radeon RX 7700 XT): 7680 Cores, 256-bit Bus, 64 MB Infinity Cache, 200mm2 GPU Die @5nm

7680 Cores, 256-bit Bus, 64 MB Infinity Cache, 200mm2 GPU Die @5nm AMD Navi 22 (Radeon RX 6700 XT): 2560 Cores, 192-bit Bus, 96 MB Infinity Cache, 335mm2 GPU Die @7nm

The AMD Navi 32 GPU codenamed ""Wheat Nas"" is also one of the two MCM GPUs featured in the RDNA 3 lineup. The GPU will feature a single GCD (Graphics Compute Dies) and four MCDs (Multi-Cache Die). The GPU or GCD is said to measure 200mm2 while each MCD will retain the same size at 37.5mm2.

The GCD will be equipped with 3 Shader Engines and each Shader Engine has 6 Shader Arrays (18 in total). The GPU will feature a total of 30 WGP or 60 Compute Units for a total of 7680 cores. This rounds up to >50% more cores than the Navi 31 flagship.

Each MCD should also feature 2 memory connect links (32-bit). That's a total of 8 32-bit memory controllers for a 256-bit bus interface. Each MCD will retain the 16 MB 0-Hi capacity but there does not seem to be any 1-Hi variant which means that the chip will have just 64 MB maximum configs. That Navi 32 GPU is said to launch in 2023 and will be the highest chip for mobile and mid-tier chip for desktops. The GPU would be first rolled out to the mobile segment and might be announced at CES 2023 which makes ideal sense since we will have Phoenix Range and Dragon Range laptops with Zen 4 cores ready by then.

AMD RDNA 3 Navi 3x GPU illustration show possible chip configurations. (Image Credits: @_wildc)

Now, this is going to result in a higher power draw and AMD seems to have confirmed this much that their next-generation graphics card lineup will feature higher power consumption but they will still be a more efficient option than what NVIDIA has to offer. The AMD Radeon RX 6750 XT already has a TBP of 250W which was a 20W increase over the RX 6700 XT. We expect the 7700 XT to set up around 220-250W TBP figure. The card is expected to retain its dual 8-pin plug input for power and feature an updated dual (reference) or even triple-fan (custom) cooling design.

AMD Radeon RX 7700 XT Graphics Card Performance

As for the performance of these monster GPUs, we can only use theoretical numbers here since the launch is a bit far away but based on what we know from the expected theoretical compute numbers, the performance is going to see over a 2.3x gain over the existing cards. This is a major leap

AMD Radeon RX 7900 XT: ~75,00 TFLOPs (FP32) (Assuming 3.0 GHz clock)

~75,00 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 7800 XT: ~64.50 TFLOPs (FP32) (Assuming 3.0 GHz clock)

~64.50 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 7700 XT : ~46.08 TFLOPs (FP32) (Assuming 3.0 GHz clock)

: ~46.08 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 6950 XT: 23.80 TFLOPs (FP32) (2324 MHz Boost Clock)

23.80 TFLOPs (FP32) (2324 MHz Boost Clock) AMD Radeon RX 6900 XT: 23.04 TFLOPs (FP32) (2250 MHz Boost clock)

23.04 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800 XT: 20.74 TFLOPs (FP32) (2250 MHz Boost clock)

20.74 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800: 16.17 TFLOPs (FP32) (2105 MHz Boost clock)

16.17 TFLOPs (FP32) (2105 MHz Boost clock) AMD Radeon RX 6750 XT: 13.31 TFLOPs (FP32) (2600 MHz Boost clock)

13.31 TFLOPs (FP32) (2600 MHz Boost clock) AMD Radeon RX 6700 XT: 13.21 TFLOPs (FP32) (2581 MHz Boost clock)

13.21 TFLOPs (FP32) (2581 MHz Boost clock) AMD Radeon RX 6700: 11.29 TFLOPs (FP32) (2450 MHz Boost clock)

Based on a theoretical clock speed of 3.0 GHz, you get up to 65 TFLOPs of compute performance and the rumors are suggesting even higher boost clocks. But one should keep in mind that compute performance doesn't necessarily indicate the overall gaming performance but despite that, it will be a huge upgrade for gaming PCs and a 5.3x increase over the current fastest console, the Xbox Series X.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RX 7900 XT 75 RX 7800 XT 65 RX 7700 XT 46 RX 6950 XT 23.8 RX 6900 XT 23 RX 6800 XT 20.7 RX 6800 16.2 RX 6750 XT 13.3 RX 6700 XT 13.2 Xbox Series X 11.2 RX 6700 10.2 PlayStation 5

This will be over a 2x compute performance uplift for each graphics card versus its predecessor and this is without even factoring in the brand new architectural features that are expected to bring major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison. A 3.25x gain over the RX 6800 XT would be huge for AMD and is definitely going to be required if they are going to tackle the likes of NVIDIA's Geforce RTX 40 series.

Gamers should expect fluid 4K gaming to be buttery smooth on these graphics cards and with the FidelityFX suite offering next-gen FSR, SAS, and SAM support, we might even see playable 60 FPS at 8K resolution.

AMD Navi 31 GPU SKUs ""Preliminary"" Specifications:

Graphics Card AMD Radeon RX 7900 XT AMD Radeon RX 7800 XT AMD Radeon RX 6900 XT AMD Radeon RX 6800 XT GPU Navi 31 XTX (RDNA 3) Navi 31 XT (RDNA 3) Navi 21 XTX (RDNA 2) Navi 21 XT (RDNA 2) Process Node 5nm+6nm 5nm+6nm 7nm 7nm Die Size ~308mm2 ~308mm2 520mm2 520mm2 Transistors TBD TBD 26.8 Billion 26.8 Billion Compute Units 48 WGPs 42 WGPs 80 72 Stream Processors 12288 10752 5120 4608 TMUs/ROPs TBD TBD 320 / 128 288 / 128 Game Clock TBD TBD 2015 MHz 2015 MHz Boost Clock ~3000 MHz ~3000 MHz 2250 MHz 2250 MHz FP32 TFLOPs ~75 TFLOPs ~65 TFLOPs 23.04 TFLOPs 20.74 TFLOPs Memory Size 24 GB GDDR6 + 96 MB Infinity Cache (+96 MB 3D Stack) 20 GB GDDR6 + 80 MB Infinity Cache (+80 MB 3D Stack) 16 GB GDDR6 +128 MB Infinity Cache 16 GB GDDR6 +128 MB Infinity Cache Memory Bus 384-bit 320-bit 256-bit 256-bit Memory Clock 24 Gbps? 24 Gbps? 16 Gbps 16 Gbps Bandwidth 1152 GB/s 960 GB/s 512 GB/s 512 GB/s TDP ~350W ~300W 300W 300W Price ~$999 US ~$649 US $999 US $649 US

AMD Radeon RX 7700 XT Graphics Card Price & Availability

The AMD Radeon RX 7000 series graphics cards will be focusing on the high-end variants first with the likes of the Navi 31, Navi 32, and Navi 33 GPUs. Previous rumors had mentioned Navi 33 to be followed by Navi 31 and then Navi 32 GPU-based graphics cards but the leaker had earlier pointed out that those plans were no longer applicable. The latest rumors point out to Navi 31 GPUs hitting the store shelves first, later this year. The Navi 32 and Navi 33 GPUs will be aiming a 2023 launch & Navi 33 is mostly mobile-focused so desktop variants might come a bit late after Navi 32 series.

This will be a similar timeframe as the AMD Ryzen 7000 'Zen 4' Desktop CPUs which will also be launching in Fall 2022. Furthermore, NVIDIA is also aiming for a Q4 2022 launch and that's not all, even Intel is planning a Q4 2022 launch for its very own 13th Gen Raptor Lake CPU family. So in total, we are looking at four major desktop PC launches later this fall which means it's going to be one heated Q4 this time around but consumers are in for a treat as they will have lots of tech to choose from for their next-gen gaming PC builds.

AMD is highly liked to maintain pricing around the $500 US range for its Navi 32 GPUs. While they are expensive to make due to a 5nm process node and chiplet design on top of that, the Radeon RX *700 series has historically been a sweet-spot positioning for high-end and mainstream gamers.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/amd-radeon-rx-7800-xt/,"AMD Radeon RX 7800 XT RDNA 3 “Navi 31” Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info AMD Radeon RX 7800 XT 2022 Manufacturer AMD Type Graphics Card Platforms Desktop PC Expected Price ~$699 US Expected Release Date 2022

AMD Radeon RX 7800 XT graphics card based on the RDNA 3 ""Navi 31"" GPU is going to be a high-end gaming solution, ushering in performance levels never before seen in the PC gaming segment, and here's everything from specs, price, and performance that you need to know.

AMD Radeon RX 7800 XT RDNA 3 Graphics Card: The Next-Gen Navi 31 Flagship Infused With Chiplet Architecture

[Updated- 04/09/22]

The AMD Radeon RX 6000 RDNA 2 graphics cards proved that the red team can offer performance on par and even exceed that of the competing GeForce RTX lineup. Each segment saw a massive increase in performance but the Navi 21 series was where the real action was, with performance surpassing even the likes of the mighty RTX 3090 Ti from NVIDIA.

AMD not just delivered a brand new GPU package to its gaming audience but a package that was uplifted with a wide variety of architectural and software innovations such as Infinity Cache tech, FSR, and Smart Access Memory. All of these features combined to give Radeon users a fluid and smooth gaming experience while enjoying all the benefits that modern-day games have to offer such as Ray Tracing, DirectX 12 Ultimate, and visual upscalers technologies.

We should expect similar things with the next-generation flagship too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new RDNA 3 GPU core that is expected to debut on the next-gen Radeon RX 7000 series graphics card lineup.

AMD Navi 31 'Plum Bonito' GPU - The Next-Gen RDNA 3 Powerhouse

At the top of the RDNA 3 SKU lineup is the Navi 31 GPU. Although there's an even faster chip in the works that is expected to debut next year, the 2022 flagship is said to be based on the Navi 31 GPU. The AMD RDNA 3 GPUs will be part of the 'GFX11' family and the flagship Navi 31 GPU is internally codenamed 'Plum Bonito' whereas the RDNA 2 flagship, the Navi 21 GPU was internally known as 'Sienna Cichlid'. AMD has become quite fond of using fish names as its internal codenames for the gaming GPU lineup and that's expected to continue with the RDNA 3 lineup.

AMD confirmed that its RDNA 3 GPUs will be coming later this year with a huge performance uplift. The company's Senior Vice President of Engineering, Radeon Technologies Group, David Wang, said that the next-gen GPUs for Radeon RX 7000 series will offer over 50% performance per watt uplift vs the existing RDNA 2 GPUs. Some of the key features of the RDNA 3 GPUs highlighted by AMD will include:

5nm Process Node

Advanced Chiplet Packaging

Rearchitected Compute Unit

Optimized Graphics Pipeline

Next-Gen AMD Infinity Cache

>50% Perf/Watt vs RDNA 2

In the information published by AMD, the company highlighted a few key features of its RDNA 3 GPUs that will power the next generation of Radeon RX graphics cards. The RDNA 3 GPU will be based on a 5nm process node and utilize an advanced chiplet packaging that delivers increased performance per watt. Furthermore, the GPU will house a range of new technologies such as a brand new and rearchitected Compute Unit, an optimized graphics pipeline, and the next-gen of Infinity Cache.

AMD will be rearchitecting the compute units within RDNA 3 to deliver enhanced raytracing capabilities. Although there's no mention of what these capabilities are if we were to guess, we would say it's definitely talking about performance and a set of advanced features on the RDNA 3 GPU core for Radeon RX 7000 graphics cards.

AMD's RDNA 2 GPU-powered Radeon RX 6000 series were the first to feature raytracing capabilities on the red camp. They were a generation behind NVIDIA who introduced their first raytracing GPUs two years prior on the Turing graphics architecture and fine-tuned it further to deliver better performance in the second generation on Ampere. With RDNA 3 GPU-powered Radeon RX 7000 pitted for launch later this year, we can expect AMD to offer a similar jump in performance or even exceed Ampere's ray-tracing capabilities. But the real challenge ahead would be to rival NVIDIA's 3rd Gen RT (Raytracing) cores which are expected to debut on the Ada Lovelace-powered GeForce RTX 40 series.

Besides raytracing, AMD will also be adding an Optimized Graphics Pipeline for RDNA 3 GPUs will allow for even higher clock speeds than RDNA 2 GPUs. The AMD Radeon RX 6000 cards already run close to 3 GHz so, with an improved 5nm process node, we can expect AMD to breach past the 3 GHz clock limit. This is essential for AMD as their competitor isn't holding back either with RTX 40 series rumors also hinting at up to 3 GHz clock speeds utilizing the more efficient 4N (optimized 5nm process node).

In addition to these, AMD will also be leveraging advanced GPU capabilities of its RDNA 3 graphics architecture to deliver a richer software ecosystem such as support for AV1 and brand new WMMA Instructions which will allow AI-Learning through the assistance of dedicated hardware blocks. The company is expected to debut its next-gen FSR 3.0 technology with RDNA 3 GPUs which will tackle NVIDIA's AI-Assisted DLSS feature suite.

The GPUs will also be amongst the first to utilize the brand new PCIe Gen 5.0 protocol, allowing for up to 128 GB/s transfer rates. This will be a crucial step in enhancing the Smart Access Memory feature and also drive the way forward for SAS (Smart Access Storage) which is a brand new feature designed in compliance with Microsoft's Direct Storage API to deliver faster loading times and better texture streaming in-game. Display capabilities such as DP2.0 and HDMI 2.1 will also be present on the new graphics cards.

AMD RDNA GPU (Generational Comparison) Preliminary:

GPU Name Navi 10 Navi 21 Navi 31 GPU Process 7nm 7nm 5nm/6nm GPU Package Monolithic Monolithic MCD (Multi-Chiplet Die) Shader Engines 2 4 6 GPU WGPs 20 40 48 SPs Per WGP 128 128 256 Compute Units (Per Die) 40 80 192 Cores (Per Die) 2560 5120 12288 Cores (Total) 2560 5120 12288 Peak Clock 1905 MHz 2250 MHz ~3000 MHz FP32 Compute 9.7 23 ~75 Memory Bus 256-bit 256-bit 384-bit Memory Type GDDR6 GDDR6 GDDR6 Memory Capacity 8 GB 16 GB 24 GB Infinity Cache N/A 128 MB 96-192 MB Flagship SKU Radeon RX 5700 XT Radeon RX 6900 XTX Radeon RX 7900 XT TBP 225W 330W 350W Launch Q3 2019 Q4 2020 Q4 2022

AMD Radeon RX 7800 XT Graphics Card Specifications

The AMD Navi 31 GPU, the flagship RDNA 3 chip, would power the next-gen enthusiast cards such as the Radeon RX 7800 XT graphics card. We have heard that AMD will drop CU (Compute Units) in favor of WGP (Work Group Processors) on its next-gen RDNA 3 GPUs. Each WGP will house dual CU (Compute Units) but with twice the SIMD32 clusters as opposed to just 2 on each CU within RDNA 2. Rumors are that AMD has the option to select between Samsung and TSMC for the 6nm die. The Radeon RX 7800 XT will be a slightly cut-down SKU, similar to the RX 6800 XT.

AMD Radeon RX 7800 XT: 10752 Cores, 320-bit Bus, 80-160 MB Infinity Cache, 308mm 2 GPU Die @5nm

10752 Cores, 320-bit Bus, 80-160 MB Infinity Cache, 308mm GPU Die @5nm AMD Radeon RX 6800 XT: 4608 Cores, 256-bit Bus, 128 MB Infinity Cache, 520mm2 GPU Die @7nm

According to the latest information, the cut-down AMD Navi 31 GPU with RDNA 3 architecture is expected to offer a single GCD with 42 WGPs. This will give out a total of 10,752 SPs or stream processors. This is an increase of 2.3x in cores compared to the 4608 SPs featured on the Navi 21 XT GPU on the RX 6800 XT. The GPU or the Navi 31 GCD is said to measure 308mm2 and will come packaged on TSMC's 5nm process node.

The Navi 31 XT GPU will also carry 5 MCD's which will feature 16 MB Infinity Cache per die and are also likely to carry the 64-bit (32-bit x 2) memory controllers that will provide the chip with a 320-bit bus interface. We can expect the card to feature 20 GB of GDDR6 memory (Samsung) since the RX 6800 XT already featured 16 GB of memory. AMD had a clear lead in memory capacity over the RTX 3080 and they would want to retain that lead going forward with over 16 GB capacities on the high-end cards.

While this equals 80 MB of Infinity Cache which is lower than the 128 MB featured on the current Navi 21 GPUs, there's also a 3D-Stacked solution in the works which was pointed out recently and that would double the Infinity Cache with 32 MB (16 MB 0-hi + 16 MB 1-hi) capacities for a total of 160 MB of cache. This is a 25% increase versus the current Navi 21 design and it also makes Navi 31 the first GPU with both, chiplet and 3D stacked designs. These chiplets or MCD's will be fabricated on TSMC's 6nm process node and measure 37.5mm2 each.

AMD RDNA 3 Navi 3x GPU illustration show possible chip configurations. (Image Credits: @_wildc)

Now, this is going to result in higher power draw and AMD seems to have confirmed this much that their next-generation graphics card lineup will feature higher power consumption but they will still be a more efficient option than what NVIDIA has to offer. The AMD Radeon RX 6950 XT already has a TBP of 335W so for a >2x performance gain. The cards are expected to retain their dual 8-pin plug input for power and feature an updated triple-fan cooling design which is slightly taller than the one currently in use.

AMD Radeon RX 7800 XT Graphics Card Performance

As for the performance of these monster GPUs, we can only use theoretical numbers here since the launch is a bit far away but based on what we know from the expected theoretical compute numbers, the performance is going to see over a 2.3x gain over the existing cards. This is a major leap

AMD Radeon RX 7900 XT: ~75,00 TFLOPs (FP32) (Assuming 3.0 GHz clock)

~75,00 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 7800 XT: ~64.50 TFLOPs (FP32) (Assuming 3.0 GHz clock)

~64.50 TFLOPs (FP32) (Assuming 3.0 GHz clock) AMD Radeon RX 6950 XT: 23.80 TFLOPs (FP32) (2324 MHz Boost Clock)

23.80 TFLOPs (FP32) (2324 MHz Boost Clock) AMD Radeon RX 6900 XT: 23.04 TFLOPs (FP32) (2250 MHz Boost clock)

23.04 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800 XT: 20.74 TFLOPs (FP32) (2250 MHz Boost clock)

20.74 TFLOPs (FP32) (2250 MHz Boost clock) AMD Radeon RX 6800: 16.17 TFLOPs (FP32) (2105 MHz Boost clock)

Based on a theoretical clock speed of 3.0 GHz, you get up to 65 TFLOPs of compute performance and the rumors are suggesting even higher boost clocks. But one should keep in mind that compute performance doesn't necessarily indicate the overall gaming performance but despite that, it will be a huge upgrade for gaming PCs and a 5.3x increase over the current fastest console, the Xbox Series X.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RX 7900 XT 75 RX 7800 XT 65 RX 6950 XT 23.8 RX 6900 XT 23 RX 6800 XT 20.7 RX 6800 16.2 Xbox Series X 12.1 PlayStation 5 10.2

This will be over a 2x compute performance uplift for each graphics card versus its predecessor and this is without even factoring in the brand new architectural features that are expected to bring major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison. A 3.25x gain over the RX 6800 XT would be huge for AMD and is definitely going to be required if they are going to tackle the likes of NVIDIA's Geforce RTX 40 series.

Gamers should expect fluid 4K gaming to be buttery smooth on these graphics cards and with the FidelityFX suite offering next-gen FSR, SAS, and SAM support, we might even see playable 60 FPS at 8K resolution.

AMD Navi 31 GPU SKUs ""Preliminary"" Specifications:

Graphics Card AMD Radeon RX 7900 XT AMD Radeon RX 7800 XT AMD Radeon RX 6900 XT AMD Radeon RX 6800 XT GPU Navi 31 XTX (RDNA 3) Navi 31 XT (RDNA 3) Navi 21 XTX (RDNA 2) Navi 21 XT (RDNA 2) Process Node 5nm+6nm 5nm+6nm 7nm 7nm Die Size ~308mm2 ~308mm2 520mm2 520mm2 Transistors TBD TBD 26.8 Billion 26.8 Billion Compute Units 48 WGPs 42 WGPs 80 72 Stream Processors 12288 10752 5120 4608 TMUs/ROPs TBD TBD 320 / 128 288 / 128 Game Clock TBD TBD 2015 MHz 2015 MHz Boost Clock ~3000 MHz ~3000 MHz 2250 MHz 2250 MHz FP32 TFLOPs ~75 TFLOPs ~65 TFLOPs 23.04 TFLOPs 20.74 TFLOPs Memory Size 24 GB GDDR6 + 96 MB Infinity Cache (+96 MB 3D Stack) 20 GB GDDR6 + 80 MB Infinity Cache (+80 MB 3D Stack) 16 GB GDDR6 +128 MB Infinity Cache 16 GB GDDR6 +128 MB Infinity Cache Memory Bus 384-bit 320-bit 256-bit 256-bit Memory Clock 24 Gbps? 24 Gbps? 16 Gbps 16 Gbps Bandwidth 1152 GB/s 960 GB/s 512 GB/s 512 GB/s TDP ~350W ~300W 300W 300W Price ~$999 US ~$649 US $999 US $649 US

AMD Radeon RX 7800 XT Graphics Card Price & Availability

The AMD Radeon RX 7000 series graphics cards will be focusing on the high-end variants first with the likes of the Navi 31, Navi 32, and Navi 33 GPUs. Previous rumors had mentioned Navi 33 to be followed by Navi 31 and then Navi 32 GPU-based graphics cards but the leaker had earlier pointed out that those plans were no longer applicable. We don't know which GPUs will hit the market first but AMD is likely to unveil its Navi 33 and Navi 31 variants first. As for the launch, the cards are either expected in Late October or Mid-November which means a Q4 2022 launch.

This will be a similar timeframe as the AMD Ryzen 7000 'Zen 4' Desktop CPUs which will also be launching in Fall 2022. Furthermore, NVIDIA is also aiming for a Q4 2022 launch and that's not all, even Intel is planning a Q4 2022 launch for its very own 13th Gen Raptor Lake CPU family. So in total, we are looking at four major desktop PC launches later this fall which means it's going to be one heated Q4 this time around but consumers are in for a treat as they will have lots of tech to choose from for their next-gen gaming PC builds.

As for pricing, the cut-down flagship dies have always been positioned very competitively against the competition. The Radeon RX 6800 and RX 6800 XT were priced at $579 US and $649 US, respectively so we can expect pricing between the $600-$700 US range for the next *800 XT parts. The Radeon RX 7900 XT will take the spot of the >$1000 US flagship but for the best price/value, most users will be looking at the 7800 XT graphics cards.","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/nvidia-geforce-rtx-4070/,"NVIDIA GeForce RTX 4070 Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info NVIDIA GeForce RTX 4070 2022 Manufacturer NVIDIA Type Graphics Card Platforms Desktop PC Expected Price $499-$599 US Expected Release Date 2022

NVIDIA GeForce RTX 4070 will be the next-generation high-end gaming graphics card, offering the latest graphics architecture based on Ada Lovelace GPUs. The graphics card will be replacing the RTX 3070, a very popular gaming graphics card in the $500-$600 US segment.

NVIDIA GeForce RTX 4070 Graphics Card - Purely Designed For Enthusiast Gamers

[Updated- 04/09/22]

While there's no denying the enthusiasm around the higher-end GeForce RTX 4090 & GeForce RTX 4080 series graphics cards that offer the best of the best gaming performance, the RTX 4070 series graphics cards will be designed around the $500 US segment which is a high-end price range that still offers lots of performance at hand. It's simple, the RTX 4090 series will be aimed at users who want the best of the best without worrying about the amount of money they are spending while the RTX 4080 series is aimed at users who want the best gaming performance at the best possible price. The RTX 4070 will be the sweet spot for high-end gaming, offering a buttery smooth 2K game experience.

The previous GeForce RTX 3070 was touted to offer a huge improvement over the RTX 2070 and was said to offer performance faster than the RTX 2080 Ti but ended up mostly on par with the Turing flagship with only the RTX 3070 Ti exceeding the performance of the previous Turing GPU flagship. It looks like the RTX 4070 will be placed in a similar position where it might offer graphics performance on par or close to the RTX 3080 Ti but a 'Ti' variant going further ahead in graphics performance.

We should expect similar things with the next-generation gaming solution too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new Ada Lovelace or AD10* class GPUs that will be powering the next-gen GeForce RTX 40 series cards.

You can also read the expected specs, prices, and performance of other upcoming RTX 40 GPUs in the posts below:

NVIDIA's AD104 'Ada Lovelace' GPU - The Next-Gen Powerhouse

Starting with the GPU configuration, the NVIDIA GeForce RTX 4070 series graphics cards are said to utilize the AD104 GPU core. The GPU is said to measure around 300mm2 and will utilize the TSMC 4N process node which is an optimized version of TSMC's 5nm (N5) node designed for the green team.

The NVIDIA Ada Lovelace AD104 GPU is expected to feature up to 5 GPC (Graphics Processing Clusters). This is the one less GPC than the GA104 GPU. Each GPU will consist of 6 TPCs and 2 SMs which is the same configuration as the existing chip. Each SM (Streaming Multiprocessor) will house four sub-cores which is also the same as the GA102 GPU. What's changed is the FP32 & the INT32 core configuration. Each sub-core will include 128 FP32 units but combined FP32+INT32 units will go up to 192. This is because the FP32 units don't share the same sub-core as the IN32 units. The 128 FP32 cores are separate from the 64 INT32 cores.

So in total, each sub-core will consist of 32 FP32 plus 16 INT32 units for a total of 48 units. Each SM will have a total of 128 FP32 units plus 64 INT32 units for a total of 192 units. And since there are a total of 60 SM units (12 per GPC), we are looking at 7,680 FP32 Units and 3,840 INT32 units for a total of 11,520 cores. Each SM will also include two Wrap Schedules (32 thread/CLK) for 64 wraps per SM. This is a 50% increase on the cores (FP32+INT32) and a 33% increase in Wraps/Threads vs the GA102 GPU.

NVIDIA AD103 'Ada Lovelace' Gaming GPU 'SM' Block Diagram (Image Credits: Kopite7kimi):

Moving over to the cache, this is another segment where NVIDIA has given a big boost over the existing Ampere GPUs. The Ada Lovelace GPUs will pack 192 KB of L1 cache per SM, an increase of 50% over Ampere. That's a total of 2 MB of L1 cache on the top AD104 GPU. The L2 cache will be increased to 48 MB as mentioned in the leaks. This is a 12x increase over the Ampere GA104 GPU that hosts just 4 MB of L2 cache. The cache will be shared across the GPU.

Finally, we have the ROPs which are also increased to 32 per GPC, an increase of 2x over Ampere. You are looking at up to 160 ROPs versus just 96 on the GA104 Ampere GPU. There are also going to be the latest 4th Generation Tensor and 3rd Generation RT (Raytracing) cores infused on the Ada Lovelace GPUs which will help boost DLSS & Raytracing performance to the next level. Overall, the Ada Lovelace AD103 GPU will offer:

5 GPCs vs 6 GPCs on GA104

+25% Cores vs GA104 GPU

50% More L1 Cache (Versus Ampere GA104)

Twice More L2 Cache (Versus Ampere GA104)

+66% ROPs (Versus Ampere GA104)

4th Gen Tensor & 3rd Gen RT Cores

NVIDIA AD104 'Ada Lovelace' Gaming GPU Block Diagram Mock-Up (Image Credits: SemiAnalysis):

Do note that clock speeds, which are said to be between the 2-3 GHz range, aren't taken into the equation so they will also play a major role in improving the per-core performance versus Ampere.

NVIDIA GeForce RTX 4070 Graphics Cards Specifications

As we saw with the GA104 GPU, NVIDIA can have various configurations of the AD104 GPU for its GeForce RTX 4070 series lineup. We realistically expect there to be two variants, the RTX 4070 and the RTX 4070 Ti. The former will be part of the initial lineup while the latter would launch as a mid-cycle refresh. The most entry-level GeForce RTX 30 had 23% fewer cores compared to the full chip but this time, the '80-class' graphics cards are going to be powered by their own chip rather than relying on the AD102 GPU that the flagships use. As such, we can expect anywhere from 6144 to the full 7680 core configuration.

NVIDIA GeForce RTX 4070 'Expected' Specifications

The NVIDIA GeForce RTX 4070 is going to be a cut-down configuration with a slightly higher core count than the RTX 3070 TI (6144 cores) allowing some room for a 'Ti' variant in the future with the full-fat configuration. The core count is expected to be 7168 which means 56 of the 60 SMs will be enabled. The GPU will come packed with 48 MB of L2 cache and up to 160 ROPs which is simply insane.

The clock speeds are not confirmed yet but considering that the TSMC 4N process is being used, we are expecting clocks between the 2.0-3.0 GHz range. The higher than usual clock speed bump comes from the fact that NVIDIA is making a two-node jump considering the Ampere GPUs with Samsung 8nm node was in reality a 10nm process node with some optimizations. NVIDIA is skipping 7nm and going straight for a 5nm node and not even the vanilla variant but an optimized version of it. With Pascal on the TSMC 16nm node, NVIDIA delivered a huge frequency leap and we can expect a similar jump this time around too.

As for memory specs, the GeForce RTX 4070 is expected to rock 10 GB GDDR6 capacities that are said to be clocked at 18 Gbps speeds across a 160-bit bus interface. The card may rock a TBP of 300W and the leaker also mentions that the pricing of this card would not be lower than the RTX 3070 or 3070 Ti graphics cards. Simply put, we can expect a price bump in the '70' class graphics segment.

As for its feature set, the NVIDIA GeForce RTX 4070 graphics cards will rock all the modern NV feature sets such as the latest 4th Gen Tensor Cores, 3rd gen RT cores, and the latest NVENC Encoder, and NVCDEC Decoder, and support for the latest APIs. They will pack all the modern RTX features such as DLSS, Reflex, Broadcast, Resizable-BAR, Freestyle, Ansel, Highlights, Shadowplay, and G-SYNC support too.

NVIDIA GeForce RTX 4070 Series Preliminary Specs:

Graphics Card Name NVIDIA GeForce RTX 4070 Ti NVIDIA GeForce RTX 4070 NVIDIA GeForce RTX 3070 Ti NVIDIA GeForce RTX 3070 GPU Name AD104-400? AD104-400? Ampere GA104-400 Ampere GA104-300 Process Node TSMC 4N TSMC 4N Samsung 8nm Samsung 8nm Die Size ~300mm2 ~300mm2 395.2mm2 395.2mm2 Transistors TBD TBD 17.4 Billion 17.4 Billion PCB NVIDIA PG141-SKU331 NVIDIA PG141-310 SKU341 NVIDIA PG141 NVIDIA PG142 CUDA Cores ~7680 ~7680 6144 5888 TMUs / ROPs TBD / 160 TBD / 160 192/ 96 184 / 96 Tensor / RT Cores TBD / TBD TBD / TBD 192/ 48 184 / 46 Base Clock TBD TBD 1575 MHz 1500 MHz Boost Clock ~2.6 GHz ~2.5 GHz 1770 MHz 1730 MHz FP32 Compute ~40 TFLOPs ~38 TFLOPs 22 TFLOPs 20 TFLOPs RT TFLOPs TBD TBD 42 TFLOPs 40 TFLOPs Tensor-TOPs TBD TBD 174 TOPs 163 TOPs Memory Capacity 12 GB GDDR6X? 12 GB GDDR6X? 8 GB GDDR6X 8 GB GDDR6 Memory Bus 192-bit 192-bit 256-bit 256-bit Memory Speed 21 Gbps 21 Gbps 19 Gbps 14 Gbps Bandwidth 504 GB/s 504 GB/s 608 Gbps 448 Gbps TBP ~400W 285W? 290W 220W Price (MSRP / FE) $599 US? $499 US? $599 US $499 US Launch (Availability) 2022 2022 10th June 2021 29th October 2020

NVIDIA GeForce RTX 4070 Graphics Cards Performance

As for the performance of the gaming GPUs, we can only use theoretical numbers here since the launch is a bit far away but based on what we know, the RTX 40 series cards might be the first gaming cards to hit the 100 TFLOPs compute horsepower limit.

Just for comparison's sake:

NVIDIA GeForce RTX 4090 Ti: ~103 TFLOPs (FP32) (Assuming 2.8 GHz clock)

~103 TFLOPs (FP32) (Assuming 2.8 GHz clock) NVIDIA GeForce RTX 4090: ~90 TFLOPs (FP32) (Assuming 2.8 GHz clock)

~90 TFLOPs (FP32) (Assuming 2.8 GHz clock) NVIDIA GeForce RTX 4080: ~50 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~50 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 3090 Ti: 40 TFLOPs (FP32) (1.86 GHz Boost clock)

40 TFLOPs (FP32) (1.86 GHz Boost clock) NVIDIA GeForce RTX 4070 Ti: ~38 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~38 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 4070: ~36 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~36 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 3090: 36 TFLOPs (FP32) (1.69 GHz Boost clock)

36 TFLOPs (FP32) (1.69 GHz Boost clock) NVIDIA GeForce RTX 3080: 30 TFLOPs (FP32) (1.71 GHz Boost clock)

30 TFLOPs (FP32) (1.71 GHz Boost clock) NVIDIA GeForce RTX 3070 Ti: 22 TFLOPs (FP32) (1.77 GHz Boost clock)

22 TFLOPs (FP32) (1.77 GHz Boost clock) NVIDIA GeForce RTX 3070: 20 TFLOPs (FP32) (1.72 GHz Boost clock)

Based on a theoretical clock speed of 2.5 GHz, you get up to 36 TFLOPs of compute performance and the rumors are suggesting even higher boost clocks. Now, these are definitely sounding like peak clocks, similar to AMD's peak frequencies which are higher than the average 'Game' clock. A 36+ TFLOPs compute performance means more performance on a '70-class' GPU than an '80-class flagship' which will be a good bump. But one should keep in mind that compute performance doesn't necessarily indicate the overall gaming performance.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RTX 4090 Ti (Theoretical) 100 RTX 4090 (Theoretical) 90 RTX 4080 (Theoretical) 50 RTX 3090 Ti 40 RTX 4070 Ti 38 RTX 4070 36 RTX 3090 36 RTX 3080 30 RX 6900 XTX 25 RTX 3070 Ti 22 RTX 3070 20 Xbox Series X 12.1 PlayStation 5 10.2

This will be around a 80% compute performance uplift for the GeForce RTX 4070 graphics card versus its predecessor and this is without even factoring in the RT and Tensor core performance which is expected to get major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison.

Gamers should expect 2K gaming to be buttery smooth on these graphics cards and with DLSS, we might even see playable 60 FPS at 4K resolution with DLSS enabled. But to be realistic, 1440p game titles would be the sweet spot for this graphics card.

NVIDIA GeForce RTX 4070 Graphics Cards Price & Availability

The NVIDIA GeForce RTX 3070 was launched at $499 US but its refreshes have really messed up the prices. The RTX 3070 Ti launched at $599 US, a $100 US premium over the standard model but not offering a big enough performance boost to make the extra $ worth it.

NVIDIA really needs to secure more gamers in the $500 US segment but they have to deliver a product that's worth the price. The RTX 2070 and RTX 3070 were a little underwhelming & while they did manage to close the gap with the previous-gen flagship, they still couldn't recapture the glory of the GTX 1070 which was a good bit ahead of the flagship Titan's that preceded it or the absolutely amazing price point of the GTX 970. With the performance leaps that are expected from the Ada Lovelace architecture, the RTX 4070 has the potential to become one stellar graphics card option in the $500 US price range. Also, if NVIDIA can simply ignore the refresh and give us a full-fat GA104 configuration at the $500 price point, that would be an insane value and one of the best graphics card in its class for some time to come.

The NVIDIA GeForce RTX 40 series graphics cards are rumored for a mid-July reveal and a launch is expected in Q3 2022 so we will know for sure what NVIDIA is up to in the next few months.

NVIDIA GeForce GPU Segment/Tier Prices

Graphics Segment 2014-2016 2016-2017 2017-2018 2018-2019 2019-2020 2020-2021 2021-2022 2022-2023 Titan Tier Titan X (Maxwell) Titan X (Pascal) Titan Xp (Pascal) Titan V (Volta) Titan RTX (Turing) GeForce RTX 3090 GeForce RTX 3090 Ti

GeForce RTX 3090 GeForce RTX 4090 Price $999 US $1199 US $1199 US $2999 US $2499 US $1499 US $1999 US

$1499 US $1599 US Ultra Enthusiast Tier GeForce GTX 980 Ti GeForce GTX 980 Ti GeForce GTX 1080 Ti GeForce RTX 2080 Ti GeForce RTX 2080 Ti GeForce RTX 3080 Ti GeForce RTX 3080 Ti GeForce RTX 4080 Price $649 US $649 US $699 US $999 US $999 US $1199 US $1199 US $1199 US Enthusiast Tier GeForce GTX 980 GeForce GTX 1080 GeForce GTX 1080 GeForce RTX 2080 GeForce RTX 2080 SUPER GeForce RTX 3080 10 GB GeForce RTX 3080 12 GB GeForce RTX 4070 Ti Price $549 US $549 US $549 US $699 US $699 US $699 US $799 US $799 US High-End Tier GeForce GTX 970 GeForce GTX 1070 GeForce GTX 1070 GeForce RTX 2070 GeForce RTX 2070 SUPER GeForce RTX 3070 Ti

GeForce RTX 3070 GeForce RTX 3070 Ti

GeForce RTX 3070 GeForce RTX 4070

GeForce RTX 4060 Ti 16 GB Price $329 US $379 US $379 US $499 US $499 US $599

$499 $599

$499 $599 US

$499 US Mainstream Tier GeForce GTX 960 GeForce GTX 1060 GeForce GTX 1060 GeForce GTX 1060 GeForce RTX 2060 SUPER

GeForce RTX 2060

GeForce GTX 1660 Ti

GeForce GTX 1660 SUPER

GeForce GTX 1660 GeForce RTX 3060 Ti

GeForce RTX 3060 12 GB GeForce RTX 3060 Ti

GeForce RTX 3060 12 GB GeForce RTX 4060 Ti

GeForce RTX 4060 Price $199 US $249 US $249 US $249 US $399 US

$349 US

$279 US

$229 US

$219 US $399 US

$329 US $399 US

$329 US $399 US

$299 US Entry Tier GTX 750 Ti

GTX 750 GTX 950 GTX 1050 Ti

GTX 1050 GTX 1050 Ti

GTX 1050 GTX 1650 SUPER

GTX 1650 GTX 1650 SUPER

GTX 1650 RTX 3050 N/A Price $149 US

$119 US $149 US $139 US

$109 US $139 US

$109 US $159 US

$149 US $159 US

$149 US $249 US N/A","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/nvidia-geforce-rtx-4060/,"NVIDIA GeForce RTX 4060 Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info NVIDIA GeForce RTX 4060 2023 Manufacturer NVIDIA Type Graphics Card Platforms Desktop PC Expected Price $300-$400 US Expected Release Date 2023

NVIDIA GeForce RTX 4060 will be the next-generation high-end gaming graphics card, offering the latest graphics architecture based on Ada Lovelace GPUs. The graphics card will be replacing the RTX 3060, a very popular gaming graphics card in the $300-$400 US segment.

NVIDIA GeForce RTX 4060 Graphics Card - Purely Designed For Enthusiast Gamers

[Updated- 04/09/22]

While there's no denying the enthusiasm around the higher-end GeForce RTX 4090, GeForce RTX 4080 & GeForce RTX 4070 series graphics cards that offer the best of the best gaming performance, the RTX 4060 series graphics cards will be designed around the $300-$400 US segment which is a mainstream price range that still offers lots of performance at hand. It's simple, the RTX 4090 series will be aimed at users who want the best of the best without worrying about the amount of money they are spending while the RTX 4080 series is aimed at users who want the best performance at the best possible price. The RTX 4070 will be the sweet spot for high-end gaming, while the RTX 4060 is designed for the gaming masses at a price that will be hard to ignore given its performance.

The previous GeForce RTX 3060 was touted to offer a huge improvement over the RTX 2080 SUPER. The card did end up meeting its promised performance target but was at most a 25-30% boost when compared to the RTX 2060 SUPER. This was mainly due to the fact that the RTX 2060 SUPER was already an upgraded version of the RTX 2060. But ever since the RTX 20 series, the RTX 30 got its own Ti and Non-Ti flavors.

The RTX 3060 Ti was around 30% faster than the RTX 3060. The RTX 3060 Ti was also 30% faster than the RTX 2060 SUPER and 40-45% faster than the standard RTX 2060. The RTX 3060 Non-Ti on the other hand was around 10% faster than the RTX 2060 SUPER and 20% faster than the RTX 2060 Non-SUPER graphics card. So based on the performance, the RTX 3060 Ti was indeed faster but also more expensive but still ended up delivering better value versus its predecessor.

For example, the RTX 3060 Ti and RTX 2060 SUPER both had an MSRP of $399 US but the 3060 Ti offered 30% faster performance. Meanwhile, the RTX 3060 Non-Ti was $20 US cheaper than the RTX 2060 Non-SUPER but offered a 20% performance boost. Since the RTX 3060 never launched with a Founders Edition variant, most of the models retailed at $15-$20 US more so at the end of the day, you were getting the same price as the RTX 2060 Non-SUPER with a 20% uplift.

The one thing NVIDIA did to persuade the gaming crowd to get its RTX 3060 graphics card equipped with 12 GB of memory versus the 8 GB on the RTX 3060 Ti. That didn't change the performance much since the card featured a lowly 192-bit bus versus the 256-bit bus of the Ti variant, ending up with lower bandwidth.

We should expect similar things with the next-generation gaming solution too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new Ada Lovelace or AD10* class GPUs that will be powering the next-gen GeForce RTX 40 series cards.

You can also read the expected specs, prices, and performance of other upcoming RTX 40 GPUs in the posts below:

NVIDIA's AD106 'Ada Lovelace' GPU - The Next-Gen Mainstream Chip

Starting with the GPU configuration, the NVIDIA GeForce RTX 4060 series graphics cards may utilize both AD104 and AD106 GPUs. The reason is the same as the situation with the current GeForce RTX 30 series where the RTX 3060 Ti is based on the GA104 GPU and the RTX 3060 is based on the GA106 GPU. We have already detailed the AD104 GPU here so let's take a look at the AD106 GPU & what it has to offer. The GPU is said to measure around 200mm2 and will utilize the TSMC 4N process node which is an optimized version of TSMC's 5nm (N5) node designed for the green team.

The NVIDIA Ada Lovelace AD106 GPU is expected to feature up to 3 GPC (Graphics Processing Clusters). This is the same GPC count as the GA106 GPU. Each GPU will consist of 6 TPCs and 2 SMs which is the same configuration as the existing chip. Each SM (Streaming Multiprocessor) will house four sub-cores which is also the same as the GA106 GPU. What's changed is the FP32 & the INT32 core configuration. Each sub-core will include 128 FP32 units but combined FP32+INT32 units will go up to 192. This is because the FP32 units don't share the same sub-core as the IN32 units. The 128 FP32 cores are separate from the 64 INT32 cores.

So in total, each sub-core will consist of 32 FP32 plus 16 INT32 units for a total of 48 units. Each SM will have a total of 128 FP32 units plus 64 INT32 units for a total of 192 units. And since there are a total of 36 SM units (12 per GPC), we are looking at 4,608 FP32 Units and 2,304 INT32 units for a total of 6,912 cores. Each SM will also include two Wrap Schedules (32 thread/CLK) for 64 wraps per SM. This is a 50% increase on the cores (FP32+INT32) and a 33% increase in Wraps/Threads vs the GA102 GPU.

NVIDIA AD103 'Ada Lovelace' Gaming GPU 'SM' Block Diagram (Image Credits: Kopite7kimi):

Moving over to the cache, this is another segment where NVIDIA has given a big boost over the existing Ampere GPUs. The Ada Lovelace GPUs will pack 192 KB of L1 cache per SM, an increase of 50% over Ampere. The L2 cache will be increased to 32 MB as mentioned in the leaks. This is a 10.6x increase over the Ampere GA106 GPU that hosts just 3 MB of L2 cache. The cache will be shared across the GPU.

Finally, we have the ROPs which will stick to 16 per GPC. You are looking at up to 48 ROPs, the same as the current GA106 GPUs. There are also going to be the latest 4th Generation Tensor and 3rd Generation RT (Raytracing) cores infused on the Ada Lovelace GPUs which will help boost DLSS & Raytracing performance to the next level. Overall, the Ada Lovelace AD106 GPU will offer:

Same Number of GPCs as GA106 GPU

+20% Cores vs GA106 GPU

50% More L1 Cache (Versus Ampere GA106)

Over 10x L2 Cache (Versus Ampere GA106)

Same Number of ROPs (Versus Ampere GA106)

4th Gen Tensor & 3rd Gen RT Cores

NVIDIA AD106 'Ada Lovelace' Gaming GPU Block Diagram Mock-Up (Image Credits: SemiAnalysis):

Do note that clock speeds, which are said to be between the 2-3 GHz range, aren't taken into the equation so they will also play a major role in improving the per-core performance versus Ampere.

NVIDIA GeForce RTX 4070 Series Preliminary Specs:

Graphics Card Name NVIDIA GeForce RTX 4070 Ti NVIDIA GeForce RTX 4070 NVIDIA GeForce RTX 3070 Ti NVIDIA GeForce RTX 3070 GPU Name AD104-400? AD104-400? Ampere GA104-400 Ampere GA104-300 Process Node TSMC 4N TSMC 4N Samsung 8nm Samsung 8nm Die Size ~300mm2 ~300mm2 395.2mm2 395.2mm2 Transistors TBD TBD 17.4 Billion 17.4 Billion PCB NVIDIA PG141-SKU331 NVIDIA PG141-310 SKU341 NVIDIA PG141 NVIDIA PG142 CUDA Cores ~7680 ~7680 6144 5888 TMUs / ROPs TBD / 160 TBD / 160 192/ 96 184 / 96 Tensor / RT Cores TBD / TBD TBD / TBD 192/ 48 184 / 46 Base Clock TBD TBD 1575 MHz 1500 MHz Boost Clock ~2.6 GHz ~2.5 GHz 1770 MHz 1730 MHz FP32 Compute ~40 TFLOPs ~38 TFLOPs 22 TFLOPs 20 TFLOPs RT TFLOPs TBD TBD 42 TFLOPs 40 TFLOPs Tensor-TOPs TBD TBD 174 TOPs 163 TOPs Memory Capacity 12 GB GDDR6X? 12 GB GDDR6X? 8 GB GDDR6X 8 GB GDDR6 Memory Bus 192-bit 192-bit 256-bit 256-bit Memory Speed 21 Gbps 21 Gbps 19 Gbps 14 Gbps Bandwidth 504 GB/s 504 GB/s 608 Gbps 448 Gbps TBP ~400W 285W? 290W 220W Price (MSRP / FE) $599 US? $499 US? $599 US $499 US Launch (Availability) 2022 2022 10th June 2021 29th October 2020

NVIDIA GeForce RTX 4060 Graphics Cards Specifications

As we saw with the GeForce RTX 3060 series, NVIDIA can have two distinct configurations of the RTX 4060 series graphics cards. We realistically expect there to be two variants, the RTX 4060 and the RTX 4060 Ti. The existing generation saw the RTX 3060 Ti and RTX 3060 release a few months apart and this is known to be a volume segment so NVIDIA will take the advantage to position two solutions, one around $300-$350 and one around $400-$450 US at mainstream gamers right off the bat.

Currently, there's no telling if the AD104 GPU will be utilized within the GeForce RTX 4060 series and as such, we will focus on the standard RTX 4060 which will utilize the AD106 GPU.

NVIDIA GeForce RTX 4060 'Expected' Specifications

Based on NVIDIA's decision to do a mix of AD104/AD106 or go AD106 across its RTX 4060 series lineup we can either see a cut-down RTX 4060 or one with a full configuration whereas the Ti can use a cut-down AD104 configuration. The AD106 GPU will come packed with 32 MB of L2 cache and up to 48 ROPs.

The clock speeds are not confirmed yet but considering that the TSMC 4N process is being used, we are expecting clocks between the 2.0-3.0 GHz range. The higher than usual clock speed bump comes from the fact that NVIDIA is making a two-node jump considering the Ampere GPUs with Samsung 8nm node was in reality a 10nm process node with some optimizations. NVIDIA is skipping 7nm and going straight for a 5nm node and not even the vanilla variant but an optimized version of it. With Pascal on the TSMC 16nm node, NVIDIA delivered a huge frequency leap and we can expect a similar jump this time around too.

I don't care about the real release date. I'm just curious about the performance of RTX 4060, which consumes more power than RTX 3070. — kopite7kimi (@kopite7kimi) June 5, 2022

As for memory specs, the GeForce RTX 4060 is expected to rock 8 GB GDDR6X capacities that might come at faster 20+ Gbps speeds across a 128-bit bus interface for over 320 GB/s of bandwidth. The 'Ti' variant, if it ends up with an AD104 GPU, could offer up to 12 GB of memory across a 192-bit bus interface. The GeForce RTX 4060 graphics card is also said to rock a TGP of 220W which is an increase of 30% over the RTX 3060 and a 10% increase over the RTX 3060 Ti. This is a massive TGP increase and the performance needs to be really good for NVIDIA to keep its efficiency numbers up.

As for its feature set, the NVIDIA GeForce RTX 4060 graphics cards will rock all the modern NV feature sets such as the latest 4th Gen Tensor Cores, 3rd gen RT cores, and the latest NVENC Encoder, and NVCDEC Decoder, and support for the latest APIs. They will pack all the modern RTX features such as DLSS, Reflex, Broadcast, Resizable-BAR, Freestyle, Ansel, Highlights, Shadowplay, and G-SYNC support too.

NVIDIA GeForce RTX 4060 Series Preliminary Specs:

Graphics Card Name NVIDIA GeForce RTX 4060 Ti NVIDIA GeForce RTX 4060 NVIDIA GeForce RTX 3060 Ti NVIDIA GeForce RTX 3060 GPU Name Ada Lovelace AD104? Ada Lovelace AD106 Ampere GA104-200 Ampere GA106-300 Process Node TSCM 4N TSCM 4N Samsung 8nm Samsung 8nm Die Size ~300mm2 ~200mm2 395.2mm2 TBC Transistors TBD TBD 17.4 Billion TBC CUDA Cores 5120? 4608 4864 3584 TMUs / ROPs TBD / 64 TBD / 48 152 / 80 112 / 64 Tensor / RT Cores TBD TBD 152 / 38 112 / 28 Base Clock TBD TBD 1410 MHz 1320 MHz Boost Clock 2.2-2.6 GHz 2.2-2.6 GHz 1665 MHz 1780 MHz FP32 Compute ~24 TFLOPs ~21 TFLOPs 16 TFLOPs 13 TFLOPs RT TFLOPs TBD TBD 32 TFLOPs 25 TFLOPs Tensor-TOPs TBD TBD 192 TOPs 101 TOPs Memory Capacity 12 GB GDDR6? 8 GB GDDR6? 8 GB GDDR6 12 GB GDDR6 Memory Bus 192-bit 128-bit 256-bit 192-bit Memory Speed TBD TBD 14 Gbps 16 Gbps Bandwidth >448 GB/s >320 GB/s 448 Gbps 384 Gbps TGP ~265W ~220W 175W 170W Price (MSRP / FE) ~$399 US ~$329 US $399 US $329 US Launch (Availability) 1H 2023 1H 2023 2nd December 2020 25th February 2021

NVIDIA GeForce RTX 4060 Graphics Cards Performance

As for the performance of the gaming GPUs, we can only use theoretical numbers here since the launch is a bit far away but based on what we know, the RTX 40 series cards might be the first gaming cards to hit the 100 TFLOPs compute horsepower limit.

Just for comparison's sake:

NVIDIA GeForce RTX 4090 Ti: ~103 TFLOPs (FP32) (Assuming 2.8 GHz clock)

~103 TFLOPs (FP32) (Assuming 2.8 GHz clock) NVIDIA GeForce RTX 4090: ~90 TFLOPs (FP32) (Assuming 2.8 GHz clock)

~90 TFLOPs (FP32) (Assuming 2.8 GHz clock) NVIDIA GeForce RTX 4080: ~50 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~50 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 3090 Ti: 40 TFLOPs (FP32) (1.86 GHz Boost clock)

40 TFLOPs (FP32) (1.86 GHz Boost clock) NVIDIA GeForce RTX 4070 Ti: ~38 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~38 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 4070: ~36 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~36 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 3090: 36 TFLOPs (FP32) (1.69 GHz Boost clock)

36 TFLOPs (FP32) (1.69 GHz Boost clock) NVIDIA GeForce RTX 3080: 30 TFLOPs (FP32) (1.71 GHz Boost clock)

30 TFLOPs (FP32) (1.71 GHz Boost clock) NVIDIA GeForce RTX 3070 Ti: 22 TFLOPs (FP32) (1.77 GHz Boost clock)

22 TFLOPs (FP32) (1.77 GHz Boost clock) NVIDIA GForce RTX 4060: 20 TFLOPs (FP32) (Assiming 2.2 GHz clock)

20 TFLOPs (FP32) (Assiming 2.2 GHz clock) NVIDIA GeForce RTX 3070: 20 TFLOPs (FP32) (1.72 GHz Boost clock)

20 TFLOPs (FP32) (1.72 GHz Boost clock) NVIDIA GeForce RTX 3060 Ti: 16 TFLOPs (FP32) (1.65 GHz Boost clock)

16 TFLOPs (FP32) (1.65 GHz Boost clock) NVIDIA GeForce RTX 3060: 13 TFLOPs (FP32) (1.77 GHz Boost clock)

Based on a theoretical clock speed of 2.2 GHz, you get up to 20 TFLOPs of compute performance and the rumors are suggesting even higher boost clocks. Now, these are definitely sounding like peak clocks, similar to AMD's peak frequencies which are higher than the average 'Game' clock. A 20+ TFLOPs compute performance means more performance on a '60-class' GPU than a '70-class flagship' which will be a good bump. But one should keep in mind that compute performance doesn't necessarily indicate the overall gaming performance.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RTX 4090 Ti (Theoretical) 100 RTX 4090 (Theoretical) 90 RTX 4080 (Theoretical) 50 RTX 3090 Ti 40 RTX 4070 Ti 38 RTX 4070 36 RTX 3090 36 RTX 3080 30 RX 6900 XTX 25 RTX 3070 Ti 22 RTX 4060 (Theoretical) 20 RTX 3070 20 RTX 3060 Ti 16 RTX 3060 13 Xbox Series X 12.1 PlayStation 5 10.2

This will be around a 54% compute performance uplift for the GeForce RTX 4060 graphics card versus its predecessor and this is without even factoring in the RT and Tensor core performance which is expected to get major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison.

Gamers should expect great 1080p and even 1440p gaming to be buttery smooth on these graphics cards and with DLSS. The '60' series has always been targeted at premium 1080p & mainstream 1440p gaming but expect these cards to be really popular amongst eSports with technologies such as Reflex, DLSS, and various streaming capabilities at a mainstream price point.

NVIDIA GeForce RTX 4060 Graphics Cards Price & Availability

The NVIDIA GeForce RTX 3060 was launched at $329 US while the RTX 3060 Ti was launched at 399 US. We can expect NVIDIA to retain the same prices for these cards with a $10-$20 US pricing adjustment here and there.

NVIDIA really needs to secure more gamers in the $300-$400 US segment but they have to deliver a product that's worth the price. The RTX 3060 Ti was a decent product while the RTX 3060 proved very competitive against the AMD Radeon RX 6600 series. Now it will be up to NVIDIA to decide if they want to retain the position of the mainstream-king or go a route that will not be in the interest of gamers and themselves, alike.

The NVIDIA GeForce RTX 40 series graphics cards are rumored for a Q3 reveal and a launch is expected in Q4 2022 so we will know for sure what NVIDIA is up to in the next few months.

NVIDIA GeForce GPU Segment/Tier Prices

Graphics Segment 2014-2016 2016-2017 2017-2018 2018-2019 2019-2020 2020-2021 2021-2022 2022-2023 Titan Tier Titan X (Maxwell) Titan X (Pascal) Titan Xp (Pascal) Titan V (Volta) Titan RTX (Turing) GeForce RTX 3090 GeForce RTX 3090 Ti

GeForce RTX 3090 GeForce RTX 4090 Price $999 US $1199 US $1199 US $2999 US $2499 US $1499 US $1999 US

$1499 US $1599 US Ultra Enthusiast Tier GeForce GTX 980 Ti GeForce GTX 980 Ti GeForce GTX 1080 Ti GeForce RTX 2080 Ti GeForce RTX 2080 Ti GeForce RTX 3080 Ti GeForce RTX 3080 Ti GeForce RTX 4080 Price $649 US $649 US $699 US $999 US $999 US $1199 US $1199 US $1199 US Enthusiast Tier GeForce GTX 980 GeForce GTX 1080 GeForce GTX 1080 GeForce RTX 2080 GeForce RTX 2080 SUPER GeForce RTX 3080 10 GB GeForce RTX 3080 12 GB GeForce RTX 4070 Ti Price $549 US $549 US $549 US $699 US $699 US $699 US $799 US $799 US High-End Tier GeForce GTX 970 GeForce GTX 1070 GeForce GTX 1070 GeForce RTX 2070 GeForce RTX 2070 SUPER GeForce RTX 3070 Ti

GeForce RTX 3070 GeForce RTX 3070 Ti

GeForce RTX 3070 GeForce RTX 4070

GeForce RTX 4060 Ti 16 GB Price $329 US $379 US $379 US $499 US $499 US $599

$499 $599

$499 $599 US

$499 US Mainstream Tier GeForce GTX 960 GeForce GTX 1060 GeForce GTX 1060 GeForce GTX 1060 GeForce RTX 2060 SUPER

GeForce RTX 2060

GeForce GTX 1660 Ti

GeForce GTX 1660 SUPER

GeForce GTX 1660 GeForce RTX 3060 Ti

GeForce RTX 3060 12 GB GeForce RTX 3060 Ti

GeForce RTX 3060 12 GB GeForce RTX 4060 Ti

GeForce RTX 4060 Price $199 US $249 US $249 US $249 US $399 US

$349 US

$279 US

$229 US

$219 US $399 US

$329 US $399 US

$329 US $399 US

$299 US Entry Tier GTX 750 Ti

GTX 750 GTX 950 GTX 1050 Ti

GTX 1050 GTX 1050 Ti

GTX 1050 GTX 1650 SUPER

GTX 1650 GTX 1650 SUPER

GTX 1650 RTX 3050 N/A Price $149 US

$119 US $149 US $139 US

$109 US $139 US

$109 US $159 US

$149 US $159 US

$149 US $249 US N/A","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
https://wccftech.com/roundup/nvidia-geforce-rtx-4050/,"NVIDIA GeForce RTX 4050 Graphics Card Specs, Performance, Price & Availability – Everything We Know So Far","Product Info NVIDIA GeForce RTX 4050 2023 Manufacturer NVIDIA Type Graphics Card Platforms Desktop PC Expected Price $200-$300 US Expected Release Date 2023

NVIDIA GeForce RTX 4050 will be the next-generation mainstream gaming graphics card, offering the latest graphics architecture based on Ada Lovelace GPUs. The graphics card will be replacing the RTX 3050, a very popular gaming graphics card in the sub-$300 US segment which is aimed at the mass consumer segment.

NVIDIA GeForce RTX 4050 Graphics Card - Purely Designed For Enthusiast Gamers

[Updated- 04/09/22]

While there's no denying the enthusiasm around the higher-end GeForce RTX 4090, GeForce RTX 4080 & GeForce RTX 4070 series, or even the more mainstream RTX 4060 graphics cards that offer the best of the best gaming performance, the RTX 4050 series graphics cards will be designed around the $250 US segment which is a mainstream priced range aimed at the budget gamer who wants the same features as higher-end cards minus the performance, at a much lower price point.

It's simple, the RTX 4090 series will be aimed at users who want the best of the best without worrying about the amount of money they are spending while the RTX 4080 series is aimed at users who want the best performance at the best possible price. The RTX 4070 will be the sweet spot for high-end gaming, while the RTX 4060 is designed for the gaming masses at a price that will be hard to ignore given its performance, and the RTX 4050 is aimed at those who want to enter the new series at a budget tier pricing without losing the next-gen feature set.

Just like the generation before it, the RTX 3050 managed to offer performance close to the RTX 2060 but was hurt by its 128-bit memory interface. The RTX 3050 did offer better performance, features, and value (at MSRP) versus its competition, the RX 6500 XT but it took months to reach a price close to the MSRP. Overall, the RTX 3050 was a 1080p-focused and eSports-aimed graphics card and the same should be expected of the RTX 4050.

The '50-class' segment is the share-cow for NVIDIA and it's definitely something that NVIDIA wants to have priced right in its given performance.

We should expect similar things with the next-generation gaming solution too but an important factor to consider is that GPUs are becoming more power-hungry and more pricey. It is a trend that might continue into the future as we get better products but in return, there's always a cost to pay for end consumers. So starting with what we know so far, first we should take a look at the brand new Ada Lovelace or AD10* class GPUs that will be powering the next-gen GeForce RTX 40 series cards.

You can also read the expected specs, prices, and performance of other upcoming RTX 40 GPUs in the posts below:

NVIDIA's AD107 'Ada Lovelace' GPU - Entry-Tier Focused Next-Gen Chip

Starting with the GPU configuration, the NVIDIA GeForce RTX 4050 series graphics cards may utilize both AD106 and AD107 GPUs. We don't think there would be a 'Ti' configuration in the lineup as we didn't get that during the Ampere family but it could change. The reason I mention both AD106 and AD107 GPU for the same card is that the RTX 3050 did the same. The card was produced on GA106 GPUs before GA107 became widely available in the market after its mobile debut.

The RTX 3050 was always meant to utilize the GA107 GPU but NVIDIA made good use of the GA106 dies that couldn't reach the yields required for the higher-end cards. The GPU is said to measure around 150mm2 and will utilize the TSMC 4N process node which is an optimized version of TSMC's 5nm (N5) node designed for the green team.

The NVIDIA Ada Lovelace AD107 GPU is expected to feature up to 3 GPC (Graphics Processing Clusters). This is the same GPC count as the GA106 GPU. Each GPC will consist of 4 TPCs and 8 SMs which is the same configuration as the existing chip. Each SM (Streaming Multiprocessor) will house four sub-cores which is also the same as the GA106 GPU. What's changed is the FP32 & the INT32 core configuration. Each sub-core will include 128 FP32 units but combined FP32+INT32 units will go up to 192. This is because the FP32 units don't share the same sub-core as the IN32 units. The 128 FP32 cores are separate from the 64 INT32 cores.

So in total, each sub-core will consist of 32 FP32 plus 16 INT32 units for a total of 48 units. Each SM will have a total of 128 FP32 units plus 64 INT32 units for a total of 192 units. And since there are a total of 24 SM units (8 per GPC), we are looking at 3,072 FP32 Units and 1,536 INT32 units for a total of 4,608 cores.

NVIDIA AD103 'Ada Lovelace' Gaming GPU 'SM' Block Diagram (Image Credits: Kopite7kimi):

Moving over to the cache, this is another segment where NVIDIA has given a big boost over the existing Ampere GPUs. The Ada Lovelace GPUs will pack 192 KB of L1 cache per SM, an increase of 50% over Ampere. The L2 cache will be increased to 16 MB as mentioned in the leaks. This is an 8x increase over the Ampere GA106 GPU that hosts just 2 MB of L2 cache. The cache will be shared across the GPU.

Finally, we have the ROPs which will stick to 16 per GPC. You are looking at up to 48 ROPs, the same as the current GA106 GPUs. There are also going to be the latest 4th Generation Tensor and 3rd Generation RT (Raytracing) cores infused on the Ada Lovelace GPUs which will help boost DLSS & Raytracing performance to the next level. Overall, the Ada Lovelace AD107 GPU will offer:

Same Number of GPCs as GA106 GPU

+20% Cores vs GA107 GPU

50% More L1 Cache (Versus Ampere GA107)

8x L2 Cache (Versus Ampere GA107)

50% More ROPs (Versus Ampere GA107)

4th Gen Tensor & 3rd Gen RT Cores

NVIDIA AD107 'Ada Lovelace' Gaming GPU Block Diagram Mock-Up (Image Credits: SemiAnalysis):

Do note that clock speeds, which are said to be between the 2-3 GHz range, aren't taken into the equation so they will also play a major role in improving the per-core performance versus Ampere.

NVIDIA GeForce RTX 4050 Series Preliminary Specs:

Graphics Card Name NVIDIA GeForce RTX 4050 NVIDIA GeForce RTX 3050 GPU Name AD107? Ampere GA106-150

Ampere GA107-300? Process Node TSMC 4N Samsung 8nm Die Size ~150mm2 276mm2 (GA106) Transistors TBD 13.2 Billion (GA106) CUDA Cores ~3072 2560 TMUs / ROPs TBD / 48 80 / 32 Tensor / RT Cores TBD / TBD 80 / 20 Base Clock TBD 1552 MHz Boost Clock TBD 1777 MHz FP32 Compute ~14 TFLOPs 9.1 TFLOPs RT TFLOPs TBD 18.2 TFLOPs Tensor-TOPs TBD 72.8 TOPs Memory Capacity 8 GB GDDR6X? 8 GB GDDR6 Memory Bus 128-bit? 128-bit Memory Speed 20 Gbps+? 14 Gbps Bandwidth 320 GB/s+? 224 GB/s TGP ~150W 130W (GA106)

115W (GA107) Price (MSRP / FE) ~$249 US $249 US Launch (Availability) 2023 27th January 2022

NVIDIA GeForce RTX 4050 Graphics Cards Specifications

NVIDIA may or may not offer two variants of the GeForce RTX 4050 graphics cards. That depends on whether they have enough chips or defective dies at hand to turn into discrete graphics cards but we know that there is indeed going to be an RTX 4050 graphics card. The laptop side may see more configurations but for RTX 4050 on desktops, we can expect the following specs.

NVIDIA GeForce RTX 4050 'Expected' Specifications

Based on NVIDIA's decision to do a mix of AD106/AD107 or go AD107 across its RTX 4050 series lineup we can see up to a total of 3072 cores. The AD107 GPU will come packed with 16 MB of L2 cache and up to 48 ROPs.

The clock speeds are not confirmed yet but considering that the TSMC 4N process is being used, we are expecting clocks between the 2.0-3.0 GHz range. The higher than usual clock speed bump comes from the fact that NVIDIA is making a two-node jump considering the Ampere GPUs with Samsung 8nm node was in reality a 10nm process node with some optimizations. NVIDIA is skipping 7nm and going straight for a 5nm node and not even the vanilla variant but an optimized version of it. With Pascal on the TSMC 16nm node, NVIDIA delivered a huge frequency leap and we can expect a similar jump this time around too.

As for memory specs, the GeForce RTX 4050 is expected to rock 8 GB GDDR6X capacities that might come at faster 20+ Gbps speeds across a 128-bit bus interface for over 320 GB/s of bandwidth. The thing is that you can either go 8 GB for such a graphics card in the given 128-bit bus or cut down to 96-bit for either 6 GB or 12 GB configurations.

The GeForce RTX 4050 graphics card is also said to rock a TGP of around 150W which is an increase of 30% over the RTX 3050 on the GA107 GPU. This is a massive TGP increase and the performance needs to be really good for NVIDIA to keep its efficiency numbers up.

As for its feature set, the NVIDIA GeForce RTX 4050 graphics cards will rock all the modern NV feature sets such as the latest 4th Gen Tensor Cores, 3rd gen RT cores, and the latest NVENC Encoder, and NVCDEC Decoder, and support for the latest APIs. They will pack all the modern RTX features such as DLSS, Reflex, Broadcast, Resizable-BAR, Freestyle, Ansel, Highlights, Shadowplay, and G-SYNC support too.

NVIDIA GeForce RTX 4060 Series Preliminary Specs:

Graphics Card Name NVIDIA GeForce RTX 4060 Ti NVIDIA GeForce RTX 4060 NVIDIA GeForce RTX 3060 Ti NVIDIA GeForce RTX 3060 GPU Name Ada Lovelace AD104? Ada Lovelace AD106 Ampere GA104-200 Ampere GA106-300 Process Node TSCM 4N TSCM 4N Samsung 8nm Samsung 8nm Die Size ~300mm2 ~200mm2 395.2mm2 TBC Transistors TBD TBD 17.4 Billion TBC CUDA Cores 5120? 4608 4864 3584 TMUs / ROPs TBD / 64 TBD / 48 152 / 80 112 / 64 Tensor / RT Cores TBD TBD 152 / 38 112 / 28 Base Clock TBD TBD 1410 MHz 1320 MHz Boost Clock 2.2-2.6 GHz 2.2-2.6 GHz 1665 MHz 1780 MHz FP32 Compute ~24 TFLOPs ~21 TFLOPs 16 TFLOPs 13 TFLOPs RT TFLOPs TBD TBD 32 TFLOPs 25 TFLOPs Tensor-TOPs TBD TBD 192 TOPs 101 TOPs Memory Capacity 12 GB GDDR6? 8 GB GDDR6? 8 GB GDDR6 12 GB GDDR6 Memory Bus 192-bit 128-bit 256-bit 192-bit Memory Speed TBD TBD 14 Gbps 16 Gbps Bandwidth >448 GB/s >320 GB/s 448 Gbps 384 Gbps TGP ~265W ~220W 175W 170W Price (MSRP / FE) ~$399 US ~$329 US $399 US $329 US Launch (Availability) 1H 2023 1H 2023 2nd December 2020 25th February 2021

NVIDIA GeForce RTX 4050 Graphics Cards Performance

As for the performance of the gaming GPUs, we can only use theoretical numbers here since the launch is a bit far away but based on what we know, the RTX 40 series cards might be the first gaming cards to hit the 100 TFLOPs compute horsepower limit.

Just for comparison's sake:

NVIDIA GeForce RTX 4090 Ti: ~103 TFLOPs (FP32) (Assuming 2.8 GHz clock)

~103 TFLOPs (FP32) (Assuming 2.8 GHz clock) NVIDIA GeForce RTX 4090: ~90 TFLOPs (FP32) (Assuming 2.8 GHz clock)

~90 TFLOPs (FP32) (Assuming 2.8 GHz clock) NVIDIA GeForce RTX 4080: ~50 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~50 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 3090 Ti: 40 TFLOPs (FP32) (1.86 GHz Boost clock)

40 TFLOPs (FP32) (1.86 GHz Boost clock) NVIDIA GeForce RTX 4070 Ti: ~38 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~38 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 4070: ~36 TFLOPs (FP32) (Assuming 2.5 GHz clock)

~36 TFLOPs (FP32) (Assuming 2.5 GHz clock) NVIDIA GeForce RTX 3090: 36 TFLOPs (FP32) (1.69 GHz Boost clock)

36 TFLOPs (FP32) (1.69 GHz Boost clock) NVIDIA GeForce RTX 3080: 30 TFLOPs (FP32) (1.71 GHz Boost clock)

30 TFLOPs (FP32) (1.71 GHz Boost clock) NVIDIA GeForce RTX 3070 Ti: 22 TFLOPs (FP32) (1.77 GHz Boost clock)

22 TFLOPs (FP32) (1.77 GHz Boost clock) NVIDIA GForce RTX 4060: 20 TFLOPs (FP32) (Assuming 2.2 GHz clock)

20 TFLOPs (FP32) (Assuming 2.2 GHz clock) NVIDIA GeForce RTX 3070: 20 TFLOPs (FP32) (1.72 GHz Boost clock)

20 TFLOPs (FP32) (1.72 GHz Boost clock) NVIDIA GeForce RTX 3060 Ti: 16 TFLOPs (FP32) (1.65 GHz Boost clock)

16 TFLOPs (FP32) (1.65 GHz Boost clock) NVIDIA GeForce RTX 4050: 14 TFLOPs (FP32) (Assuming 2.2 GHz clock)

14 TFLOPs (FP32) (Assuming 2.2 GHz clock) NVIDIA GeForce RTX 3060: 13 TFLOPs (FP32) (1.77 GHz Boost clock)

13 TFLOPs (FP32) (1.77 GHz Boost clock) NVIDIA GeForce RTX 3050: 9 TFLOPs (FP32) (1.77 GHz Boost clock)

Based on a theoretical clock speed of 2.2 GHz, you get up to 14 TFLOPs of compute performance and the rumors are suggesting even higher boost clocks. Now, these are definitely sounding like peak clocks, similar to AMD's peak frequencies which are higher than the average 'Game' clock. A 14+ TFLOPs compute performance means more performance on a '50-class' GPU than a '60-class flagship' which will be a good bump. But one should keep in mind that compute performance doesn't necessarily indicate the overall gaming performance.

FP32 Compute Horsepower Comparisons (Higher is Better) Compute Power 0 20 40 60 80 100 120 0 20 40 60 80 100 120 RTX 4090 Ti (Theoretical) 100 RTX 4090 (Theoretical) 90 RTX 4080 (Theoretical) 50 RTX 3090 Ti 40 RTX 4070 Ti 38 RTX 4070 36 RTX 3090 36 RTX 3080 30 RX 6900 XTX 25 RTX 3070 Ti 22 RTX 4060 (Theoretical) 20 RTX 3070 20 RTX 3060 Ti 16 RTX 4050 14 RTX 3060 13 Xbox Series X 12.1 PlayStation 5 10.2 RTX 3050 9

This will be around a 55% compute performance uplift for the GeForce RTX 4050 graphics card versus its predecessor and this is without even factoring in the RT and Tensor core performance which is expected to get major lifts too in their respective department. Now FLOPs aren't necessarily reflective of the graphics or gaming performance but they do provide a metric that can be used for comparison.

Gamers should most realistically expect good 1080p performance from the RTX 3050. The '50' series has always been targeted at budget 1080p solutions that are popular amongst eSports with technologies such as Reflex, DLSS, and various streaming capabilities at a mainstream price point.

NVIDIA GeForce RTX 4050 Graphics Cards Price & Availability

The NVIDIA GeForce RTX 3050 was launched at $249 US. We can expect NVIDIA to retain the same prices for these cards with a $10-$20 US pricing adjustment here and there.

NVIDIA really needs to secure more gamers in the $200-$300 US segment but they have to deliver a product that's worth the price. The RTX 3050 was a decent upgrade path given and what made it really interesting was its expansive 'GeForce RTX' feature set. This time, NVIDIA should focus on both the feature and performance side of things to lure more gamers into their ecosystem as this is going to be a really heated segment with Intel entering the space with its Arc lineup.

The NVIDIA GeForce RTX 40 series graphics cards are rumored for a Q3 reveal and a launch is expected in Q4 2022 so we will know for sure what NVIDIA is up to in the next few months.

NVIDIA GeForce GPU Segment/Tier Prices

Graphics Segment 2014-2016 2016-2017 2017-2018 2018-2019 2019-2020 2020-2021 2021-2022 2022-2023 Titan Tier Titan X (Maxwell) Titan X (Pascal) Titan Xp (Pascal) Titan V (Volta) Titan RTX (Turing) GeForce RTX 3090 GeForce RTX 3090 Ti

GeForce RTX 3090 GeForce RTX 4090 Price $999 US $1199 US $1199 US $2999 US $2499 US $1499 US $1999 US

$1499 US $1599 US Ultra Enthusiast Tier GeForce GTX 980 Ti GeForce GTX 980 Ti GeForce GTX 1080 Ti GeForce RTX 2080 Ti GeForce RTX 2080 Ti GeForce RTX 3080 Ti GeForce RTX 3080 Ti GeForce RTX 4080 Price $649 US $649 US $699 US $999 US $999 US $1199 US $1199 US $1199 US Enthusiast Tier GeForce GTX 980 GeForce GTX 1080 GeForce GTX 1080 GeForce RTX 2080 GeForce RTX 2080 SUPER GeForce RTX 3080 10 GB GeForce RTX 3080 12 GB GeForce RTX 4070 Ti Price $549 US $549 US $549 US $699 US $699 US $699 US $799 US $799 US High-End Tier GeForce GTX 970 GeForce GTX 1070 GeForce GTX 1070 GeForce RTX 2070 GeForce RTX 2070 SUPER GeForce RTX 3070 Ti

GeForce RTX 3070 GeForce RTX 3070 Ti

GeForce RTX 3070 GeForce RTX 4070

GeForce RTX 4060 Ti 16 GB Price $329 US $379 US $379 US $499 US $499 US $599

$499 $599

$499 $599 US

$499 US Mainstream Tier GeForce GTX 960 GeForce GTX 1060 GeForce GTX 1060 GeForce GTX 1060 GeForce RTX 2060 SUPER

GeForce RTX 2060

GeForce GTX 1660 Ti

GeForce GTX 1660 SUPER

GeForce GTX 1660 GeForce RTX 3060 Ti

GeForce RTX 3060 12 GB GeForce RTX 3060 Ti

GeForce RTX 3060 12 GB GeForce RTX 4060 Ti

GeForce RTX 4060 Price $199 US $249 US $249 US $249 US $399 US

$349 US

$279 US

$229 US

$219 US $399 US

$329 US $399 US

$329 US $399 US

$299 US Entry Tier GTX 750 Ti

GTX 750 GTX 950 GTX 1050 Ti

GTX 1050 GTX 1050 Ti

GTX 1050 GTX 1650 SUPER

GTX 1650 GTX 1650 SUPER

GTX 1650 RTX 3050 N/A Price $149 US

$119 US $149 US $139 US

$109 US $139 US

$109 US $159 US

$149 US $159 US

$149 US $249 US N/A","Software, Mobile, Analysis, Exclusives, Web, Finance, Security, Hardware, Interviews, Gaming, Deals"
